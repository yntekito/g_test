# 統計学（Statistics）

## 要点
- **誤差の種類**を正確に区別することがG検定で頻出：偶然誤差（ランダム）vs 系統誤差（一定方向に偏り）
- **機械学習の文脈**では訓練誤差とテスト誤差の差がモデルの汎化性能を表す
- **損失関数**は訓練誤差を最小化する指標。系統誤差（バイアス）と偶然誤差（バリアンス）のトレードオフが性能に影響

---

## 誤差の種類と損失関数の関係（★試験頻出）

### 1. 測定誤差（Measurement Error）

**定義**:
- データ収集・測定時に生じる誤差の総称
- 真の値 $x$ と測定値 $\hat{x}$ の差： $e = \hat{x} - x$

**分類**:
測定誤差は大きく2種類に分けられる：
1. **偶然誤差（Random Error）**
2. **系統誤差（Systematic Error / Bias）**

**機械学習との関連**:
- 測定誤差を含むデータで学習すると、モデル性能が低下（ノイズ学習）
- データ品質管理が重要

---

### 2. 偶然誤差（Random Error）

**定義**:
- **ランダムに発生する予測不可能な誤差**
- 測定ごとに大きさと方向が異なる
- 正規分布に従うことが多い（平均0）

**特徴**:
- ✅ 測定回数を増やせば平均化して**誤差が減少**
- ✅ 統計的手法（平均化、標準偏差計算）で扱える
- ❌ 完全に除去することは不可能

**日常の比喩**:
- 体重計で毎回少しずつ異なる値が出る（±0.1kg程度のブレ）
- サイコロを振って出た目の合計が理論値からズレる（多数回で平均に収束）

**例**:
- センサーのノイズ（熱雑音、電気的ノイズ）
- サンプリング誤差（有限個のサンプルから推定）
- 人間の測定作業の微小なブレ

**機械学習との関連**:
- 偶然誤差 = **バリアンス（Variance）**
- モデルが訓練データの偶然誤差（ノイズ）まで学習すると**過学習**
- 正則化、ドロップアウト、データ拡張で対処

---

### 3. 系統誤差（Systematic Error / Bias）

**定義**:
- **一定方向に偏る再現性のある誤差**
- 測定ごとに同じ方向・同じ大きさで発生
- 真の値からの恒常的なズレ

**特徴**:
- ❌ 測定回数を増やしても**誤差は減少しない**（平均化できない）
- ✅ 原因を特定すれば**補正可能**（キャリブレーション）
- ❌ 統計的手法では検出しにくい

**日常の比喩**:
- 体重計が常に+2kg多く表示される（調整不良）
- 時計が毎日5分遅れる（内部機構の不具合）
- 体温計が常に0.3°C低く測定（センサーの劣化）

**例**:
- 測定機器の校正不良（ゼロ点のズレ）
- 測定方法の偏り（常に斜めから測定）
- データ収集の偏り（特定時間帯のみサンプリング）

**機械学習との関連**:
- 系統誤差 = **バイアス（Bias）**
- モデルの表現力不足や不適切な仮定により生じる
- モデル複雑化、特徴量追加で対処

**重要な混同注意**:
- 「バイアス（bias）」は機械学習では**2つの意味**がある：
  1. **系統誤差**の意味（バイアス-バリアンストレードオフ）
  2. **ニューラルネットワークのバイアス項**（$y = wx + b$ の $b$）

---

### 4. 訓練誤差（Training Error）

**定義**:
- **訓練データに対するモデルの予測誤差**
- 損失関数で計算される値そのもの

$$\text{訓練誤差} = \frac{1}{N} \sum_{i=1}^{N} L(y_i, \hat{y}_i)$$

- $N$: 訓練データ数
- $L$: 損失関数（MSE、交差エントロピー等）
- $y_i$: 正解ラベル
- $\hat{y}_i$: モデルの予測値

**特徴**:
- 学習の進行とともに**必ず減少**する（勾配降下法の性質）
- 訓練誤差が低い ≠ 良いモデル（過学習の可能性）

**テスト誤差との関係**:
```
誤差
 ↑
 │ ╱‾‾‾‾‾ テスト誤差（汎化誤差）
 │╱        ↑ 過学習で上昇
 │         │
 │╲       ╱
 │ ╲─────╱ 訓練誤差（常に減少）
 │
 └─────────────────────→ 学習の進行
   適切な停止点↑
```

**日常の比喩**:
- 教科書の問題は全問正解（訓練誤差=0）
- でも初見の問題は解けない（テスト誤差が高い）
- これが「丸暗記（過学習）」の状態

---

## 誤差の種類の比較表

| 誤差の種類 | 方向 | 再現性 | 平均化 | 原因例 | 対処法 |
|-----------|------|--------|--------|--------|--------|
| **偶然誤差** | ランダム | なし | ⭕減少 | センサーノイズ、サンプリング | 測定回数増加、平均化 |
| **系統誤差** | 一定方向 | あり | ❌変わらず | 機器の校正不良、測定方法の偏り | 原因特定、補正 |
| **訓練誤差** | - | - | - | モデルの予測ミス | 学習の継続 |

---

## 損失関数との関連

### 損失関数とは
**損失関数（Loss Function）** = 訓練誤差を数値化する関数

$$L(\theta) = \frac{1}{N} \sum_{i=1}^{N} \text{誤差}(y_i, f_\theta(x_i))$$

- **回帰**: MSE（平均二乗誤差）
- **分類**: クロスエントロピー

### 各誤差と損失関数の関係

#### 1. 訓練誤差と損失関数
- 損失関数の値 **=** 訓練誤差
- 勾配降下法で**損失関数を最小化** = **訓練誤差を最小化**

#### 2. 偶然誤差（バリアンス）と損失関数
- 訓練データに偶然誤差（ノイズ）が含まれる
- モデルがノイズまで学習 → **過学習**
- 損失関数に**正則化項**を追加して対処

$$L_{\text{正則化}} = L(\theta) + \lambda R(\theta)$$

- $R(\theta)$: 正則化項（L1、L2）
- パラメータの大きさを制約してバリアンスを抑制

#### 3. 系統誤差（バイアス）と損失関数
- データ収集に系統的な偏りがある場合、損失関数を最小化しても**偏ったモデル**になる
- 例: 特定の人種のデータのみで学習 → 他人種で性能低下
- 対処: **データの多様性確保**、バイアス検証

---

## バイアス-バリアンストレードオフ（★試験超重要）

機械学習の汎化誤差は3要素に分解できる：

$$\text{汎化誤差} = \text{バイアス}^2 + \text{バリアンス} + \text{ノイズ}$$

### 各要素の意味

| 要素 | 対応する誤差 | 意味 | 原因 |
|------|-------------|------|------|
| **バイアス²** | 系統誤差 | モデルの**表現力不足**による誤差 | 単純すぎるモデル |
| **バリアンス** | 偶然誤差 | 訓練データへの**過剰適合**による誤差 | 複雑すぎるモデル |
| **ノイズ** | 測定誤差 | データ自体の**本質的な誤差**（削減不可） | 測定限界 |

### トレードオフの関係

```
誤差
 ↑
 │       ╱‾‾‾‾‾╲  汎化誤差（総誤差）
 │      ╱       ╲
 │     ╱         ╲
 │    │ バリアンス ╲
 │    │  ╱‾‾╲     ╲
 │────┼─╱────╲────╲─── ノイズ（削減不可）
 │    │╱ バイアス² ╲
 │    ╱              ╲
 │   ╱                ╲
 └──────────────────────→ モデルの複雑さ
   単純←   最適   →複雑
   (過小適合)  (過学習)
```

**重要ポイント**:
- モデルを複雑化 → バイアス↓、バリアンス↑
- モデルを単純化 → バイアス↑、バリアンス↓
- **最適な複雑さ**で汎化誤差が最小化

---

## 試験での問われ方

### 典型的な穴埋め問題

**問1**: 誤差の分類
> 「測定時にランダムに発生する誤差を**（A）**といい、一定方向に偏る再現性のある誤差を**（B）**という。**（A）**は測定回数を増やせば減少するが、**（B）**は測定回数を増やしても減少しない。」

**正解**:
- **(A): 偶然誤差（Random Error）**
- **(B): 系統誤差（Systematic Error / Bias）**

**問2**: 損失関数との関連
> 「勾配降下法によってモデルを学習させるとき、**（C）**を最小化するようにパラメータが更新される。**（C）**の値は訓練データに対する**（D）**を表す。」

**正解**:
- **(C): 損失関数（Loss Function）**
- **(D): 訓練誤差（Training Error）**

**問3**: バイアス-バリアンス
> 「モデルの表現力不足による誤差を**（E）**といい、訓練データへの過剰適合による誤差を**（F）**という。両者はトレードオフの関係にある。」

**正解**:
- **(E): バイアス（Bias）**
- **(F): バリアンス（Variance）**

### ひっかけポイント

**混同しやすい組み合わせ**:

1. **偶然誤差 vs 系統誤差**:
   - ❌「偶然誤差は補正できない」→ 正しいのは「系統誤差は補正できる（原因特定後）」
   - ❌「系統誤差は平均化で減少」→ 正しいのは「偶然誤差は平均化で減少」

2. **訓練誤差 vs テスト誤差**:
   - ❌「訓練誤差が低い = 良いモデル」→ テスト誤差も確認必須（過学習検出）
   - ❌「テスト誤差は学習中に最小化する」→ 訓練誤差を最小化（テスト誤差は評価のみ）

3. **バイアス（系統誤差） vs バイアス項（ニューラルネット）**:
   - 全く別の概念！文脈で判断
   - 系統誤差のバイアス: モデルの表現力不足
   - ニューラルネットのバイアス: $y = wx + b$ の $b$

4. **損失関数 vs 評価指標**:
   - 損失関数: 学習時に最小化する指標（微分可能）
   - 評価指標: 性能評価の指標（精度、F1等、必ずしも微分可能でない）

---

## 補足：実務での重要性

### データ品質管理
- **系統誤差の検出**: 異なる測定器での結果比較、標準試料での検証
- **偶然誤差の低減**: 複数回測定の平均、高精度センサーの採用

### モデル診断
- **訓練誤差 vs テスト誤差**の乖離で過学習を検出
- **学習曲線（Learning Curve）**で誤差の推移を可視化
- **交差検証（Cross Validation）**で汎化性能を推定

### バイアス対策
- データ収集の偏りを事前に分析（年齢、性別、地域等）
- 公平性指標（Fairness Metrics）で系統的偏りを検証
- 多様なデータセットでの評価

---

## 定義（再掲）

| 用語 | 英語 | 定義 |
|------|------|------|
| **測定誤差** | Measurement Error | データ収集・測定時に生じる誤差の総称 |
| **偶然誤差** | Random Error | ランダムに発生する予測不可能な誤差 |
| **系統誤差** | Systematic Error / Bias | 一定方向に偏る再現性のある誤差 |
| **訓練誤差** | Training Error | 訓練データに対するモデルの予測誤差 |
| **損失関数** | Loss Function | 訓練誤差を数値化し、学習時に最小化する関数 |
| **バイアス（機械学習）** | Bias | モデルの表現力不足による系統的な誤差 |
| **バリアンス** | Variance | 訓練データへの過剰適合による誤差のばらつき |

---

## 重要キーワード
- **偶然誤差（Random Error）**: ランダム発生、平均化で減少可能
- **系統誤差（Systematic Error）**: 一定方向、補正で除去可能
- **訓練誤差（Training Error）**: 損失関数の値、学習で減少
- **テスト誤差（Test Error）**: 汎化性能の指標
- **バイアス-バリアンストレードオフ**: モデル複雑さの最適化
- **正則化（Regularization）**: バリアンス抑制の手法
- **過学習（Overfitting）**: バリアンスが過大な状態
- **過小適合（Underfitting）**: バイアスが過大な状態
