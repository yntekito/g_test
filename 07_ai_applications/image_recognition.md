# 画像認識

## 要点（試験用）
- 画像から物体・パターンを識別するAI技術。CNNの発展で精度が飛躍的に向上し、ImageNet競技で人間超え達成。
- 主要タスク：画像分類、物体検出（ワンステージ/ツーステージ）、セグメンテーション、顔認識等。
- 深層学習以前は特徴量設計（SIFT、HOG）が主流、現在はEnd-to-Endで特徴抽出から分類まで自動学習。

## 定義
画像認識とは、入力画像からパターン・物体・シーンを識別・分類するコンピュータビジョン技術。深層学習（特にCNN）により、従来の手作業特徴量設計を不要にし、大規模データから自動で特徴を学習する。

## 重要キーワード
- **画像分類**: 画像全体に1つのクラスラベルを割り当てる（例：猫/犬）
- **物体検出**: 画像内の複数物体の位置（バウンディングボックス）とクラスを特定
- **セグメンテーション**: ピクセル単位で領域を分割（セマンティック/インスタンス）
- **CNN（畳み込みニューラルネットワーク）**: 画像認識の基盤技術
- **転移学習**: 事前学習済みモデル（ImageNet）を新タスクにファインチューニング
- **ImageNet**: 大規模画像データセット（1400万枚）、ILSVRCコンペで技術進化を牽引
- **データ拡張**: 回転・反転・切り抜き等で学習データを増やし汎化性能向上

---

## セマンティックセグメンテーション（Semantic Segmentation）

### 要点（試験用）
セマンティックセグメンテーションは、画像の各ピクセルにクラスラベルを割り当てる手法。物体検出が矩形領域で識別するのに対し、ピクセル単位で領域を正確に分割。自動運転の道路認識、医療画像の臓器抽出等に利用。FCN、U-Net、SegNet、DeepLabが代表的。

### 定義
セマンティックセグメンテーションとは、入力画像の各ピクセルに対してクラスラベル（道路、人、空、建物等）を割り当てるコンピュータビジョン技術。画像を意味のある領域に分割し、各領域が何であるかを識別する。

### 重要キーワード
- **ピクセル単位分類**: 各画素に対してクラスを予測
- **セマンティック vs インスタンス**: セマンティックは同じクラスを区別しない、インスタンスは個別物体を区別
- **エンコーダ-デコーダ**: ダウンサンプリング→アップサンプリングの構造
- **スキップ結合**: エンコーダの特徴をデコーダに直接伝播
- **FCN（Fully Convolutional Network）**: 最初の完全畳み込みベースセグメンテーション
- **U-Net**: 医療画像で広く使用、スキップ結合が特徴
- **SegNet**: プーリングインデックス記憶でメモリ効率化
- **DeepLab**: Atrous Convolution（拡張畳み込み）使用
- **IoU（Intersection over Union）**: セグメンテーションの評価指標

### 詳細（教科書風）

#### 背景
従来の画像分類は画像全体に1つのラベル、物体検出は矩形領域で識別。より詳細な領域理解には、ピクセル単位での分類が必要。深層学習（特にFCN以降）により高精度なセグメンテーションが実現。

#### 主要手法の比較

**FCN（Fully Convolutional Network）- 2015年**:
- **特徴**: 全結合層を畳み込み層に置き換え、任意サイズの画像を処理
- **アップサンプリング**: 転置畳み込み（Deconvolution）
- **スキップ結合**: 浅い層の特徴を深い層に結合し、細部を保持
- **意義**: セマンティックセグメンテーションの基礎を確立

**U-Net - 2015年**:
- **構造**: U字型のエンコーダ-デコーダ
- **特徴**: スキップ結合で対応する層を直接接続
- **利点**: 少ないデータで高精度、医療画像に最適
- **用途**: 細胞・臓器のセグメンテーション

**SegNet - 2015年**:
- **特徴**: プーリングインデックスを記憶・再利用
- **利点**: メモリ効率が高い
- **用途**: 自動運転、リアルタイム処理

**DeepLab - 2017年（V3）**:
- **特徴**: Atrous Convolution（拡張畳み込み）で受容野を拡大
- **ASPP**: Atrous Spatial Pyramid Pooling
- **利点**: 高精度、マルチスケール対応
- **用途**: 一般的な高精度セグメンテーション

#### 図解（タスク比較）
```
画像分類:
入力画像 → "犬"（画像全体に1ラベル）

物体検出:
入力画像 → [矩形1: 犬], [矩形2: 猫]（バウンディングボックス）

セマンティックセグメンテーション:
入力画像 → ピクセルごとに色分け
           [空:青, 道路:灰, 車:赤, 人:緑, 建物:黄]

インスタンスセグメンテーション:
入力画像 → ピクセルごと + 個別識別
           [車1:赤, 車2:橙, 人1:緑, 人2:黄緑]
```

#### 基本プロセス（エンコーダ-デコーダ型）
1. **エンコーダ**: CNNで特徴抽出とダウンサンプリング
2. **ボトルネック**: 最も圧縮された特徴表現
3. **デコーダ**: アップサンプリングで元解像度に復元
4. **分類**: 各ピクセルでSoftmaxによりクラス予測
5. **出力**: 入力と同サイズのクラスマップ

### 試験での問われ方

#### 典型設問
- **「画素単位でクラス識別」→セマンティックセグメンテーション**
- **「ピクセルごとにクラスラベルを割り当てる」→セマンティックセグメンテーション**
- FCN、U-Net、SegNet、DeepLabの特徴と違い
- セマンティック vs インスタンスセグメンテーション
- エンコーダ-デコーダ構造の利点

#### ひっかけポイントと違いの整理

**タスク別比較**:

| タスク | 出力単位 | 個別識別 | 代表手法 | 用途例 |
|--------|----------|----------|----------|--------|
| **画像分類** | 画像全体 | - | ResNet, VGG | 画像カテゴリ判定 |
| **物体検出** | 矩形領域 | 可能 | SSD, YOLO, R-CNN | 物体位置特定 |
| **セマンティック** | ピクセル | 不可 | FCN, U-Net, SegNet | 領域分割 |
| **インスタンス** | ピクセル | 可能 | Mask R-CNN | 個別物体抽出 |

**手法別比較**:

| 手法 | 主な特徴 | メモリ | 精度 | 用途 |
|------|----------|--------|------|------|
| **FCN** | 転置畳み込み | 中 | 中 | 基礎手法 |
| **U-Net** | スキップ結合 | 多 | 高 | 医療画像 |
| **SegNet** | インデックス記憶 | 少 | 中 | リアルタイム |
| **DeepLab** | Atrous Conv | 中 | 非常に高 | 高精度要求 |

**混同注意**:
- **セマンティック vs インスタンス**: セマンティックは「道路」「車」をクラス分類、インスタンスは「車1」「車2」を個別識別
- **物体検出 vs セグメンテーション**: 検出は矩形、セグメンテーションは正確な輪郭
- **画像分類 vs セグメンテーション**: 分類は画像全体、セグメンテーションはピクセル単位

**出題パターン**:
- 「画素単位でクラス識別」→**セマンティックセグメンテーション**
- 「スキップ結合で特徴マップ結合」→**U-Net**
- 「プーリングインデックス記憶」→**SegNet**
- 「全結合層を畳み込み層に置き換え」→**FCN**
- 「個別の物体をピクセル単位で区別」→**インスタンスセグメンテーション（Mask R-CNN）**

### 補足

#### 実務観点
**用途**: 
- 自動運転: 道路・歩行者・車両の領域分割
- 医療: 臓器・腫瘍の抽出
- 衛星画像: 土地利用分類
- ARアプリ: 背景除去

**評価指標**: 
- **IoU（Intersection over Union）**: 予測と正解の重なり度 = (交差面積) / (和集合面積)
- **mIoU（mean IoU）**: 全クラスのIoU平均
- **Pixel Accuracy**: ピクセル単位の正解率

**課題**: 
- クラス不均衡（背景が大部分を占める）
- 境界の正確な予測が困難
- 計算コストが高い
- アノテーションコスト（ピクセル単位のラベル付け）

#### 最新動向
- **Transformer系**: SegFormer、Segmenter等
- **リアルタイム化**: BiSeNet、ICNet等
- **弱教師あり**: 粗いアノテーションから学習
- **3Dセグメンテーション**: 点群データへの拡張

#### 関連トピック
- [CNN](../06_deep_learning/cnn.md) - ベースとなる畳み込みネットワーク
- [SegNet](07_ai_applications/image_recognition.md) - 具体的手法の詳細
- [評価指標](../05_machine_learning/evaluation_metrics.md) - IoU、Pixel Accuracy

---

## SSD（Single Shot MultiBox Detector）

### 要点（試験用）
SSDはYOLOと並ぶワンステージ物体検出器で、領域候補生成と分類を1回の順伝播で同時実行。R-CNNのようなツーステージ検出器と異なり、推論速度が速くリアルタイム処理に適する。複数スケールの特徴マップから異なるサイズの物体を検出する点が特徴。

### 定義
SSD（Single Shot MultiBox Detector）は、畳み込みニューラルネットワーク（CNN）の複数層から得られる特徴マップ上で、デフォルトボックス（アンカー）を基準に物体の位置（バウンディングボックス）とクラスを同時に予測するワンステージ物体検出アルゴリズム。

### 重要キーワード
- **ワンステージ検出器**: 領域候補生成と分類を1つのネットワークで一度に実行
- **ツーステージ検出器**: R-CNN系のように、領域候補→分類の2段階処理
- **デフォルトボックス（アンカー）**: 事前定義された候補矩形
- **マルチスケール特徴マップ**: 異なる解像度の層から検出を行う
- **バウンディングボックス**: 物体を囲む矩形領域
- **YOLO**: 同様のワンステージ検出器
- **Non-Maximum Suppression (NMS)**: 重複検出の除去処理

### 詳細（教科書風）

#### 背景
従来のR-CNN系（Faster R-CNN等）はRegion Proposal Network（RPN）で候補領域を生成し、その後分類する**ツーステージ検出器**で精度は高いが処理が遅い。SSDは2016年に提案され、YOLOと同様に**ワンステージ**で処理することで高速化を実現。

#### 基本プロセス
1. **特徴抽出**: VGG16等のベースネットワークで画像から特徴マップを抽出
2. **マルチスケール検出**: 複数の畳み込み層（異なる解像度）でデフォルトボックスを配置
3. **予測**: 各デフォルトボックスに対し、クラススコアと位置オフセットを出力
4. **Non-Maximum Suppression (NMS)**: 重複検出を除去して最終結果を得る

#### 図解（アーキテクチャ）
```
入力画像 (300×300)
  ↓
VGG-16ベース (特徴抽出)
  ↓
Conv4_3 → 検出ヘッド (大きい物体)
  ↓
Conv7   → 検出ヘッド (中程度の物体)
  ↓
Conv8_2 → 検出ヘッド (小さい物体)
  ↓
... (さらに小さいスケール)
  ↓
各層で: クラススコア + バウンディングボックスオフセット
  ↓
NMS → 最終検出結果
```

#### 主な特徴
- **速度**: 1回の順伝播で完結（59 FPS @SSD300）
- **精度**: マルチスケール特徴により様々なサイズの物体に対応
- **デフォルトボックス**: アスペクト比・スケールを変えた複数の候補を事前定義

### 試験での問われ方

#### 典型設問
- SSDの検出方式（ワンステージ/ツーステージ）
- R-CNN/Faster R-CNN/YOLOとの比較（速度・精度・処理段階）
- マルチスケール特徴マップの役割
- **穴埋め問題**: 「SSDは位置の特定とクラスの識別を同時に行う（ワンステージ検出器）であり、出力層から入力画像の位置における物体らしさと矩形領域を出力する手法であり、（リアルタイム物体検出）を目的としている。」

#### ひっかけポイントと違いの整理

| 項目 | SSD | R-CNN/Faster R-CNN | YOLO |
|------|-----|-------------------|------|
| **検出方式** | ワンステージ | ツーステージ | ワンステージ |
| **処理段階** | 同時予測（位置+クラス） | 候補生成→分類 | 同時予測 |
| **速度** | 高速（リアルタイム可） | 遅い | 非常に高速 |
| **精度** | 中〜高 | 高精度 | 中程度 |
| **特徴** | マルチスケール特徴マップ | RPN使用 | グリッド分割 |
| **小物体検出** | 比較的得意 | 得意 | 苦手 |

**混同注意**:
- **R-CNNとの違い**: SSD��領域候補生成（RPN）を行わず、デフォルトボックスで直接予測
- **YOLOとの違い**: SSDは複数層から検出、YOLOは最終層のみ（初期版）
- **セグメンテーションとの違い**: SSDは矩形検出、Mask R-CNNはピクセル単位のマスク生成

**出題パターン**:
- 「ワンステージ/ツーステージ」の用語選択
- 「リアルタイム処理に適した手法」→SSD/YOLO
- 「高精度が必要な場合」→Faster R-CNN

### 補足

#### 実務観点
- **用途**: 自動運転（歩行者・車両検出）、監視カメラ、ロボットビジョン
- **トレードオフ**: 速度と精度のバランスが重要。用途に応じてSSD/YOLO（速度重視）かFaster R-CNN（精度重視）を選択
- **実装**: TensorFlow、PyTorchで実装済みモデルが利用可能
- **改良版**: SSD512（入力サイズ大）、DSSD（デコンボリューション追加）等

#### 関連トピック
- [CNN](../06_deep_learning/cnn.md) - ベースとなる畳み込みネットワーク
- [評価指標](../05_machine_learning/evaluation_metrics.md) - mAP（mean Average Precision）、IoU

---

## SegNet（Segmentation Network）

### 要点（試験用）
SegNetはセマンティックセグメンテーション向けエンコーダ-デコーダ構造のネットワーク。エンコーダのプーリング時に**最大値の位置（インデックス）を記憶**し、デコーダのアンプーリングで再利用する点が特徴。メモリ効率が高く、境界保存に優れる。

### 定義
SegNetは、VGG16ベースのエンコーダで特徴抽出とダウンサンプリングを行い、対称的なデコーダでアップサンプリングしてピクセル単位のクラス予測を行うセマンティックセグメンテーションモデル。最大プーリング時のインデックスを記憶・再利用することで、空間情報を効率的に保持する。

### 重要キーワード
- **セマンティックセグメンテーション**: ピクセル単位で各領域のクラスを予測
- **エンコーダ-デコーダ構造**: 圧縮→復元の対称的なネットワーク
- **最大プーリングインデックス**: プーリングで選ばれた最大値の位置情報
- **アンプーリング（Unpooling）**: プーリングの逆操作、保存したインデックスで復元
- **U-Net**: スキップ結合を使う類似アーキテクチャ
- **FCN（Fully Convolutional Network）**: 全結合層を畳み込み層に置き換えたセグメンテーション手法

### 詳細（教科書風）

#### 背景
セマンティックセグメンテーションでは、空間解像度を保ちながら特徴抽出を行う必要がある。SegNetは2015年に提案され、プーリングインデックスの記憶により、メモリ効率と境界精度を両立。

#### アーキテクチャ

**エンコーダ**:
1. **特徴抽出**: VGG16の畳み込み層を使用
2. **最大プーリング**: ダウンサンプリングと同時に最大値の位置インデックスを記憶
3. **段階的圧縮**: 解像度を1/2ずつ削減

**デコーダ**:
1. **アンプーリング**: 記憶したインデックスを使い、元の位置に値を配置
2. **畳み込み**: アンプーリング後に畳み込みで特徴を復元
3. **段階的復元**: エンコーダと対称的に解像度を2倍ずつ拡大

#### 図解（アーキテクチャ）
```
エンコーダ                          デコーダ
入力画像                            出力（クラスマップ）
  ↓                                    ↑
Conv+ReLU ──────インデックス記憶──→ Upconv+ReLU
  ↓                                    ↑
MaxPool (1/2) ──インデックス保存──→ Unpooling
  ↓                                    ↑
Conv+ReLU ──────インデックス記憶──→ Upconv+ReLU
  ↓                                    ↑
MaxPool (1/4) ──インデックス保存──→ Unpooling
  ↓                                    ↑
   ... (繰り返し)                     ...
  ↓                                    ↑
特徴ベクトル ─────────────────→ 復元開始
```

#### プーリングインデックスの仕組み
```
元の特徴マップ (4×4)     MaxPooling (2×2)
[1  3  2  8]             [3  8]  + インデックス: [(0,1), (0,3)]
[0  2  4  1]             [5  9]                   [(1,0), (1,3)]
[5  1  0  2]
[2  0  9  1]

Unpooling時に元の位置に配置:
[0  3  0  8]
[5  0  0  1]  ← 空白は0埋め or 後続の畳み込みで補完
[0  0  0  0]
[0  0  9  0]
```

#### 主な特徴
- **メモリ効率**: 特徴マップ全体ではなくインデックスのみ保存（U-Netより軽量）
- **境界保存**: プーリング位置を正確に復元し、物体境界を精密に再現
- **対称性**: エンコーダとデコーダが完全対称

### 試験での問われ方

#### 典型設問
- **「最大プーリングの位置を記憶するセグメンテーション手法」→SegNet**
- **「エンコーダとデコーダが対になっている」→SegNet、U-Net**
- **「セマンティックセグメンテーションに利用される」→SegNet、U-Net、FCN、DeepLab**
- エンコーダ-デコーダ構造の利点
- U-Net、FCNとの違い

#### ひっかけポイントと違いの整理

| 項目 | SegNet | U-Net | FCN | DeepLab |
|------|--------|-------|-----|---------|
| **構造** | エンコーダ-デコーダ | エンコーダ-デコーダ | 全畳み込み | 拡張畳み込み |
| **特徴** | プーリングインデックス記憶 | スキップ結合 | 転置畳み込み | Atrous Convolution |
| **メモリ** | 効率的 | やや多い | 中程度 | 中程度 |
| **境界精度** | 高 | 非常に高 | 中 | 高 |
| **用途** | 自動運転、屋外シーン | 医療画像 | 一般的 | 一般的・高精度 |

**混同注意**:
- **SegNet vs U-Net**: SegNetはインデックス記憶、U-Netは特徴マップ全体をスキップ結合
- **SegNet vs FCN**: SegNetはインデックス利用、FCNは転置畳み込みでアップサンプリング
- **セマンティック vs インスタンスセグメンテーション**: セマンティックは同じクラスを区別しない、インスタンスは個別に識別（Mask R-CNN等）

**出題パターン**:
- 「エンコーダで最大プーリングした位置を記憶」→**SegNet**
- 「スキップ結合で特徴マップを結合」→**U-Net**
- 「全結合層を畳み込み層に置き換え」→**FCN**
- 「医療画像セグメンテーションで広く使われる」→**U-Net**

### 補足

#### 実務観点
- **用途**: 自動運転（道路・歩行者領域分割）、衛星画像解析、ロボットビジョン
- **実装**: Keras、PyTorchで実装可能。VGG16の事前学習重みが利用可能
- **後継**: PSPNet、DeepLabV3等でさらに高精度化
- **課題**: 小物体の検出、クラス不均衡への対応

#### U-Netとの使い分け
- **SegNet**: メモリ制約がある場合、リアルタイム処理
- **U-Net**: 高精度が必要な場合（医療画像）、学習データが少ない場合

#### 関連トピック
- [CNN](../06_deep_learning/cnn.md) - ベースとなる畳み込みネットワーク
- [評価指標](../05_machine_learning/evaluation_metrics.md) - IoU（Intersection over Union）

---

## 試験での問われ方（画像認識全般）
- **AlexNet/VGGNet/ResNet**: 代表的CNNアーキテクチャの特徴と年代
- **物体検出手法の分類**: ワンステージ（YOLO、SSD）vsツーステージ（R-CNN系）
- **転移学習**: ImageNet事前学習モデルの利用メリット
- **データ拡張**: 過学習対策としての有効性

### 引っ掛けポイント
- **分類vs検出vsセグメンテーション**: タスクの違いを明確に（分類は画像全体、検出は矩形、セグメンテーションはピクセル単位）
- **精度vs速度**: リアルタイム要求ならYOLO/SSD、高精度ならFaster R-CNN
- **転移学習の前提**: ドメインが近いほど効果大（医療画像→自然画像は難）

## 補足（画像認識全般）
- **実務課題**: 学習データの質・量、クラス不均衡、未知物体への対応、計算コスト
- **最新動向**: Vision Transformer（ViT）、DETR（Transformerベース物体検出）、自己教師あり学習
- **評価指標**: 分類は精度・F1、検出はmAP（mean Average Precision）、セグメンテーションはIoU（Intersection over Union）
