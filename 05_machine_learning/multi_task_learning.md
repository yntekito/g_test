# マルチタスク学習（Multi-Task Learning）

## 要点
- **複数の関連タスクを同時に学習**し、タスク間の共通知識を共有することで各タスクの性能を向上させる手法
- **共有表現（Shared Representation）**を学習し、タスク固有の層で各タスクの出力を生成。データ効率と汎化性能が向上
- 画像認識（物体検出+セグメンテーション）、自然言語処理（複数言語の翻訳）等で広く活用

## 定義
マルチタスク学習（Multi-Task Learning, MTL）は、複数の関連するタスクを同時に学習する機械学習の手法。単一のモデルで複数のタスクを扱い、タスク間で知識（特徴表現や重み）を共有することで、各タスクの学習を相互に補強し、汎化性能を向上させる。「複数のタスクを同時に学ぶことで、より良い汎化が得られる」という帰納バイアスに基づく。

---

## マルチタスク学習の基本原理

### 背景と直観

**人間の学習との類似**:
人間は複数の関連スキルを同時に学ぶことで、より効率的に学習できます。例えば：
- **言語学習**: 英語を学ぶとき、読む・書く・話す・聞くを同時に学ぶ方が、各スキルを別々に学ぶより効果的
- **スポーツ**: テニスとバドミントンを同時に練習すると、ラケットスポーツの共通技術が身につく
- **楽器**: ピアノとオルガンを学ぶと、鍵盤楽器の共通知識が活用できる

**AIでの応用**:
関連するタスク間で**共通の特徴表現**を学習することで：
- データが少ないタスクでも、他のタスクから知識を借りて学習できる
- 共通の特徴が強化され、各タスクの汎化性能が向上
- 過学習を抑制（共有表現が正則化として機能）

---

## マルチタスク学習のアーキテクチャ

### 基本構造（ハードパラメータ共有）

最も一般的な構造は**ハードパラメータ共有（Hard Parameter Sharing）**:

```
入力（例：画像）
     ↓
┌────────────────┐
│  共有層         │ ← 全タスクで共通の特徴抽出
│  (Shared Layers)│    畳み込み層、エンコーダ等
└────────────────┘
     ↓
  ┌──┴──┬──────┐
  ↓     ↓      ↓
┌────┐┌────┐┌────┐
│タスク││タスク││タスク│ ← タスク固有の層
│ 1  ││ 2  ││ 3  │    各タスク専用の出力層
└────┘└────┘└────┘
  ↓     ↓      ↓
出力1  出力2  出力3
（例：物体検出、セグメンテーション、姿勢推定）
```

**特徴**:
- 下層（共有層）で共通の特徴を学習
- 上層（タスク固有層）で各タスク専用の処理
- パラメータの大部分を共有し、効率的

---

### ソフトパラメータ共有（Soft Parameter Sharing）

各タスクが独自のモデルを持ち、パラメータ間の距離を正則化で制約：

```
タスク1モデル    タスク2モデル    タスク3モデル
    ↓              ↓              ↓
   W₁  ←─制約─→  W₂  ←─制約─→  W₃
   
制約: ||W₁ - W₂||² + ||W₂ - W₃||² を最小化
```

**特徴**:
- 各タスクが独立したモデルを持つ
- 正則化により類似したパラメータを学習
- タスク間の独立性が高い場合に有効

---

## マルチタスク学習の利点

**優先順（主目的から順に）**:
1. **汎化性能の向上** - 過学習抑制、より良い一般化（最重要）
2. **データ効率の向上** - 少ないデータでも高性能（最重要）
3. **表現学習の改善** - より頑健で汎用的な特徴
4. **計算効率（推論時のみ）** - 副次的効果

**重要な誤解の訂正**:
- ✅ **学習データの効率的な利用** = 主目的
- ❌ **学習時間の短縮** = 目的ではない（むしろ複数タスク同時学習で時間増加）
- ○ **推論速度の向上** = 副次的効果（個別モデル複数より速い）

### 1. データ効率の向上（Data Efficiency）★主目的

**効果**: 少ないデータでも高性能を達成

**メカニズム**:
- タスクAのデータでタスクBの学習を補助
- 共有層が複数タスクのデータで訓練され、豊富なデータで学習した効果
- データが少ないタスクが、データ豊富なタスクから知識を「借りる」

**例**:
```
単一タスク学習:
- タスクA: 1000サンプル → 精度80%
- タスクB: 500サンプル → 精度70%（データ不足）

マルチタスク学習:
- タスクA+B: 合計1500サンプル
  → タスクA: 精度82%
  → タスクB: 精度76%（他タスクの知識を活用）

データ効率: タスクBは実質的に1500サンプル分の知識で学習
```

**学習時間について**:
- 複数タスクを同時に学習するため、単一タスク学習より時間がかかる
- しかし、個別に複数モデルを訓練するよりは短い
- **学習時間短縮は目的ではない**

---

### 2. 汎化性能の向上（Improved Generalization）

**効果**: 過学習を抑制し、テストデータでの性能向上

**メカニズム**:
- **帰納バイアスの強化**: 複数タスクに共通する特徴を優先的に学習
- **正則化効果**: タスクAの学習がタスクBの過学習を防ぐ
- **ノイズの平滑化**: 各タスクのノイズが他タスクで相殺

**理論的背景**:
単一タスクは特定データセットに過適合しやすいが、複数タスクを同時に解くことで、より一般的な表現を学習せざるを得ない。

---

### 3. 表現学習の改善（Better Representation Learning）

**効果**: より汎用的で頑健な特徴表現を獲得

**メカニズム**:
- **多様な信号**: 各タスクの勾配が異なる側面から特徴を更新
- **冗長性の削減**: 複数タスクに有用な特徴のみが残る
- **転移学習への適用**: 学習した共有表現を新しいタスクに転用可能

**例**: 画像認識での共有層
```
タスク1（物体検出）: エッジ、形状を重視
タスク2（セグメンテーション）: 領域の境界を重視
タスク3（姿勢推定）: 人体の構造を重視

→ 共有層は全てに有用な「頑健なエッジ検出」「スケール不変特徴」等を学習
```

---

### 4. 計算効率（Computational Efficiency）★副次的効果・推論時のみ

**重要**: これは副次的なメリットであり、マルチタスク学習の主目的ではない

**推論時の効果**: 個別モデルより少ないパラメータ・計算量で推論高速化

**メカニズム**:
- 1つの統合モデルで複数タスクを処理
- 共有層を再利用するため、個別モデルを複数動かすより効率的
- パラメータ数削減により、メモリ使用量も削減

**数値例**:
```
個別学習（推論時）: 
- タスク1モデル: 10Mパラメータ
- タスク2モデル: 10Mパラメータ
- タスク3モデル: 10Mパラメータ
合計: 30Mパラメータ、推論3回

マルチタスク学習（推論時）:
- 共有層: 8Mパラメータ
- タスク固有層: 各2M × 3 = 6M
合計: 14Mパラメータ（53%削減）、推論1回で全タスク完了
→ 推論速度が個別モデルの2～3倍高速
```

**学習時の効率について**:
```
個別学習（学習時）:
- タスク1: 10エポック × 1時間 = 10時間
- タスク2: 10エポック × 1時間 = 10時間
- タスク3: 10エポック × 1時間 = 10時間
合計: 30時間（並列実行なら10時間）

マルチタスク学習（学習時）:
- 全タスク同時: 15エポック × 1.5時間 = 22.5時間
→ 個別逐次より速いが、並列実行よりは遅い
→ 複数タスクの勾配計算・バランス調整で時間増加
```

**重要な整理**:
- ✅ **推論速度は向上**（副次的効果）
- ❌ **学習時間の短縮は目的ではない**（むしろ複雑化）
- ✅ **データ効率が主目的**（少ないデータで高性能）

**注意点**:
- **速度が主目的なら他の手法を検討**: プルーニング、量子化、軽量アーキテクチャ（MobileNet等）の方が適切
- マルチタスク学習の本質は「**タスク間の知識共有による性能向上**」
- 推論速度の向上は、結果として得られる副次的なメリット

---

## マルチタスク学習の実例

### 画像認識での応用★試験頻出

**自動運転の認識システム**:
```
入力: 車載カメラ画像
   ↓
[共有CNN層]
   ↓
┌──┴──┬──────┬──────┐
↓     ↓      ↓      ↓
物体検出 車線検出 交通標識認識 距離推定
```

**効果**:
- 道路の特徴（エッジ、テクスチャ）を共有
- 各タスクが相互に精度向上
- 推論速度が個別モデルの3倍高速

---

**物体検出 + セグメンテーション（Mask R-CNN）**:
```
入力画像
   ↓
[ResNetバックボーン（共有）]
   ↓
┌──┴──┬──────┐
↓     ↓      ↓
BBox  クラス  マスク
検出  分類   セグメンテーション
```

**効果**: 物体の位置情報とピクセル単位の領域が相互に改善

---

### 自然言語処理での応用

**多言語機械翻訳（Multilingual Translation）**:
```
入力: 英語文
   ↓
[共有Encoder]
   ↓
┌──┴──┬──────┐
↓     ↓      ↓
仏語  独語   日本語
Decoder Decoder Decoder
```

**効果**:
- 言語横断的な意味表現を学習
- データの少ない言語でも高精度（低リソース言語対応）

---

**BERT等の事前学習モデル**:
```
タスク1: マスク言語モデル（穴埋め）
タスク2: 次文予測（文の順序判定）
→ 同時学習により高品質な言語表現を獲得
```

---

### 音声処理

**音声認識 + 話者識別 + 感情認識**:
```
入力: 音声波形
   ↓
[共有音響特徴抽出]
   ↓
┌──┴──┬──────┬──────┐
↓     ↓      ↓
音声認識 話者識別 感情認識
```

---

## マルチタスク学習の課題

### 1. タスク間の干渉（Negative Transfer）

**問題**: タスク間の関連が弱い場合、逆に性能が低下

**原因**:
- 無関係なタスクを同時学習すると、共有表現が中途半端になる
- タスクAの最適解がタスクBの最適解と矛盾

**例**:
```
良い組み合わせ: 犬の品種分類 + 犬の年齢推定（共に犬の特徴が重要）
悪い組み合わせ: 犬の分類 + 音声認識（関連性が薄い）
```

**対策**:
- タスクの関連性を事前に評価
- タスクのグループ化（関連タスクのみを組み合わせる）
- 適応的なパラメータ共有

---

### 2. タスクバランスの調整

**問題**: タスク間の難易度や損失のスケールが異なり、特定タスクの学習が支配的になる

**損失関数**:
$$L_{total} = \lambda_1 L_1 + \lambda_2 L_2 + \lambda_3 L_3$$

**課題**:
- $\lambda_i$（タスクの重み）の設定が困難
- タスク1の損失が大きいと、タスク2, 3の学習が進まない

**対策**:
- **動的重み調整**: 学習中に損失の大きさに応じて $\lambda_i$ を自動調整
- **勾配の正規化**: 各タスクの勾配を正規化して等しく扱う
- **不確実性ベースの重み**: 各タスクの不確実性を考慮した重み設定

**アルゴリズム例**:
```
GradNorm: 各タスクの勾配ノルムを均等化
1. 各タスクの勾配を計算
2. 勾配ノルムを計算: ||∇L₁||, ||∇L₂||, ||∇L₃||
3. 重みを調整して勾配を均等化: λᵢ ← λᵢ × (||∇Lᵢ|| の逆数)
```

---

### 3. タスク固有層の設計

**問題**: どこまで共有し、どこからタスク固有にするかの設計が困難

**選択肢**:
- **浅い共有**: 初期層のみ共有（汎用的特徴）
- **深い共有**: 深い層まで共有（タスク特化特徴も共有）

**設計指針**:
- タスクが似ている → 深い層まで共有
- タスクが異なる → 浅い層のみ共有
- 実験的に最適な構造を探索（NAS等）

---

## マルチタスク学習 vs 転移学習 vs 単一タスク学習

| 項目 | 単一タスク学習 | 転移学習 | マルチタスク学習 |
|------|---------------|---------|----------------|
| **学習タスク数** | 1つ | 1つずつ順次 | 複数同時 |
| **知識の共有** | なし | 事前学習タスク→目標タスク | 全タスク間で相互共有 |
| **学習方法** | タスク専用データで学習 | 事前学習→ファインチューニング | 全タスクを同時に学習 |
| **データ効率** | 低 | 高 | 高 |
| **適用場面** | データ豊富 | データ不足の目標タスク | 関連タスクが複数 |
| **代表例** | ImageNet分類のみ | ImageNet事前学習→医療画像 | 物体検出+セグメンテーション |

**重要な違い**:
- **転移学習**: タスクAを学習→タスクBにファインチューニング（**逐次的**）
- **マルチタスク学習**: タスクA, B, Cを**同時に**学習

---

## 重要キーワード

- **マルチタスク学習（Multi-Task Learning, MTL）**: 複数タスクを同時に学習
- **共有表現（Shared Representation）**: タスク間で共有される特徴表現
- **ハードパラメータ共有（Hard Parameter Sharing）**: 層を物理的に共有
- **ソフトパラメータ共有（Soft Parameter Sharing）**: パラメータ間の距離を制約
- **帰納バイアス（Inductive Bias）**: 複数タスクに共通する知識を優先
- **正則化効果（Regularization Effect）**: 過学習を抑制
- **負の転移（Negative Transfer）**: タスク間の干渉による性能低下
- **タスクバランス（Task Balancing）**: 各タスクの損失の重み調整
- **データ効率（Data Efficiency）**: 少ないデータで高性能

---

## 試験での問われ方

### 典型的な出題パターン

1. **定義の確認**: 「マルチタスク学習の説明として適切なものは？」
   → **複数の関連タスクを同時に学習し、タスク間で知識を共有**
   
2. **利点**: 「マルチタスク学習の利点は？」
   → **データ効率向上、汎化性能向上、過学習抑制**
   
3. **転移学習との違い**: 「転移学習との違いは？」
   → **マルチタスクは同時学習、転移学習は逐次学習**
   
4. **応用例**: 「マルチタスク学習が使われる例は？」
   → **自動運転（物体検出+車線検出）、多言語翻訳**
   
5. **共有表現**: 「共有層の役割は？」
   → **全タスクに共通する特徴を学習**

### ひっかけポイントと違いの整理

**マルチタスク学習 vs 転移学習**（最重要）:

| 記述 | マルチタスク | 転移学習 |
|------|------------|---------|
| 複数タスクを同時に学習 | ◎ 正解 | ✗ 逐次 |
| タスクを順次学習 | ✗ 同時 | ◎ 正解 |
| 事前学習→ファインチューニング | ✗ | ◎ 正解 |
| タスク間で相互に知識共有 | ◎ 正解 | △ 一方向 |

**選択肢で出やすい正解パターン**:
- ✅ 「複数の関連タスクを同時に学習する」
- ✅ 「タスク間で共有表現を学習する」
- ✅ 「データ効率と汎化性能が向上する」
- ✅ 「物体検出とセグメンテーションを同時に学習する」
- ✅ 「共有層で共通特徴、タスク固有層で各タスクの出力」

**選択肢で出やすい誤答パターン**:
- ❌ 「事前学習したモデルを別タスクに転用」→ 転移学習の説明
- ❌ 「タスクを順次学習する」→ 転移学習
- ❌ 「単一タスクを複数のモデルで学習」→ アンサンブル学習
- ❌ 「複数のモデルの予測を統合」→ アンサンブル学習
- ❌ 「データを複数のグループに分けて学習」→ データ分割

**混同注意**:

| 手法 | 説明 | タスク数 | 学習方法 |
|------|------|---------|---------|
| **マルチタスク学習** | 複数タスクを同時学習 | 複数 | 同時 |
| **転移学習** | 学習済みモデルを転用 | 1つずつ | 逐次 |
| **アンサンブル学習** | 複数モデルで同一タスク | 1つ | 並列（複数モデル） |
| **メタ学習** | 学習方法自体を学習 | 複数 | タスク横断 |

**実例での識別**:
- 「ImageNetで事前学習→医療画像で再学習」→ **転移学習**
- 「物体検出とセグメンテーションを1つのモデルで同時学習」→ **マルチタスク学習**
- 「複数のモデルで物体検出し、結果を投票」→ **アンサンブル学習**

---

## 補足

### 実務での活用

**効果的な場面**:
- **関連タスクが複数**: 自動運転、医療診断、ロボット制御
- **データ不足のタスクがある**: 豊富なタスクから知識を借りる
- **計算リソース制約**: 複数の個別モデルを動かせない環境

**実装フレームワーク**:
- **PyTorch**: 共有層+複数のタスクヘッド（比較的容易に実装）
- **TensorFlow/Keras**: Functional APIで複数出力を定義
- **専用ライブラリ**: LibMTL, Multi-Task Learning Toolkit

**実装例（PyTorch風擬似コード）**:
```python
class MultiTaskModel(nn.Module):
    def __init__(self):
        # 共有層
        self.shared_layers = ResNet50(pretrained=True)
        
        # タスク固有層
        self.task1_head = nn.Linear(2048, 10)  # 分類
        self.task2_head = nn.Linear(2048, 1)   # 回帰
        self.task3_head = nn.Conv2d(2048, 21, 1)  # セグメンテーション
    
    def forward(self, x):
        # 共有特徴抽出
        features = self.shared_layers(x)
        
        # 各タスクの出力
        out1 = self.task1_head(features)
        out2 = self.task2_head(features)
        out3 = self.task3_head(features)
        
        return out1, out2, out3

# 損失関数（重み付き和）
loss = λ1 * loss_task1 + λ2 * loss_task2 + λ3 * loss_task3
```

### 最新動向

**タスク関連性の自動推定**:
- どのタスクを組み合わせると効果的かを自動判定
- タスクのグループ化（クラスタリング）

**動的アーキテクチャ**:
- Neural Architecture Search（NAS）でマルチタスク構造を自動設計
- タスクごとに異なる層を動的に選択

**メタ学習との統合**:
- Few-shot Learningとの組み合わせ
- タスク間の転移を効率化

### 理論的背景

**正則化としてのマルチタスク学習**:
複数タスクを解くという制約が、暗黙的に正則化として機能：
$$\min_{\theta} \sum_{i=1}^{T} L_i(\theta) \quad \text{s.t.} \quad \theta \text{ works well for all tasks}$$

**ベイズ的解釈**:
各タスクを条件とする事後分布の積を最大化：
$$p(\theta | D_1, D_2, ..., D_T) \propto p(D_1|\theta) \cdot p(D_2|\theta) \cdot ... \cdot p(D_T|\theta) \cdot p(\theta)$$

### 関連トピック

- [転移学習](../06_deep_learning/) - 事前学習とファインチューニング
- [アンサンブル学習](ensemble_learning.md) - 複数モデルの統合
- [過学習対策](overfitting_underfitting.md) - マルチタスクの正則化効果
- [CNNアーキテクチャ](../06_deep_learning/cnn.md) - 共有層の設計
- [メタ学習](../06_deep_learning/) - 学習方法の学習
