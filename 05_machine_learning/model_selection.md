# モデル選択とハイパーパラメータチューニング

## 要点
- **AIC（赤池情報量規準）**と**BIC（ベイズ情報量規準）**は、モデルの複雑さと予測精度のバランスを評価する情報量規準。
- AICはパラメータ数にペナルティを課し、過学習を防ぐ。BICはサンプル数も考慮し、よりシンプルなモデルを選択しやすい。
- モデル選択では、訓練精度だけでなく汎化性能を重視し、交差検証や情報量規準を併用する。

---

## 定義

**モデル選択（Model Selection）**は、複数の候補モデルの中から、最も適切なモデルを選択するプロセス。単に訓練データでの精度が高いモデルではなく、未知データへの**汎化性能**が高いモデルを選ぶことが目的。

---

## 重要キーワード

- **AIC（赤池情報量規準：Akaike Information Criterion）**：モデルの尤度とパラメータ数のバランスを評価。値が小さいほど良い。
- **BIC（ベイズ情報量規準：Bayesian Information Criterion）**：AICにサンプル数の項を追加。大規模データでよりシンプルなモデルを選択。
- **情報量規準（Information Criterion）**：モデルの良さを数値化する指標。AIC、BIC、AICc等。
- **尤度（Likelihood）**：モデルがデータを説明する度合い。高いほど良い。
- **パラメータ数**：モデルの複雑さを表す指標。多いほど過学習リスク増加。
- **汎化性能（Generalization Performance）**：未知データへの予測精度。
- **ハイパーパラメータ**：学習前に設定するパラメータ（学習率、正則化係数等）。
- **グリッドサーチ（Grid Search）**：ハイパーパラメータの全組み合わせを試す手法。
- **ランダムサーチ（Random Search）**：ランダムにハイパーパラメータを試す手法。

---

## 詳細

### 情報量規準（AIC・BIC）

#### AIC（赤池情報量規準）★試験頻出

**定義**：
1973年に赤池弘次が提案した、モデルの良さを評価する指標。**モデルの尤度（フィット度）**と**パラメータ数（複雑さ）**のバランスを取る。

**計算式**：
$$\text{AIC} = -2 \log L + 2k$$

- $L$：最大尤度（モデルがデータを説明する度合い）
- $k$：パラメータ数（モデルの複雑さ）
- **小さいほど良いモデル**

**直感的な意味**：
```
AIC = データへのフィット度（-2logL：小さいほど良い）
      + 複雑さペナルティ（2k：パラメータ数が多いほど大きい）
```

**特徴**：
- ✅ **バランス評価**：精度と複雑さのトレードオフを定量化
- ✅ **過学習防止**：パラメータ数にペナルティを課す
- ✅ **モデル間比較**：異なるモデルを同じ尺度で比較可能
- ✅ **理論的基盤**：情報理論に基づく厳密な導出
- ❌ **相対的な指標**：絶対的な良し悪しは判断できない（相対比較のみ）

**使い方**：
```
【候補モデル】
モデルA：AIC = 1200（パラメータ数：10）
モデルB：AIC = 1150（パラメータ数：5）
モデルC：AIC = 1180（パラメータ数：15）

【選択】
AICが最小のモデルB を選択
→ モデルBは精度と簡潔さのバランスが最良
```

---

#### BIC（ベイズ情報量規準）

**定義**：
AICの改良版で、**サンプル数**も考慮してペナルティを調整する情報量規準。

**計算式**：
$$\text{BIC} = -2 \log L + k \log n$$

- $L$：最大尤度
- $k$：パラメータ数
- $n$：サンプル数
- **小さいほど良いモデル**

**AICとの違い**：

| 項目 | AIC | BIC |
|------|-----|-----|
| ペナルティ項 | $2k$ | $k \log n$ |
| サンプル数依存 | なし | **あり** |
| ペナルティの強さ | 小さい（$n > 8$の時） | **大きい**（$n > 8$の時） |
| 傾向 | やや複雑なモデル | **よりシンプルなモデル** |
| 用途 | 予測精度重視 | モデルの簡潔性重視 |

**特徴**：
- ✅ 大規模データで過学習をより強く抑制
- ✅ AICより保守的（シンプルなモデルを選びやすい）
- ❌ 小規模データでは過度にシンプルなモデルを選ぶ可能性

**実例**：
```
サンプル数 n = 100、パラメータ数 k = 5

【AICのペナルティ】
2k = 2 × 5 = 10

【BICのペナルティ】
k log n = 5 × log(100) ≈ 5 × 4.6 ≈ 23

→ BICの方がペナルティが大きい（約2.3倍）
→ BICはよりシンプルなモデルを選択
```

---

#### AICc（補正AIC）

**定義**：
小規模データ（サンプル数が少ない場合）用のAIC補正版。

**計算式**：
$$\text{AICc} = \text{AIC} + \frac{2k(k+1)}{n-k-1}$$

**特徴**：
- サンプル数が少ない時に過学習を防ぐ補正
- $n \to \infty$ で通常のAICに収束
- $n < 40k$ の場合はAICcを使用すべき

---

### モデル選択の典型問題（★試験頻出）

> 「機械学習のモデル設計において、モデルの複雑さと予測精度のバランスについての指標として、最も適切な選択肢を1つ選べ。」

✅ **正解の選択肢**：
- **AIC（赤池情報量規準）**
- **BIC（ベイズ情報量規準）**
- **情報量規準**
- **AICc（補正AIC）**

❌ **不適切な選択肢（混同注意）**：

**1. 精度のみを評価する指標**：
- **正解率（Accuracy）**：複雑さを考慮しない（訓練精度のみ）
- **F1スコア**：予測性能のみ評価、複雑さは考慮しない
- **再現率・適合率**：複雑さのバランスは評価しない

**2. 複雑さのみの指標**：
- **パラメータ数**：精度を考慮しない
- **モデルの深さ**：精度とのバランスは評価しない

**3. 他の評価手法**：
- **交差検証（Cross-validation）**：汎化性能を評価するが、「モデルの複雑さと精度のバランス」を明示的に数値化する指標ではない
- **混同行列**：分類性能の内訳、複雑さは考慮しない
- **ROC-AUC**：分類性能の指標、複雑さは考慮しない

**4. 損失関数**：
- **MSE（平均二乗誤差）**：訓練誤差のみ、複雑さペナルティなし
- **クロスエントロピー**：予測誤差のみ評価

---

### ひっかけポイント

| ひっかけ | 正しい理解 |
|----------|------------|
| ❌ 「交差検証がモデル複雑さとのバランス指標」 | ✅ 交差検証は汎化性能評価。**AIC/BIC**が複雑さとのバランス指標 |
| ❌ 「正解率が高いモデルが最良」 | ✅ 複雑すぎると過学習。**AIC/BIC**でバランス評価 |
| ❌ 「パラメータ数が少ないほど良い」 | ✅ 単純すぎると学習不足。**AIC/BIC**でバランス |
| ❌ 「AICが大きいほど良い」 | ✅ AICは**小さいほど良い** |
| ✅ 「AICはパラメータ数にペナルティ」 | ✅ 正しい（$2k$のペナルティ項） |
| ✅ 「BICはAICより保守的」 | ✅ 正しい（ペナルティが大きい） |

---

### AIC/BICの実例

**実例：線形回帰のモデル選択**

```
【データ】
住宅価格予測（サンプル数 n = 100）

【候補モデル】
モデル1：y = a₁x₁ + b（パラメータ数 k=2）
モデル2：y = a₁x₁ + a₂x₂ + b（k=3）
モデル3：y = a₁x₁ + a₂x₂ + a₃x₃ + a₄x₄ + b（k=5）

【計算】
モデル1：尤度 -2logL = 1000、AIC = 1000 + 2×2 = 1004
モデル2：尤度 -2logL = 950、AIC = 950 + 2×3 = 956
モデル3：尤度 -2logL = 940、AIC = 940 + 2×5 = 950

【選択】
AICが最小のモデル3を選択
→ 4つの特徴量を使うモデルが最適

【BICで比較】
モデル2：BIC = 950 + 3×log(100) ≈ 950 + 14 = 964
モデル3：BIC = 940 + 5×log(100) ≈ 940 + 23 = 963

BICではモデル3がわずかに良いが、差が小さい
→ サンプル数に対してモデル3はやや複雑かも
```

---

### 情報量規準の使い分け

| 状況 | 推奨指標 | 理由 |
|------|---------|------|
| **標準的なケース** | AIC | バランスが良い、広く使われる |
| **大規模データ** | BIC | 過学習をより強く抑制 |
| **小規模データ** | AICc | サンプル数少ない時の補正 |
| **予測精度重視** | AIC | ペナルティが小さい |
| **モデル簡潔性重視** | BIC | ペナルティが大きい |
| **時系列モデル** | AIC | ARIMAモデル選択で標準 |

---

## ハイパーパラメータチューニング

### ハイパーパラメータとは

**定義**：
学習前に人間が設定するパラメータ。学習中に更新されるモデルパラメータ（重み）とは異なる。

**代表例**：
- 学習率（Learning Rate）
- 正則化係数（λ）
- 決定木の深さ（Max Depth）
- ニューラルネットワークの層数
- K-meansのクラスタ数（K）
- SVMのカーネル種類

---

### グリッドサーチ（Grid Search）

**定義**：
ハイパーパラメータの全ての組み合わせを網羅的に試す手法。

**プロセス**：
```
【設定】
学習率：[0.001, 0.01, 0.1]
正則化係数：[0.1, 1.0, 10.0]

【全組み合わせ】
(0.001, 0.1), (0.001, 1.0), (0.001, 10.0),
(0.01, 0.1), (0.01, 1.0), (0.01, 10.0),
(0.1, 0.1), (0.1, 1.0), (0.1, 10.0)
→ 計9通り

【評価】
各組み合わせで交差検証を実行
最も性能が良い組み合わせを選択
```

**特徴**：
- ✅ 全探索なので最適解を見逃さない
- ✅ 実装が簡単
- ❌ 計算コストが高い（組み合わせ爆発）
- ❌ パラメータが増えると現実的でない

---

### ランダムサーチ（Random Search）

**定義**：
ハイパーパラメータをランダムにサンプリングして試す手法。

**特徴**：
- ✅ グリッドサーチより高速
- ✅ 重要なパラメータを効率的に探索
- ✅ 高次元パラメータ空間でも有効
- ❌ 最適解を見逃す可能性

**比較**：
```
【グリッドサーチ】
10パラメータ、各3値 → 3¹⁰ = 59,049通り

【ランダムサーチ】
100回ランダムサンプリング → 100通り
→ 計算量1/590に削減、精度もほぼ同等
```

---

### ベイズ最適化（Bayesian Optimization）

**定義**：
過去の評価結果を活用し、効率的にハイパーパラメータを探索する手法。

**特徴**：
- ✅ 少ない試行回数で最適解に到達
- ✅ 計算コストの高いモデルに有効
- ❌ 実装がやや複雑

---

## 試験での問われ方

### 典型的な出題パターン

**パターン1：情報量規準の説明**

> 「AICに関する説明として、最も適切な選択肢を1つ選べ。」

✅ **正解**：
- **モデルの尤度とパラメータ数のバランスを評価する指標**
- **値が小さいほど良いモデル**
- **パラメータ数にペナルティを課すことで過学習を防ぐ**
- **赤池弘次が提案した情報量規準**

❌ **不正解**：
- 「値が大きいほど良い」→ 誤り（小さいほど良い）
- 「パラメータ数のみを評価」→ 誤り（尤度も考慮）
- 「訓練精度のみを評価」→ 誤り（複雑さも考慮）

---

**パターン2：AIC vs BIC**

> 「AICとBICの違いとして、最も適切な選択肢を1つ選べ。」

✅ **正解**：
- **BICはサンプル数も考慮する**
- **BICの方がペナルティが大きい（n>8の場合）**
- **BICはよりシンプルなモデルを選択しやすい**

---

**パターン3：モデル選択の指標**

> 「モデルの複雑さと予測精度のバランスを評価する指標として、最も適切なものを選べ。」

✅ **正解**：
- **AIC**
- **BIC**
- **情報量規準**

❌ **不正解**：
- 正解率（複雑さを考慮しない）
- 交差検証（汎化性能の評価、複雑さとのバランス指標ではない）
- MSE（誤差のみ）

---

## 補足：実務観点

### モデル選択の実務的アプローチ

**ステップ1：候補モデルの準備**
- 線形回帰、決定木、ランダムフォレスト、ニューラルネットワーク等

**ステップ2：交差検証で汎化性能評価**
- K-分割交差検証で各モデルの性能を評価

**ステップ3：情報量規準で比較**
- AIC/BICで複雑さと精度のバランスを確認

**ステップ4：最終選択**
- ビジネス要件（速度、解釈性、精度）も考慮して決定

---

### 注意点

**過度な最適化に注意**：
- テストデータでの評価を繰り返すと、テストデータへの過学習が起こる
- ホールドアウト検証セット（Validation Set）を別途用意

**計算コストとのトレードオフ**：
- グリッドサーチは時間がかかる
- ランダムサーチやベイズ最適化で効率化

**解釈性とのバランス**：
- AICで選ばれたモデルが最も複雑とは限らない
- ビジネス要件で解釈性が重要なら、多少精度を犠牲にしてもシンプルなモデルを選ぶ

---

## 関連トピック
- [評価指標](evaluation_metrics.md)：精度・再現率・F1スコア等の性能指標
- [過学習・汎化](overfitting_underfitting.md)：過学習の原因と対策
- [交差検証](cross_validation.md)：汎化性能の評価手法
- [正則化](../10_math_statistics/optimization.md)：L1/L2正則化によるモデル複雑さの制御

---

## 参考文献・出典
- 赤池弘次『情報量基準AICとは何か』（1973）
- 日本ディープラーニング協会G検定シラバス
- 『パターン認識と機械学習』（Bishop）
