# 過学習と汎化（Overfitting and Generalization）

## 要点
- **過学習（Overfitting）**: 訓練データに過度に適合し、未知データへの性能が低下。対策：正則化、Dropout、Early Stopping。
- **汎化（Generalization）**: 未知データに対する予測性能。訓練誤差と汎化誤差の差が汎化ギャップ。
- **ダブルディセント**: モデルサイズ増加で性能が一度悪化後、再び向上する現象。深層学習で観測される。

## 定義
**過学習（Overfitting）**は、モデルが訓練データの細かいノイズやパターンまで学習してしまい、未知のテストデータに対する予測性能（汎化性能）が低下する現象。**汎化（Generalization）**は、訓練データ以外の未知データに対してもモデルが正確に予測できる能力。

## 重要キーワード
- **過学習（Overfitting）**: 訓練データに過度に適合し汎化性能が低下
- **未学習（Underfitting）**: モデルが単純すぎて訓練データすら学習できない
- **汎化（Generalization）**: 未知データへの予測性能
- **汎化誤差（Generalization Error）**: テストデータでの誤差
- **汎化ギャップ（Generalization Gap）**: 訓練誤差とテスト誤差の差
- **バイアス-バリアンストレードオフ**: モデルの複雑さと汎化性能のバランス
- **正則化（Regularization）**: 過学習を防ぐための制約
- **Early Stopping**: 検証誤差が悪化し始めたら学習を停止
- **ダブルディセント（Double Descent）**: モデルサイズ増加で性能が一度悪化後に再向上する現象

## 詳細

### 過学習（Overfitting）

#### 定義と症状
モデルが訓練データの**ノイズや特異なパターン**まで記憶してしまい、本質的なパターンの学習が不十分な状態。

**典型的な症状**：
- 訓練誤差は非常に小さい（ほぼゼロ）
- テスト誤差は大きい（汎化性能が低い）
- 訓練誤差とテスト誤差の差が大きい

#### 図解：学習曲線
```
誤差
 ↑
 │         ┌─ テスト誤差（上昇）
 │        ╱
 │       ╱
 │      ╱    ← 過学習開始
 │     ╱
 │    ╱
 │   ╱  ＼─ 訓練誤差（減少）
 │  ╱     ＼_____
 │ ╱            ＼_____
 └─────────────────────→ エポック数
   最適な停止点↑
```

#### 過学習の原因
1. **モデルが複雑すぎる**: パラメータ数 >> データ数
2. **訓練データが少ない**: 十分な例がない
3. **訓練時間が長すぎる**: 過度に学習
4. **ノイズが多い**: データに誤りや外れ値が多い
5. **正則化不足**: 制約がない

### 未学習（Underfitting）

#### 定義
モデルが単純すぎて、訓練データのパターンすら十分に学習できない状態。

**典型的な症状**：
- 訓練誤差が大きい
- テスト誤差も大きい
- 両方の誤差が近い値

#### 未学習の原因
1. **モデルが単純すぎる**: 線形モデルで非線形データを学習
2. **特徴量が不足**: 重要な情報が欠けている
3. **訓練時間が短すぎる**: 学習が不十分
4. **正則化が強すぎる**: 過度な制約

### 汎化（Generalization）

#### 定義
訓練データで学習したモデルが、**未知のデータに対してもうまく機能する**能力。

#### 汎化性能の評価
- **訓練誤差**: 訓練データでの誤差
- **検証誤差**: ハイパーパラメータ調整用の誤差
- **テスト誤差**: 最終評価用の誤差（汎化誤差）

$$\text{汎化ギャップ} = \text{テスト誤差} - \text{訓練誤差}$$

汎化ギャップが小さいほど、モデルは汎化している。

### バイアス-バリアンストレードオフ

#### 定義
モデルの**バイアス（偏り）**と**バリアンス（分散）**のバランス。

**バイアス（Bias）**：
- モデルの単純さによる誤差
- 高バイアス → 未学習

**バリアンス（Variance）**：
- 訓練データへの過敏性による誤差
- 高バリアンス → 過学習

#### トレードオフの図
```
誤差
 ↑
 │  ＼              ╱
 │   ＼  総誤差   ╱
 │    ＼        ╱
 │     ＼      ╱
 │      ＼    ╱
 │       ＼  ╱  ← 最適な複雑さ
 │    バイアス
 │         ╲ ╱
 │          X
 │         ╱ ╲
 │   バリアンス
 │       ╱     ╲____
 └─────────────────────→ モデルの複雑さ
   単純    最適    複雑
 （未学習）      （過学習）
```

### ダブルディセント現象（Double Descent）

#### 定義（★試験重要）
**ダブルディセント**は、モデルサイズ（パラメータ数）や訓練時間を増やしていくと：
1. **最初は性能が向上**（未学習から脱却）
2. **ある点で性能が最悪化**（補間閾値：interpolation threshold）
3. **さらに増やすと再び性能が向上**（過パラメータ化領域）

という**U字型の性能変化が2回起こる**現象。

#### 典型的な質問形式
> 「学習初期は性能が上がるものの、次第に性能が悪化し、モデルサイズや訓練時間を増やすと再び性能が上がる現象のことを何と呼ぶか。」

✅ **正解**: **ダブルディセント（Double Descent）**

#### 3つの領域

```
テスト誤差
 ↑
 │ ＼                    ╱
 │  ＼     伝統的      ╱  近代的
 │   ＼    リスク曲線 ╱   リスク曲線
 │    ＼            ╱
 │     ＼          ╱
 │      ＼      ╱╲
 │       ＼    ╱  ╲
 │        ＼  ╱    ╲___
 │         ╲╱         ＼___
 └─────────────────────────→ モデルサイズ
   未学習   最適  臨界点  過パラメータ化
     ①      ②     ③        ④
```

**①未学習領域（Underparameterized）**：
- モデルが単純すぎて訓練データを学習できない
- 性能が低い

**②古典的な最適点**：
- バイアス-バリアンストレードオフの最適点
- 従来の機械学習理論で推奨される複雑さ

**③補間閾値（Interpolation Threshold）**：
- モデルが訓練データを完全に記憶できる境界
- **性能が最悪**になる点（過学習のピーク）
- パラメータ数 ≈ データ数

**④過パラメータ化領域（Overparameterized）**：
- モデルが非常に大きい（パラメータ数 >> データ数）
- 深層学習の実用領域
- **性能が再び向上**（暗黙の正則化が働く）

#### なぜダブルディセントが起こるのか

**従来の理論との矛盾**：
- 古典的理論：モデルが大きすぎると必ず過学習
- 現実：巨大な深層学習モデルは汎化性能が高い

**現在の理解**：
1. **補間閾値付近**：訓練データにぎりぎり適合しようとして不安定
2. **過パラメータ化領域**：
   - 解の空間が広く、「滑らかな解」を見つけやすい
   - 暗黙の正則化（Implicit Regularization）が働く
   - SGDが滑らかな最小値を選好

#### 訓練時間によるダブルディセント

モデルサイズだけでなく、**訓練時間（エポック数）**でも同様の現象が観測される：

```
テスト誤差
 ↑
 │                     ╱
 │     Early        ╱
 │     Stopping   ╱
 │      ↓       ╱
 │      ＼    ╱╲
 │       ＼  ╱  ╲
 │        ╲╱    ╲____
 └─────────────────────→ 訓練時間
   未学習   過学習  再向上
```

1. 初期：未学習
2. 中期：過学習（Early Stoppingで停止すべき点）
3. 後期：性能が再び向上

#### 実例

**深層学習での観測**：
- ResNet等の巨大モデルは訓練データを完全に記憶しても汎化性能が高い
- GPT-3（1750億パラメータ）は過学習せず高性能

**ランダムフォレスト**：
- 木の数を増やすと一度性能が落ちた後、再び向上

#### ダブルディセントの意味

✅ **正しい理解**：
- 深層学習では「大きいモデル + 十分な訓練」が有効
- Early Stoppingが常に最適とは限らない
- 過パラメータ化は悪ではない

❌ **誤解**：
- 「モデルは常に小さい方が良い」→ 状況による
- 「過学習は必ず避けるべき」→ 補間閾値を超えれば再向上

### 過学習の対策

#### 1. 正則化（Regularization）★試験頻出

**定義**: モデルの複雑さにペナルティを課し、過学習を防ぐ手法

**L1正則化（Lasso）**：
$$\text{Loss} = \text{誤差} + \lambda \sum |w_i|$$
- スパース性を促進（一部の重みがゼロに）
- 特徴選択の効果
- 重みの絶対値の和にペナルティ

**L2正則化（Ridge）**：
$$\text{Loss} = \text{誤差} + \lambda \sum w_i^2$$
- 重みを小さく保つ
- 最も一般的
- 重みの二乗和にペナルティ

**Elastic Net**：
$$\text{Loss} = \text{誤差} + \lambda_1 \sum |w_i| + \lambda_2 \sum w_i^2$$
- L1とL2の組み合わせ

**$\lambda$（正則化パラメータ）の役割**:
- $\lambda$が大きい → 正則化が強い → 単純なモデル（未学習リスク）
- $\lambda$が小さい → 正則化が弱い → 複雑なモデル（過学習リスク）
- $\lambda = 0$ → 正則化なし

---

### G検定選択肢問題：正則化の「不適切な選択肢」★重要

#### 典型的な「不適切な選択肢」（誤解・誤り）

**❌ 誤答パターン1: 訓練データを増やす**
- 「正則化は訓練データを増やして過学習を防ぐ」
  - **誤り**: データ拡張の説明、正則化は**ペナルティ**を課す

**❌ 誤答パターン2: モデルを複雑にする**
- 「正則化はモデルの表現力を高めて過学習を防ぐ」
  - **誤り**: 逆、正則化はモデルを**単純化**する方向

**❌ 誤答パターン3: 学習率の調整**
- 「正則化は学習率を調整して学習を安定化させる」
  - **誤り**: 学習率スケジューリングの説明、正則化は**重みにペナルティ**

**❌ 誤答パターン4: データの前処理**
- 「正則化はデータを正規化して学習を改善する」
  - **誤り**: データ正規化（標準化）の説明、正則化は**損失関数に項を追加**

**❌ 誤答パターン5: 推論時に使用**
- 「正則化は推論時にモデルの出力を調整する」
  - **誤り**: 正則化は**学習時のみ**、推論時は通常のモデル

**❌ 誤答パターン6: 精度を向上させる主目的**
- 「正則化の主な目的は訓練データでの精度向上である」
  - **誤り**: 目的は**汎化性能向上**（テストデータでの精度）

#### 適切な選択肢（正しい理解）

**✅ 正解パターン1: 重みへのペナルティ**
- 「正則化は損失関数に重みのペナルティ項を追加して過学習を防ぐ」

**✅ 正解パターン2: モデルの単純化**
- 「正則化はモデルの複雑さを制限して汎化性能を向上させる」

**✅ 正解パターン3: L1とL2の違い**
- 「L1正則化はスパース性を促進し、L2正則化は重みを小さく保つ」

**✅ 正解パターン4: 過学習対策**
- 「正則化は訓練データへの過度な適合を防ぐ手法である」

**✅ 正解パターン5: λパラメータ**
- 「正則化パラメータλが大きいほど制約が強くなる」

**✅ 正解パターン6: 学習時のみ**
- 「正則化は学習時に損失関数に適用され、推論時は影響しない」

#### 選択肢判定フローチャート

```
正則化の不適切な選択肢を選ぶ問題：

1. 「訓練データを増やす」→ ❌ 不適切（データ拡張）
2. 「モデルを複雑化」「表現力を高める」→ ❌ 不適切（逆効果）
3. 「学習率を調整」→ ❌ 不適切（最適化の話）
4. 「データを正規化」→ ❌ 不適切（前処理の話）
5. 「推論時に調整」→ ❌ 不適切（学習時のみ）
6. 「訓練精度向上が目的」→ ❌ 不適切（汎化が目的）

適切な選択肢：
1. 「重みにペナルティ」→ ✅ 適切
2. 「モデルを単純化」→ ✅ 適切
3. 「過学習を防ぐ」→ ✅ 適切
4. 「損失関数に項を追加」→ ✅ 適切
```

#### 混同しやすい概念の対比表

| 概念 | 目的 | 手法 | タイミング |
|------|------|------|-----------|
| **正則化** | 過学習防止 | 重みにペナルティ | 学習時 |
| **データ拡張** | 過学習防止 | データ増加 | 学習時 |
| **Dropout** | 過学習防止 | ニューロン無効化 | 学習時 |
| **Batch Norm** | 学習安定化 | 層ごとに正規化 | 学習・推論両方 |
| **データ正規化** | 学習効率化 | 入力データ標準化 | 前処理 |
| **Early Stopping** | 過学習防止 | 学習停止 | 学習時（検証誤差監視） |
| **最適化手法** | 収束改善 | 学習率調整 | 学習時 |

#### 頻出キーワードと判定

| キーワード | 正誤判定 | 補足 |
|----------|---------|------|
| 「重みにペナルティ」 | ✅ 適切 | 正則化の本質 |
| 「損失関数に項を追加」 | ✅ 適切 | 正しい説明 |
| 「過学習を防ぐ」 | ✅ 適切 | 主目的 |
| 「訓練データを増やす」 | ❌ 不適切 | データ拡張の説明 |
| 「モデルを複雑化」 | ❌ 不適切 | 逆効果 |
| 「学習率を調整」 | ❌ 不適切 | 最適化の話 |
| 「データを正規化」 | ❌ 不適切 | 前処理の話 |
| 「推論時に使用」 | ❌ 不適切 | 学習時のみ |
| 「L1はスパース」 | ✅ 適切 | L1の特徴 |
| 「L2は重みを小さく」 | ✅ 適切 | L2の特徴 |

#### L1正則化とL2正則化の比較★頻出

| 項目 | L1正則化（Lasso） | L2正則化（Ridge） |
|------|-----------------|-----------------|
| **ペナルティ** | $\sum \|w_i\|$ | $\sum w_i^2$ |
| **効果** | スパース性（重み0） | 重みを小さく |
| **特徴選択** | できる | できない |
| **数値安定性** | やや不安定 | 安定 |
| **微分可能性** | 0で不可 | 全域で可 |
| **用途** | 特徴が多い場合 | 一般的用途 |

**見極めポイント**:
- 「重みをゼロにする」「特徴選択」→ **L1正則化**
- 「重みを小さく保つ」「最も一般的」→ **L2正則化**

#### G検定頻出の穴埋め問題：線形回帰と正則化

**問題例**: 線形回帰とは、とあるデータ分布を表すような直線を求める手法のことである。この線形回帰にL1正則化項を加えた手法を（A）、L2正則化項を加えた手法を（B）と呼ぶ。

**答え**:
- **(A) Lasso（ラッソ）**
- **(B) Ridge（リッジ）**

**解説**:

**1. 線形回帰の基本**:
$$
y = w_0 + w_1 x_1 + w_2 x_2 + \cdots + w_n x_n
$$

損失関数（最小二乗法）:
$$
\text{Loss} = \sum_{i=1}^{m} (y_i - \hat{y}_i)^2
$$

**2. L1正則化を加えた線形回帰 = Lasso（ラッソ）**:

$$
\text{Loss} = \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{n} |w_j|
$$

**特徴**:
- ✅ 重みの**絶対値の和**をペナルティとして追加
- ✅ **スパース性（Sparsity）**: 一部の重みが正確に0になる
- ✅ **自動特徴選択**: 重要でない特徴の重みが0になり、実質的に除外
- ✅ 用途: 特徴量が多く、重要な特徴を選びたい場合

**例**:
```
元の重み: [0.5, 0.02, -0.8, 0.01, 0.3]
Lasso適用後: [0.5, 0, -0.8, 0, 0.3]  ← 小さい重みが0に
```

**3. L2正則化を加えた線形回帰 = Ridge（リッジ）**:

$$
\text{Loss} = \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{n} w_j^2
$$

**特徴**:
- ✅ 重みの**二乗の和**をペナルティとして追加
- ✅ **重みの縮小**: すべての重みを小さく保つ（0にはならない）
- ✅ **数値安定性**: 微分可能で最適化が安定
- ✅ 用途: 多重共線性（特徴間の相関）がある場合

**例**:
```
元の重み: [0.5, 0.02, -0.8, 0.01, 0.3]
Ridge適用後: [0.4, 0.015, -0.6, 0.008, 0.25]  ← すべて縮小
```

**4. Elastic Net（併用）**:

L1とL2の両方を組み合わせ:
$$
\text{Loss} = \sum (y_i - \hat{y}_i)^2 + \lambda_1 \sum |w_j| + \lambda_2 \sum w_j^2
$$

- Lassoのスパース性とRidgeの安定性を両立

**5. 名称の由来**:

| 手法 | 名称の由来 | 別名 |
|------|----------|------|
| **Lasso** | Least Absolute Shrinkage and Selection Operator | L1正則化 |
| **Ridge** | Ridge Regression（尾根回帰） | L2正則化 |

**6. 判定フロー（穴埋め問題）**:

```
問題文を読む
    ↓
「L1正則化を加えた」とある？
    ↓ YES → Lasso（ラッソ）
    ↓
「L2正則化を加えた」とある？
    ↓ YES → Ridge（リッジ）
    ↓
「重みの絶対値の和」とある？
    ↓ YES → Lasso
    ↓
「重みの二乗の和」とある？
    ↓ YES → Ridge
    ↓
「スパース性」「特徴選択」とある？
    ↓ YES → Lasso
    ↓
「重みを小さく保つ」とある？
    ↓ YES → Ridge
```

**7. 混同しやすい選択肢**:

| 選択肢 | 正誤 | 理由 |
|--------|------|------|
| L1正則化 = Lasso | ✅ | 正しい |
| L2正則化 = Ridge | ✅ | 正しい |
| L1正則化 = Ridge | ❌ | 逆（L2がRidge） |
| L2正則化 = Lasso | ❌ | 逆（L1がLasso） |
| L1正則化 = Elastic Net | ❌ | Elastic NetはL1+L2 |
| L2正則化 = Dropout | ❌ | Dropoutは別の正則化手法 |

**8. 実務での使い分け**:

| 状況 | 推奨手法 | 理由 |
|------|---------|------|
| 特徴量が非常に多い | **Lasso** | 自動特徴選択 |
| 特徴間に相関がある | **Ridge** | 数値安定性 |
| 解釈性が重要 | **Lasso** | スパースで理解しやすい |
| 予測精度最優先 | **Ridge or Elastic Net** | 安定した性能 |
| 特徴数 > サンプル数 | **Lasso or Elastic Net** | 過学習防止 |

**9. 関連する典型問題**:

**問**: Lassoの特徴として正しいものは？
- ✅ **正解**: 一部の重みが正確に0になる
- ✅ **正解**: 自動的に特徴選択ができる
- ❌ 誤答: すべての重みが0に近づく（これはRidge）
- ❌ 誤答: 訓練データを増やす手法（これはデータ拡張）

**問**: Ridgeの特徴として正しいものは？
- ✅ **正解**: 重みの二乗和をペナルティとする
- ✅ **正解**: すべての重みを小さく保つ
- ❌ 誤答: 一部の重みが0になる（これはLasso）
- ❌ 誤答: ニューロンをランダムに無効化（これはDropout）

**10. 数式の確認（G検定では詳細不要だが理解用）**:

**Lasso（L1）**:
$$
\min_w \left[ \frac{1}{2m} \sum_{i=1}^{m} (y_i - w^T x_i)^2 + \lambda \sum_{j=1}^{n} |w_j| \right]
$$

**Ridge（L2）**:
$$
\min_w \left[ \frac{1}{2m} \sum_{i=1}^{m} (y_i - w^T x_i)^2 + \lambda \sum_{j=1}^{n} w_j^2 \right]
$$

**ポイント**:
- $\lambda$: 正則化の強さを制御するハイパーパラメータ
- $\lambda$が大きい → 重みの制約が強い
- $\lambda = 0$ → 通常の線形回帰

#### 2. Dropout

ニューラルネットワークで、訓練時に**ランダムにニューロンを無効化**：
```
通常:  ●─●─●─●
       ↓ ↓ ↓ ↓
Dropout: ●─×─●─×  (50%をランダムに無効化)
```

**効果**：
- アンサンブル学習に近い効果
- ニューロン間の過度な依存を防ぐ

#### 3. Early Stopping

検証誤差が悪化し始めたら学習を停止：
```
誤差
 ↑    ┌─ 検証誤差
 │   ╱
 │  ╱  ←ここで停止
 │ ╱
 │╱＼─ 訓練誤差
 └──────→ エポック
```

**注意**：ダブルディセント現象がある場合、早期停止が最適とは限らない。

#### 4. データ拡張（Data Augmentation）

訓練データを人工的に増やす：
- 画像：回転、反転、クロッピング、色調変換
- テキスト：同義語置換、バックトランスレーション
- 音声：ノイズ追加、ピッチ変換

#### 5. その他の手法

**Batch Normalization**：
- 各層の入力を正規化して学習安定化

**Weight Decay**：
- 重みを小さく保つ（L2正則化と同等）

**モデル簡略化**：
- 層数削減、パラメータ数削減

**交差検証**：
- データを分割して汎化性能を正確に評価

### 汎化性能の評価方法

#### ホールドアウト法
データを訓練・検証・テストに分割：
```
全データ
├─ 訓練（60%）: モデル学習
├─ 検証（20%）: ハイパーパラメータ調整
└─ テスト（20%）: 最終評価（一度だけ使用）
```

#### k-分割交差検証
データをk個に分割し、k回学習・評価：
- 詳細は [cross_validation.md](cross_validation.md) を参照

## 試験での問われ方
- **典型設問**：
  - 「訓練誤差は小さいがテスト誤差が大きい状態は？」→ **過学習（Overfitting）**
  - 「訓練誤差もテスト誤差も大きい状態は？」→ **未学習（Underfitting）**
  - 「過学習の対策として適切なものは？」→ 正則化、Dropout、Early Stopping、データ拡張
  - 「モデルサイズ増加で性能が一度悪化後に再向上する現象は？」→ **ダブルディセント（Double Descent）**
  - 「ダブルディセントで性能が最悪になる点は？」→ **補間閾値（Interpolation Threshold）**
- **比較されやすい概念**：
  - **過学習** vs **未学習**: 訓練誤差が小さい vs 大きい
  - **正則化** vs **Dropout**: 重みへの制約 vs ニューロンの無効化
  - **L1正則化** vs **L2正則化**: スパース性 vs 重みの縮小
  - **Early Stopping** vs **ダブルディセント**: 早期停止 vs 訓練継続で再向上
  - **バイアス** vs **バリアンス**: 単純さの誤差 vs 複雑さの誤差
- **引っ掛けポイント**：
  - ✅ 「過学習は訓練誤差が小さくテスト誤差が大きい」= **正しい**
  - ❌ 「過学習は訓練誤差が大きい」→ 誤り（未学習の症状）
  - ✅ 「L2正則化は重みを小さく保つ」= **正しい**
  - ❌ 「Dropoutは推論時も使用する」→ 誤り（訓練時のみ）
  - ✅ 「ダブルディセントでは巨大モデルが高性能」= **正しい**
  - ❌ 「ダブルディセントは常に起こる」→ 誤り（特定の条件下）
  - ❌ 「Early Stoppingが常に最適」→ 誤り（ダブルディセントでは継続が有効な場合も）
  - ❌ 「過学習は必ず避けるべき」→ 誤り（補間閾値を超えれば再向上）
- **頻出パターン**：
  - 過学習と未学習の見分け方（訓練誤差とテスト誤差の関係）
  - 過学習対策の列挙（正則化、Dropout、Early Stopping等）
  - 正則化の種類と効果（L1、L2、Elastic Net）
  - ダブルディセント現象の説明（3つの領域）
  - バイアス-バリアンストレードオフの理解

## 補足
- **実務的観点**：
  - 深層学習では過パラメータ化（巨大モデル）が標準的
  - Early Stoppingは一般的だが、ダブルディセントを考慮すると訓練継続が有効な場合も
  - 正則化とDropoutは併用可能（相乗効果）
  - データ拡張は最も効果的な過学習対策の一つ
  - 転移学習で事前学習済みモデルを使うと過学習リスク低減
  - ダブルディセントは2019年頃から注目された比較的新しい知見
- **関連トピック**：
  - [交差検証](cross_validation.md) - 汎化性能の評価手法
  - [評価指標](evaluation_metrics.md) - 性能評価の指標
  - [ニューラルネットワーク基礎](../06_deep_learning/neural_network_basics.md) - Dropout、Batch Normalization
  - [アンサンブル学習](ensemble_learning.md) - バイアス-バリアンストレードオフ
- **発展**：
  - Implicit Regularization（暗黙の正則化）
  - Neural Tangent Kernel（深層学習の理論的理解）
  - Lottery Ticket Hypothesis（スパースネットワークの理論）
  - Mixup、CutMix（データ拡張の発展形）
