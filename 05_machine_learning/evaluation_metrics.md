# 評価指標（Evaluation Metrics）

## 要点（試験用）
- 機械学習モデルの性能を定量評価する指標群。タスク（分類/回帰）と要件（外れ値の扱い、解釈性、コスト）によって適切な指標を選択
- 分類：精度（Accuracy）、適合率・再現率・F値、AUC-ROCが主要。不均衡データでは精度だけでは不十分
- 回帰：RMSE（外れ値に敏感）、MAE（頑健）、R²（説明力）を使い分け

## 定義
機械学習モデルの予測性能を数値化する指標。タスクの特性（分類/回帰、データ分布、ビジネス要件）に応じて選択する。

---

## 分類タスクの評価指標

### 混同行列（Confusion Matrix）
予測と実際のラベルを集計した2×2表（二値分類の場合）

|  | 予測：Positive | 予測：Negative |
|---|---|---|
| **実際：Positive** | TP（真陽性） | FN（偽陰性） |
| **実際：Negative** | FP（偽陽性） | TN（真陰性） |

### 精度（Accuracy）
- **定義**: $\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$
- **意味**: 全予測のうち正解した割合
- **注意**: 不均衡データ（例：陽性1%）では高精度でも無意味な場合あり

### 適合率（Precision）
- **定義**: $\text{Precision} = \frac{TP}{TP + FP}$
- **意味**: Positiveと予測したもののうち実際にPositiveだった割合
- **適用**: スパム検定（誤判定を減らしたい）、医療診断の確信度

### 再現率（Recall / 感度 Sensitivity）
- **定義**: $\text{Recall} = \frac{TP}{TP + FN}$
- **意味**: 実際のPositiveのうち正しく検出できた割合
- **適用**: がん検診（見逃しを減らしたい）、異常検知

### F値（F-measure / F1スコア）
- **定義**: $F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$（調和平均）
- **意味**: 適合率と再現率のバランス指標
- **利点**: 不均衡データでも有効。単一指標で評価可能

### AUC-ROC
- **ROC曲線**: 横軸にFPR（偽陽性率）、縦軸にTPR（真陽性率=再現率）をプロット
- **AUC**: ROC曲線の下側面積（0.5〜1.0、0.5はランダム予測、1.0は完全分類）
- **利点**: 閾値に依存せず全体性能を評価

---

## 回帰タスクの評価指標

### RMSE（Root Mean Squared Error / 平方根平均二乗誤差）
- **定義**: $\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$
- **特徴**:
  - 誤差を2乗するため**外れ値に敏感**（大きな誤差を強調）
  - 元データと同じ単位
  - 微分可能→勾配降下法で最適化しやすい
- **適用**: 大きな誤差を避けたい場面（予測精度重視）

### MAE（Mean Absolute Error / 平均絶対誤差）
- **定義**: $\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$
- **特徴**:
  - 誤差の絶対値の平均→**外れ値に頑健**（全誤差を均等に扱う）
  - 解釈が直感的（平均的な誤差量）
  - 原点（誤差=0）で微分不可能だが部分微分可能
- **適用**: 安定した評価が必要、外れ値が多い場合

### RMSE vs MAE の主な違い（重要）

| 観点 | RMSE | MAE |
|------|------|-----|
| **外れ値への感度** | **高い**（2乗で増幅） | **低い**（線形） |
| **解釈性** | やや複雑 | **直感的** |
| **最適化** | 微分可能（勾配法◎） | 原点で微分不可 |
| **適用場面** | 大誤差を避けたい | 安定評価が必要 |
| **単位** | 元データと同単位 | 元データと同単位 |

### R²（決定係数 / Coefficient of Determination）
- **定義**: $R^2 = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$
- **意味**: モデルがデータの分散をどれだけ説明できるか（0〜1、1に近いほど良い）
- **注意**: 説明変数を増やすと自動的に上がる→調整済みR²を使用

---

## 重要キーワード
- **混同行列（Confusion Matrix）**: TP/TN/FP/FNの集計表
- **精度（Accuracy）**: 全体の正解率。不均衡データでは注意
- **適合率（Precision）**: 予測陽性の精度（誤検知を減らす）
- **再現率（Recall）**: 実際の陽性の検出率（見逃しを減らす）
- **F1スコア**: 適合率と再現率の調和平均
- **AUC-ROC**: 閾値非依存の分類性能指標
- **RMSE**: 外れ値に敏感な回帰誤差（2乗平均の平方根）
- **MAE**: 外れ値に頑健な回帰誤差（絶対値の平均）
- **R²**: モデルの説明力（分散の説明割合）

## 詳細（教科書風）

### 分類と回帰での指標の使い分け
機械学習タスクは大きく**分類**（離散ラベル）と**回帰**（連続値）に分かれ、それぞれ適切な評価指標が異なる。

**分類**: クラス間の境界を学習。精度だけでなく、誤分類の種類（FP/FN）を区別する指標が重要。医療診断では再現率、スパムフィルタでは適合率を優先。

**回帰**: 連続値の予測誤差を評価。RMSEは大きな誤差にペナルティを与え、MAEは誤差を均等に扱う。予測の安定性とビジネス要件で選択。

### 不均衡データでの注意
クラス比が極端（例：陽性1%、陰性99%）な場合、常に陰性と予測しても精度99%を達成。このため**F値**や**AUC-ROC**を併用し、少数クラスの検出性能も評価する。

### 評価指標とモデル選択
指標はビジネス目標と直結：
- がん検診：再現率を最重視（見逃しのコストが高い）
- 広告配信：適合率を優先（無駄な配信を減らす）
- 需要予測：RMSEで大幅なずれを抑制

## 試験での問われ方

### 典型的な出題パターン
1. **RMSE vs MAE**: 「外れ値に敏感なのはどちらか」→ **RMSE**（2乗で増幅）
2. **精度の落とし穴**: 「不均衡データで精度90%は良いモデルか」→ 不十分（F値やAUCで評価）
3. **適合率 vs 再現率**: 「医療診断で重視すべきは」→ **再現率**（見逃し回避）
4. **F1スコアの意味**: 「調和平均を使う理由」→ 適合率・再現率のバランス（片方だけ高くても低評価）
5. **R²の解釈**: 「R²=0.9の意味」→ モデルがデータ分散の90%を説明

### 引っ掛けポイント
❌ 「MAEの方が外れ値に敏感」→ **逆**（RMSEが敏感）  
❌ 「RMSEは単位が異なる」→ 同単位（平方根で元に戻る）  
❌ 「精度が高ければ良いモデル」→ データ分布による（不均衡時は不十分）  
❌ 「再現率を上げれば適合率も上がる」→ **トレードオフ**関係（一方を上げると他方が下がる傾向）  
✅ 「RMSEは大きな誤差を重視する」→ **正解**

### 比較されやすい概念
- **精度 vs F値**: 不均衡データではF値が適切
- **適合率 vs 再現率**: タスク要件で優先度が変わる
- **RMSE vs MAE**: 外れ値の扱いが正反対
- **ROC vs PR曲線**: 不均衡データではPR曲線が有用

## 補足
- **実務では複数指標を併用**: 単一指標だけでは不十分。ビジネスKPIと紐付けて評価
- **クロスバリデーション**: 評価指標を複数分割で平均し、過学習を検証
- **閾値調整**: 分類では閾値（確率カットオフ）によって適合率・再現率が変動。ROC/PR曲線で最適点を探索
- **コスト考慮**: 誤分類のコスト（FPとFNの重み）が異なる場合、カスタム損失関数を設計
