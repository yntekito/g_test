# 交差検証（Cross-Validation）

## 要点
- **k-分割交差検証**：データをk個に分割し、1つをテスト・残りk-1個を訓練として k回繰り返し評価。全データが1回ずつテストに使われる。
- モデルの**汎化性能**を安定的に評価し、過学習・未学習の判定に有効。
- k=10が一般的。データ量が少ない場合は k を大きく（LOOCV: k=データ数）、多い場合は k=5 等で計算コスト削減。

## 定義
**交差検証**は、限られたデータでモデルの汎化性能を信頼性高く評価する手法。データセットを複数に分割し、訓練とテストを繰り返すことで、特定の分割に依存しない性能指標を得る。

**k-分割交差検証（k-fold Cross-Validation）**：
1. データセット全体を k個のほぼ等しいサブセット（fold）に分割
2. 各イテレーションで1つのfoldをテストデータ、残り k-1個を訓練データとして使用
3. k回の評価結果（精度・損失等）の**平均**と**標準偏差**でモデル性能を評価

$$
\text{CV Score} = \frac{1}{k} \sum_{i=1}^{k} \text{Score}_i
$$

## 重要キーワード
- **k-分割（k-fold）**：データを k個に分割する手法。k=5 や k=10 が標準的。
- **ホールドアウト法**：データを1回だけ訓練・テストに分割（70:30等）。計算効率高いが評価の安定性低い。
- **LOOCV（Leave-One-Out Cross-Validation）**：k=データ数とする特殊ケース。1サンプルずつテスト。小データ向きだが計算コスト大。
- **層化k-分割（Stratified k-fold）**：各foldでクラス比率を保持。不均衡データの評価に必須。
- **汎化性能**：未知データへの予測精度。交差検証で訓練データの性能過大評価を防ぐ。
- **ハイパーパラメータチューニング**：交差検証を用いて最適なパラメータを探索（グリッドサーチ等）。

## 詳細

### 背景・目的
機械学習モデルの評価で単純にデータを訓練・テストに分割すると、以下の問題が発生：
- **データの偏り**：たまたま簡単/難しいサンプルがテストに集中し、評価が不安定
- **データの浪費**：小規模データセットでは訓練に使えるデータが減少

交差検証は全データを訓練・テストの両方に使い、安定した性能評価を実現する。

### k-分割交差検証のプロセス
```
元データ: [D1, D2, D3, D4, D5, D6, D7, D8, D9, D10]  (k=5の例)

分割:
Fold1: [D1, D2]
Fold2: [D3, D4]
Fold3: [D5, D6]
Fold4: [D7, D8]
Fold5: [D9, D10]

イテレーション1: Fold1=テスト, Fold2~5=訓練 → Score1
イテレーション2: Fold2=テスト, Fold1,3~5=訓練 → Score2
イテレーション3: Fold3=テスト, Fold1,2,4,5=訓練 → Score3
イテレーション4: Fold4=テスト, Fold1~3,5=訓練 → Score4
イテレーション5: Fold5=テスト, Fold1~4=訓練 → Score5

最終評価: 平均(Score1~5) ± 標準偏差
```

### kの選択基準
| k値 | 特徴 | 適用場面 |
|-----|------|----------|
| k=5 | バランス良、計算速い | 大規模データ、初期評価 |
| k=10 | **標準的**、評価安定 | 一般的な用途（推奨） |
| k=データ数（LOOCV） | 最大限データ活用 | 小規模データ、計算リソース潤沢 |
| k=3 | 高速だが不安定 | 大規模データの粗評価 |

### 層化k-分割（Stratified k-fold）
不均衡データ（クラス比率が偏る）では、各foldのクラス比率を元データと同じに保つ。

例：全体でクラスA:B=8:2の場合、各foldでも8:2を維持。
- 通常のk-分割: あるfoldにクラスBが全く含まれない可能性
- 層化k-分割: 全foldに適切な比率でクラスBを配分

## 実例

### 例1：精度評価（k=5）
```
データ: 100サンプル → 各fold 20サンプル

イテレーション1: 精度 0.85
イテレーション2: 精度 0.88
イテレーション3: 精度 0.82
イテレーション4: 精度 0.87
イテレーション5: 精度 0.84

最終評価: 平均 0.852 ± 0.022
→ モデルの汎化精度は約85%、安定性も良好
```

### 例2：ハイパーパラメータチューニング
```
候補: 学習率 {0.01, 0.001, 0.0001}

各学習率で5-fold CV実施:
- lr=0.01  → CV Score: 0.78
- lr=0.001 → CV Score: 0.85  ← 最高
- lr=0.0001→ CV Score: 0.80

最適値 lr=0.001 を選択し、全訓練データで最終モデル訓練
```

## 試験での問われ方

### 典型問題
**問**: k-分割交差検証の説明として最も適切なものを選べ。
- ✅ **正解例**: 「データをk個に分割し、1つをテストデータ、残りk-1個を訓練データとして、全k回評価を行う」
- ❌ 誤答例1: 「訓練データとテストデータを k:1 の比率で分割する」→ ホールドアウト法
- ❌ 誤答例2: 「k個のモデルを独立に訓練し、多数決で予測する」→ アンサンブル学習（バギング）
- ❌ 誤答例3: 「データをk回ランダムサンプリングして評価する」→ 繰り返しサンプリングの概念が不正確

### 比較問題（違いのポイント）
| 手法 | データ分割回数 | 各データの使用 | 計算コスト | 用途 |
|------|----------------|----------------|------------|------|
| **ホールドアウト** | 1回のみ | 訓練 or テストのみ | 低 | 大規模データ、迅速評価 |
| **k-分割交差検証** | k回 | 訓練k-1回、テスト1回 | 中 | 標準的な性能評価 |
| **LOOCV** | データ数回 | 訓練n-1回、テスト1回 | 高 | 小規模データ、精密評価 |
| **層化k-分割** | k回 | 同上＋クラス比率保持 | 中 | 不均衡データ |

### 引っ掛けポイント
1. **「k個のモデルを作る」は誤り**：k回評価するが、最終的には1つのモデルを全データで訓練するのが一般的。
2. **「テストデータが複数回使われる」は誤り**：各データは**1回だけ**テストセットになる。
3. **「ホールドアウトとの混同」**：ホールドアウトは1回分割、交差検証は複数回繰り返し。
4. **「訓練・検証・テストの3分割との混同」**：交差検証はハイパーパラメータ選択に使い、最終評価は別の独立テストセットで行う。
5. **「層化の必要性」**：不均衡データで通常k-分割を使うと性能が不安定（層化k-分割を使うべき）。

### 実務観点の設問
- **問**: 小規模データ（100サンプル）でモデル評価する最適手法は？
  - → k=10 の交差検証 または LOOCV（データを最大限活用）
- **問**: 大規模データ（100万サンプル）で迅速に評価するには？
  - → ホールドアウト法（70:30分割）または k=3 の交差検証（計算コスト削減）

## 補足

### 実務上の注意点
1. **時系列データ**: 過去→未来の順序を保持する **Time Series Split** を使用（未来データで訓練しない）。
2. **データリーケージ防止**: 正規化・特徴選択は各fold内で独立実施（テストデータ情報を訓練に混入させない）。
3. **ネスト交差検証**: ハイパーパラメータ選択（内側CV）と性能評価（外側CV）を分離し、過度な最適化を防ぐ。
4. **計算リソース**: 深層学習等で k-分割CVは時間がかかる→ホールドアウトやk=3で代用も検討。

### 関連トピック
- [評価指標](evaluation_metrics.md)：精度・再現率・F1等、CVで算出する指標
- [過学習・未学習](overfitting_underfitting.md)：CVで訓練・テストの性能差から判定
- [アンサンブル学習](ensemble_learning.md)：バギングとの違い（複数モデルの組み合わせ）
