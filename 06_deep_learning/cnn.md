# 畳み込みニューラルネットワーク（CNN）

## 要点
- 画像認識に特化した深層学習モデル。畳み込み層とプーリング層で特徴抽出。
- **ストライド**はフィルタの移動幅、**パディング**は入力の余白追加で出力サイズを調整。
- パラメータ共有と局所受容野で、全結合層より少ないパラメータで高精度を実現。

## 定義
畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）は、画像データに対して**畳み込み層（Convolutional Layer）**と**プーリング層（Pooling Layer）**を組み合わせ、空間的な特徴を階層的に抽出するニューラルネットワーク。1998年のLeNet-5が起源。

## 重要キーワード
- **畳み込み層（Convolutional Layer）**: フィルタ（カーネル）で局所的特徴を抽出。
- **フィルタ（カーネル）**: 重み行列。画像上をスライドして特徴マップを生成。
- **ストライド（Stride）**: フィルタを移動させる幅（ピクセル数）。★重要
- **パディング（Padding）**: 入力画像の周囲に余白を追加（ゼロパディング等）。
- **特徴マップ（Feature Map）**: 畳み込み演算の出力。
- **プーリング層（Pooling Layer）**: 特徴マップのダウンサンプリング（Max/Average Pooling）。
- **受容野（Receptive Field）**: 各ニューロンが参照する入力領域。
- **パラメータ共有（Weight Sharing）**: 同じフィルタを全領域で使用。
- **局所結合（Local Connectivity）**: 全結合でなく局所的に結合。
- **チャネル（Channel）**: RGB画像なら3チャネル、中間層では複数の特徴マップ。
- **全結合層（Fully Connected Layer）**: CNN最終段で分類を行う。

## 詳細

### 背景と直観
CNNは1980年代の新古典派理論（Neocognitron, Fukushima）や、1998年のLeCunによるLeNet-5を起源とし、2012年のAlexNet以降、画像認識の主流となりました。

**基本的な考え方**：
- 画像の**空間構造**を保持しながら特徴抽出
- **局所的なパターン**（エッジ、テクスチャ等）を階層的に学習
- 全結合層より**パラメータ数を削減**し過学習を抑制

### CNNの基本構造

```
入力画像
  ↓
[畳み込み層 → 活性化(ReLU) → プーリング層] × 複数回
  ↓
[全結合層] × 複数回
  ↓
出力層（Softmax）
```

**典型例（AlexNet風）**：
```
入力(224×224×3)
 → Conv(96 filters) → ReLU → MaxPool
 → Conv(256 filters) → ReLU → MaxPool
 → Conv(384 filters) → ReLU
 → Conv(384 filters) → ReLU
 → Conv(256 filters) → ReLU → MaxPool
 → FC(4096) → ReLU → Dropout
 → FC(4096) → ReLU → Dropout
 → FC(1000) → Softmax
```

### 畳み込み層の詳細

#### 畳み込み演算
フィルタ（例：3×3の重み行列）を入力画像上でスライドさせ、要素ごとの積和を計算：

$$S(i,j) = \sum_{m}\sum_{n} I(i+m, j+n) \cdot K(m,n)$$

- $I$: 入力画像
- $K$: フィルタ（カーネル）
- $S$: 特徴マップ（出力）

#### 図解：畳み込み演算（3×3フィルタ）
```
入力画像（5×5）    フィルタ（3×3）
┌─────────┐    ┌─────┐
│1 2 3 4 5│    │1 0 1│
│2 3 4 5 6│ ⊗  │0 1 0│
│3 4 5 6 7│    │1 0 1│
│4 5 6 7 8│    └─────┘
│5 6 7 8 9│
└─────────┘
       ↓
出力（3×3）※ストライド1、パディング0
┌───────┐
│28 34 40│
│38 44 50│
│48 54 60│
└───────┘
```

### ストライド（Stride）★重要

#### 定義
**ストライド**は、フィルタを入力画像上で移動させる際の**移動幅（ピクセル数）**。

#### 影響
- **ストライド1**: 1ピクセルずつ移動（細かく特徴抽出）
- **ストライド2**: 2ピクセルずつ移動（出力サイズが約半分）
- ストライド大 → **出力サイズ小**、**計算量減**

#### 図解：ストライドの違い
```
ストライド1（1ピクセル移動）
┌─┬─┬─┬─┐
│■│■│ │ │  →  ┌─┬─┬─┐
├─┼─┼─┼─┤     │1│2│3│  
│ │■│■│ │  →  └─┴─┴─┘
├─┼─┼─┼─┤     出力: 3×3
│ │ │■│■│
└─┴─┴─┴─┘

ストライド2（2ピクセル移動）
┌─┬─┬─┬─┐
│■│■│ │ │  →  ┌─┬─┐
├─┼─┼─┼─┤     │1│2│  
│ │ │■│■│  →  └─┴─┘
└─┴─┴─┴─┘     出力: 2×2
```

#### 出力サイズの計算式
$$\text{出力サイズ} = \left\lfloor \frac{W - F + 2P}{S} \right\rfloor + 1$$

- $W$: 入力サイズ
- $F$: フィルタサイズ
- $P$: パディング
- $S$: ストライド

**計算例**：
- 入力: 5×5
- フィルタ: 3×3
- パディング: 0
- ストライド: 1
- 出力: $(5 - 3 + 0) / 1 + 1 = 3$×3

### パディング（Padding）

#### 定義
入力画像の周囲に余白（通常は0）を追加すること。

#### 目的
- **出力サイズの維持**（入力と同サイズに保つ）
- **端の情報の保持**（パディングなしでは端が失われる）

#### タイプ
- **Valid Padding**: パディングなし（出力サイズ減）
- **Same Padding**: 出力サイズ = 入力サイズになるよう調整
- **ゼロパディング**: 0で埋める（最も一般的）

#### 図解：パディング
```
入力（3×3）  →  パディング1  →  5×5
┌───┐       ┌─────────┐
│1 2│       │0 0 0 0 0│
│3 4│       │0 1 2 3 0│
└───┘       │0 4 5 6 0│
            │0 7 8 9 0│
            │0 0 0 0 0│
            └─────────┘
```

### プーリング層（Pooling Layer）

#### 目的
- **ダウンサンプリング**（特徴マップの縮小）
- **位置不変性**の獲得（微小な位置ずれに頑健）
- 計算量削減

#### 種類
**Max Pooling**（最も一般的）：
- 領域内の最大値を取得
```
入力（4×4）    Max Pooling(2×2, stride=2)
┌───────┐    ┌───┐
│1 3 2 4│    │3 4│
│5 6 1 2│ →  │8 7│
│7 8 3 5│    └───┘
│4 2 6 7│
└───────┘
```

**Average Pooling**：
- 領域内の平均値を取得

#### Max/Average Pooling vs Global Average Pooling（★重要な違い）

通常のプーリング（Max/Average Pooling）とGlobal Average Pooling（GAP）は**目的と適用範囲が全く異なる**手法です：

| 項目 | Max/Average Pooling | Global Average Pooling |
|------|-------------------|----------------------|
| **適用範囲** | 局所領域（2×2、3×3等） | **特徴マップ全体**（H×W全体） |
| **目的** | ダウンサンプリング | 全結合層の代替・解釈性向上 |
| **出力サイズ** | 入力より小さい特徴マップ | **チャネルごとに1値**（ベクトル） |
| **ネットワーク内の位置** | 中間層（畳み込み層の後） | **出力層の直前**（最終層） |
| **パラメータ数** | ゼロ | ゼロ |
| **空間情報** | 保持される（縮小） | **完全に失われる**（平均化） |
| **主な効果** | 位置不変性・計算量削減 | 解釈性向上・過学習抑制 |
| **可視化** | 不可 | **CAMで可視化可能** |

**具体例で見る違い**：

```
入力特徴マップ（4×4）
┌───────┐
│1 3 2 4│
│5 6 1 2│
│7 8 3 5│
│4 2 6 7│
└───────┘

↓ Max Pooling(2×2, stride=2) ← 局所領域の最大値
┌───┐
│6 4│  出力: 2×2の特徴マップ（空間情報は保持）
│8 7│
└───┘

↓ Average Pooling(2×2, stride=2) ← 局所領域の平均値
┌──────┐
│3.75 2.25│  出力: 2×2の特徴マップ（空間情報は保持）
│5.25 5.25│
└──────┘

↓ Global Average Pooling ← 全体の平均値
[4.125]  出力: 1つの値（空間情報は失われる）
```

**使い分けのポイント**：
- **Max/Average Pooling**: ネットワーク中間層で特徴抽出を続ける場合
- **Global Average Pooling**: 最終層で分類する際、解釈性を重視する場合

**試験での引っ掛け**：
- ❌ 「GAPは局所領域のプーリング」→ 誤り（全体を平均化）
- ❌ 「Max Poolingで解釈性向上」→ 誤り（解釈性向上はGAPの特徴）
- ❌ 「GAPは中間層で使用」→ 誤り（出力層直前で使用）
- ✅ 「GAPは全結合層の代替」→ 正しい
- ✅ 「Max Poolingはダウンサンプリング」→ 正しい

### パラメータ共有と局所結合

#### パラメータ共有
- 同じフィルタを画像全体で使用
- 例：3×3フィルタ → パラメータ数は9個（位置によらず）
- 全結合層なら: 100×100画像で10,000個のパラメータ

#### 利点
- **パラメータ数の大幅削減**
- **過学習の抑制**
- **平行移動不変性**（物体の位置が変わっても認識可能）

### 受容野（Receptive Field）

各層のニューロンが参照する入力領域：
```
畳み込み1層目: 3×3の局所領域
畳み込み2層目: より広い領域（例：5×5、7×7）
深い層ほど広い受容野 → 大域的特徴の抽出
```

### Dilated Convolution（拡張畳み込み/空間的畳み込み）

#### 定義
**Dilated Convolution（Atrous Convolution）**は、フィルタの要素間に「穴（空白）」を開けることで、**パラメータ数を増やさずに受容野を拡大**する畳み込み手法。Dilation Rate（拡張率）$r$ で穴の間隔を制御します。

#### 通常の畳み込みとの違い

**通常の畳み込み（Dilation Rate = 1）**：
```
3×3フィルタ（受容野: 3×3）
┌─┬─┬─┐
│●│●│●│
├─┼─┼─┤
│●│●│●│
├─┼─┼─┤
│●│●│●│
└─┴─┴─┘
パラメータ数: 9個
```

**Dilated Convolution（Dilation Rate = 2）**：
```
3×3フィルタが実質5×5の受容野をカバー
┌─┬─┬─┬─┬─┐
│●│ │●│ │●│
├─┼─┼─┼─┼─┤
│ │ │ │ │ │
├─┼─┼─┼─┼─┤
│●│ │●│ │●│
├─┼─┼─┼─┼─┤
│ │ │ │ │ │
├─┼─┼─┼─┼─┤
│●│ │●│ │●│
└─┴─┴─┴─┴─┘
パラメータ数: 9個（変わらず）
受容野: 5×5（拡大！）
```

#### Dilated Convolutionの計算式

受容野のサイズ：
$$R = (K - 1) \times r + 1$$

- $K$: フィルタサイズ（例：3×3なら $K=3$）
- $r$: Dilation Rate（拡張率）
- $R$: 実効受容野サイズ

**計算例**：
| フィルタサイズ | Dilation Rate | 受容野サイズ |
|------------|--------------|----------|
| 3×3 | r=1（通常） | 3×3 |
| 3×3 | r=2 | 5×5 |
| 3×3 | r=3 | 7×7 |
| 3×3 | r=4 | 9×9 |

#### Dilated Convolution特有のメリット（★試験重要）

通常の畳み込みと比較した際の主なメリット：

✅ **1. パラメータ数を増やさずに受容野を拡大**
- 最大の特徴：3×3フィルタのパラメータ数（9個）のまま、受容野を5×5、7×7に拡大可能
- 通常の5×5畳み込み: 25パラメータ、Dilated 3×3（r=2）: 9パラメータで同等の受容野

✅ **2. 計算量を増やさずに広域的な文脈情報を獲得**
- プーリング層なしで受容野拡大が可能
- セグメンテーションタスクで解像度を維持しながら広域情報を利用

✅ **3. 解像度の低下を防ぐ**
- プーリング層を使わないため、空間解像度が保持される
- セマンティックセグメンテーション（DeepLab等）で重要

❌ **メリットではないもの（試験の引っ掛け）**：
- 学習速度の高速化 → メリットではない（計算コストはほぼ同じ）
- パラメータ数の削減による過学習抑制 → パラメータ数は変わらない
- 小さい物体の検出精度向上 → 広域情報向き、小物体には不向き

#### 代表的な応用例

**DeepLab（セマンティックセグメンテーション）**：
- Atrous Spatial Pyramid Pooling (ASPP)でマルチスケール特徴抽出
- Dilation Rate = {6, 12, 18}の並列畳み込み

**WaveNet（音声生成）**：
- 時系列データで長距離依存関係を効率的に学習
- 指数的に増加するDilation Rate: 1, 2, 4, 8, 16, ...

#### 図解：複数層でのDilated Convolution

```
層1（r=1）: ●─●─●  受容野3
           
層2（r=2）: ●──●──●  受容野7（累積）

層3（r=4）: ●────●────●  受容野15（累積）

→ 3層で受容野15倍に拡大（パラメータは3×9=27個のみ）
```

#### 通常の畳み込みとの比較表

| 項目 | 通常の畳み込み | Dilated Convolution |
|------|-------------|-------------------|
| **パラメータ数** | フィルタサイズに比例 | フィルタサイズに比例（同じ） |
| **受容野拡大** | 層を深くするorフィルタサイズ増 | Dilation Rateで調整 |
| **解像度** | プーリング併用で低下 | 保持可能 |
| **計算効率** | 標準 | 同等 |
| **主な用途** | 一般的画像認識 | セグメンテーション、音声 |

#### 注意点

**Gridding Artifact（格子状のアーティファクト）**：
- Dilation Rateが大きすぎると、サンプリング点が離れすぎて情報が欠落
- 対策: Hybrid Dilated Convolution（異なるrateを組み合わせ）

### Global Average Pooling（GAP）と解釈性の向上

#### 定義
**Global Average Pooling（GAP、大域平均プーリング）**は、各特徴マップの空間次元全体を平均化して1つの値にする手法。**全結合層の代替**として出力層の直前に使用され、**解釈性を大幅に向上**させます。

#### 従来のCNN構造 vs GAP使用構造

**従来の構造（全結合層あり）**：
```
畳み込み層（複数）
    ↓ 出力: (H×W×C)の特徴マップ
全結合層（Flatten → Dense）
    ↓ パラメータ数: H×W×C × クラス数
出力層（Softmax）
    ↓
予測結果

問題点:
- パラメータ数が膨大（過学習のリスク）
- 特徴マップと出力クラスの対応関係が不明瞭
```

**GAP使用構造（解釈性向上）**：
```
畳み込み層（複数）
    ↓ 出力: (H×W×C)の特徴マップ
Global Average Pooling
    ↓ 各チャネルを1値に平均化: (1×1×C)
出力層（重み付き和 → Softmax）
    ↓
予測結果

利点:
- パラメータ数が大幅削減
- 各特徴マップとクラスの対応が明確
- 解釈性が向上（CAMで可視化可能）
```

#### GAPの計算方法

各特徴マップの空間次元全体で平均を取る：

$$\text{GAP}_k = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} f_k(i, j)$$

- $f_k$: 第$k$チャネルの特徴マップ
- $H, W$: 特徴マップの高さ・幅
- $\text{GAP}_k$: 第$k$チャネルの平均値（スカラー）

**具体例**：
```
特徴マップ（4×4）    GAP適用    出力（1値）
┌────────┐          
│2 3 1 4│          平均 = (2+3+1+4+
│1 2 5 3│                  1+2+5+3+
│4 1 2 1│                  4+1+2+1+
│3 2 3 2│                  3+2+3+2)/16
└────────┘                = 2.5
```

#### GAP使用のメリット（★試験重要）

✅ **1. 解釈性の向上（最大の特徴）**
- 各特徴マップ（チャネル）が特定クラスに対応
- Class Activation Mapping（CAM）で「どの領域が判断に寄与したか」を可視化可能
- 出力層の重みから各特徴マップの重要度が直接分かる

✅ **2. パラメータ数の大幅削減**
- 全結合層: 数百万～数千万パラメータ
- GAP: **パラメータゼロ**（平均演算のみ）
- 過学習のリスク低減

✅ **3. 入力サイズの柔軟性**
- 全結合層: 固定サイズの入力が必要
- GAP: 任意サイズの入力に対応可能

✅ **4. 空間的なロバスト性**
- 位置ずれに頑健（全体の平均を取るため）

❌ **GAPのデメリット（試験の引っ掛け）**：
- 精度が若干低下する場合がある（全結合層より表現力が限定的）
- 学習速度の高速化 → メリットではない（計算量はほぼ同じ）

#### Class Activation Mapping（CAM）

GAPを使用することで、**どの画像領域が判断に寄与したか**を可視化できます：

**CAMの計算手順**：
1. 最後の畳み込み層の特徴マップ: $f_k(i, j)$（$k$チャネル目）
2. GAP適用: $\text{GAP}_k = \frac{1}{HW}\sum_{i,j} f_k(i, j)$
3. 出力層の重み: $w_k^c$（$k$チャネルから$c$クラスへの重み）
4. クラス$c$のアクティベーションマップ: $$\text{CAM}^c(i, j) = \sum_k w_k^c \cdot f_k(i, j)$$

**可視化例**：
```
入力画像    →    畳み込み    →    CAM可視化
  犬の画像        特徴抽出       「犬」クラスに
                              寄与する領域が
                              ヒートマップで表示
                              （顔・体が強調）
```

#### 全結合層との比較表

| 項目 | 全結合層 | Global Average Pooling |
|------|---------|----------------------|
| **パラメータ数** | 非常に多い | ゼロ |
| **過学習リスク** | 高い | 低い |
| **解釈性** | 低い（ブラックボックス） | **高い（CAMで可視化可能）** |
| **入力サイズ** | 固定 | 可変 |
| **計算コスト** | 高い | 低い |
| **精度** | 高い（表現力が高い） | やや低い場合あり |
| **主な用途** | 一般的分類 | 解釈性重視の分類・物体位置特定 |

#### 代表的な応用例

**Network in Network（NIN, 2013）**：
- GAPを最初に提案した論文
- 全結合層を完全に排除

**GoogLeNet/Inception（2014）**：
- GAPで全結合層を削減
- パラメータ数を大幅削減（AlexNetの1/12）

**ResNet（2015）**：
- 最終層にGAPを使用
- 深い層でも学習安定

**CAM/Grad-CAM**：
- 医療画像診断での判断根拠可視化
- 品質検査での欠陥箇所特定

#### 注意点

**GAPが不向きなケース**：
- 細かい位置情報が必要なタスク（物体検出、セグメンテーション）
- 高精度が最優先のタスク（全結合層の方が精度高い場合あり）

**GAP使用のベストプラクティス**：
- 最後の畳み込み層のチャネル数 = クラス数にする設計が一般的
- Dropout等の正則化と併用で更に効果的

### 代表的なCNNアーキテクチャ

**LeNet-5 (1998)**：
- 手書き数字認識（MNIST）
- 畳み込み → プーリング → 全結合

**AlexNet (2012)**：
- ImageNet優勝（Top-5エラー率15.3%）
- ReLU、Dropout、GPU活用

**VGGNet (2014)**：
- 3×3フィルタの繰り返し
- 深さの重要性を実証（16-19層）

**ResNet (2015)**：
- 残差接続（Skip Connection）で152層を実現
- 勾配消失問題の解決

**Inception/GoogLeNet (2014)**：
- 複数サイズのフィルタを並列実行
- 1×1畳み込みで次元削減

### 実装例（擬似コード）

```python
# Kerasでの簡単なCNN
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])
```

## 試験での問われ方
- **典型設問**：
  - 「フィルタを移動させる幅を何と呼ぶか？」→ **ストライド（Stride）**
  - 「出力サイズを維持するための処理は？」→ **パディング（Padding）**
  - 「領域内の最大値を取る処理は？」→ **Max Pooling**
  - 「CNNが全結合層より優れる理由は？」→ パラメータ共有、局所受容野
  - 「Dilated Convolutionの主なメリットは？」→ **パラメータ数を増やさずに受容野を拡大**
  - 「全結合層に代わって解釈性を高める手法は？」→ **Global Average Pooling（GAP）**
  - 「MobileNetが計算負荷を削減した仕組みは？」→ **Depthwise Separable Convolution**
- **比較されやすい概念**：
  - **ストライド** vs **パディング**: 移動幅 vs 余白追加
  - **ストライド** vs **フィルタサイズ**: 移動幅 vs フィルタの大きさ
  - **Max Pooling** vs **Average Pooling**: 最大値 vs 平均値
  - **Max Pooling** vs **Global Average Pooling**: 局所的ダウンサンプリング vs 空間次元全体を1値に平均化
  - **CNN** vs **全結合NN**: パラメータ共有 vs 全結合
  - **畳み込み層** vs **プーリング層**: 特徴抽出 vs ダウンサンプリング
  - **全結合層** vs **Global Average Pooling**: パラメータ多数・解釈性低 vs パラメータゼロ・解釈性高
  - **通常の畳み込み** vs **Dilated Convolution**: 密な畳み込み vs 空間的に分散した畳み込み（パラメータ数同じ、受容野拡大）
  - **通常の畳み込み** vs **Depthwise Separable Convolution**: 一度に全処理 vs 2段階分離（計算量1/8～1/9）
- **引っ掛けポイント**：
  - 「フィルタの移動幅」→ **ストライド**（カーネルサイズではない）
  - 「入力の周囲に余白」→ **パディング**（ストライドではない）
  - ストライド大 → 出力サイズ**小**（大ではない）
  - パディング大 → 出力サイズ**大**（小ではない）
  - プーリングには**学習パラメータなし**（畳み込み層にはあり）
  - **Dilated Convolutionの引っ掛け**：
    - ✅ パラメータ数を増やさず受容野拡大 = **正しいメリット**
    - ✅ 解像度を保ちながら広域情報獲得 = **正しいメリット**
    - ❌ 学習速度の高速化 = メリットではない（計算コストはほぼ同じ）
    - ❌ パラメータ数削減 = 削減しない（フィルタサイズ同じなら同数）
    - ❌ 小物体検出の向上 = 広域情報向き、小物体には不向き
  - **Global Average Poolingの引っ掛け**：
    - ✅ 解釈性の向上（特徴マップと出力クラスの対応が明確） = **最大のメリット**
    - ✅ パラメータ数削減 = **正しいメリット**（パラメータゼロ）
    - ✅ 過学習抑制 = **正しいメリット**
    - ❌ 精度向上 = メリットではない（全結合層より精度は低い場合あり）
    - ❌ 学習速度の高速化 = メリットではない
- **頻出パターン**：
  - 出力サイズの計算（ストライド・パディングの影響）
  - CNNの構造順序（畳み込み→活性化→プーリング）
  - パラメータ数の比較（CNN vs 全結合、通常 vs Dilated）
  - 各層の役割（特徴抽出 vs ダウンサンプリング vs 分類）
  - Dilated Convolutionの受容野計算：$R = (K-1) \times r + 1$

## 補足
- **実務的観点**：
  - 画像認識では転移学習が主流（ResNet、EfficientNet等の事前学習済みモデル）
  - ストライド2の畳み込みでプーリング層を代替する設計も増加
  - Data Augmentation（データ拡張）で過学習対策
  - Batch Normalizationで学習安定化・高速化
  - 1×1畳み込みでチャネル数削減（計算量削減）
  - Dilated ConvolutionはDeepLab（セグメンテーション）、WaveNet（音声）で実用
  - Global Average Poolingは解釈性重視の用途（医療診断、品質検査等）で有効
  - CAM/Grad-CAMで判断根拠の可視化が可能
- **関連トピック**：
  - [ニューラルネットワーク基礎](neural_network_basics.md) - 活性化関数、誤差逆伝播
  - [画像認識](../07_ai_applications/image_recognition.md) - CNNの応用
  - [過学習対策](../05_machine_learning/overfitting_underfitting.md) - Dropout、正則化
  - [RNN](rnn.md) - 系列データ向けの構造
- **発展**：
  - Attention機構（Vision Transformer）
  - Dilated/Atrous Convolution（受容野拡大）← 本ページで説明
  - Depthwise Separable Convolution（軽量化）← 本ページで説明
  - Semantic Segmentation（U-Net、FCN、DeepLab）

---

## 軽量化CNN：Depthwise Separable Convolution

### 背景と必要性

**モバイル端末での課題**：
- 計算リソース（CPU/GPU）の制約
- メモリ容量の制限
- バッテリー消費の問題
- リアルタイム処理の要求

**軽量化CNNの登場**：
- **MobileNet（Google, 2017）**：モバイル端末向けの軽量化モデル
- **ShuffleNet（2018）**：チャネルシャッフルによる軽量化
- **EfficientNet（2019）**：精度と効率のバランス最適化

### Depthwise Separable Convolution（深さ方向分離可能畳み込み）

**定義**：
通常の畳み込みを**2つのステップに分離**することで計算量を大幅に削減する手法。

#### ステップ1：Depthwise Convolution（深さ方向畳み込み）

**仕組み**：
- 各チャネルに対して**独立に**空間方向（横×縦）の畳み込みを実行
- チャネル間の情報は混合しない

**処理イメージ**：
```
入力：H×W×C（高さ×幅×チャネル数）
     ↓
各チャネルごとに3×3フィルタで畳み込み
（Cチャネル → Cチャネル、チャネル数不変）
     ↓
出力：H'×W'×C
```

**特徴**：
- フィルタサイズ：K×K×1（チャネル方向の深さは1）
- フィルタ数：C個（入力チャネル数と同じ）
- 計算量：$H' \times W' \times K^2 \times C$

#### ステップ2：Pointwise Convolution（点ごと畳み込み）

**仕組み**：
- 1×1畳み込みでチャネル間の情報を混合
- 空間方向の処理はせず、各位置でチャネル次元の線形結合

**処理イメージ**：
```
入力：H'×W'×C
     ↓
1×1×C×Mフィルタで畳み込み
（Cチャネル → Mチャネル、チャネル数変換）
     ↓
出力：H'×W'×M
```

**特徴**：
- フィルタサイズ：1×1×C×M
- フィルタ数：M個（出力チャネル数）
- 計算量：$H' \times W' \times C \times M$

### 計算量の比較

#### 通常の畳み込み

```
入力：H×W×C
フィルタ：K×K×C×M
出力：H'×W'×M
```

**計算量**：
$$\text{通常} = H' \times W' \times K^2 \times C \times M$$

#### Depthwise Separable Convolution

**計算量**：
$$\text{Depthwise Separable} = H' \times W' \times (K^2 \times C + C \times M)$$

**削減率**：
$$\frac{\text{Depthwise Separable}}{\text{通常}} = \frac{K^2 \times C + C \times M}{K^2 \times C \times M} = \frac{1}{M} + \frac{1}{K^2}$$

**具体例**（K=3, M=128の場合）：
$$\frac{1}{128} + \frac{1}{9} \approx 0.119 \approx \frac{1}{8.4}$$

**結果**：通常の畳み込みの**約1/8～1/9の計算量**

### MobileNetの構造

**基本ブロック**：
```
Depthwise Convolution (3×3)
  ↓
Batch Normalization
  ↓
ReLU
  ↓
Pointwise Convolution (1×1)
  ↓
Batch Normalization
  ↓
ReLU
```

**全体構造**：
1. 通常の畳み込み層（最初の1層のみ）
2. Depthwise Separable Convolutionブロック × 13層
3. Average Pooling
4. 全結合層（分類）

**特徴**：
- パラメータ数：約420万（AlexNetの約1/15）
- 計算量：約0.57 GFLOPS（AlexNetの約1/20）
- ImageNet精度：Top-1約70%（通常CNNの90%程度の精度）

### MobileNetのバリエーション

| モデル | 年 | 主な改良点 |
|--------|-----|------------|
| **MobileNet v1** | 2017 | Depthwise Separable Convolutionの導入 |
| **MobileNet v2** | 2018 | Inverted Residual、Linear Bottleneck |
| **MobileNet v3** | 2019 | NAS（Neural Architecture Search）で構造最適化 |

**MobileNet v2の改良**：
- **Inverted Residual**：狭→広→狭（通常のResidualは逆）
- **Linear Bottleneck**：最後の層は活性化関数なし（情報保持）

### 計算量削減の具体例

**設定**：
- 入力：56×56×64
- フィルタ：3×3
- 出力：56×56×128

#### 通常の畳み込み

計算量：$56 \times 56 \times 3^2 \times 64 \times 128 = 231,211,008$ 回

#### Depthwise Separable Convolution

**Depthwise Convolution**：
$56 \times 56 \times 3^2 \times 64 = 1,806,336$ 回

**Pointwise Convolution**：
$56 \times 56 \times 64 \times 128 = 25,690,112$ 回

**合計**：$1,806,336 + 25,690,112 = 27,496,448$ 回

**削減率**：$\frac{27,496,448}{231,211,008} \approx 0.119 \approx \frac{1}{8.4}$

### 他の軽量化手法との比較

| 手法 | 原理 | 計算量削減 | 精度 |
|------|------|------------|------|
| **Depthwise Separable** | 畳み込みを2段階に分離 | 1/8～1/9 | 高（90%程度維持） |
| **1×1畳み込み** | チャネル数削減 | 中程度 | 高 |
| **Group Convolution** | チャネルをグループ分割 | 1/g（g=グループ数） | 中～高 |
| **Pruning** | 不要な重みを削除 | 可変 | 再学習で回復 |
| **Quantization** | パラメータの精度削減 | メモリ1/4 | わずかに低下 |

**Depthwise Separableの利点**：
- ✅ 精度低下が小さい（通常CNNの90%程度）
- ✅ 学習が安定（構造が単純）
- ✅ 実装が容易（標準的なフレームワークでサポート）

**欠点**：
- ❌ 小さいモデルでは効果が限定的（チャネル数が少ない場合）
- ❌ ハードウェア最適化が必要（GPUよりCPU/モバイルで真価）

### 試験での問われ方

#### 典型問題：MobileNetの計算量削減手法

> 「MobileNetは2017年にGoogleから発表されたモデルであり、モバイル端末でも学習できるほどに計算負荷が低いことが特徴です。この計算負荷を削減した仕組みとして、最も適切な選択肢を1つ選べ。」

✅ **正解**：Depthwise Separable Convolution（深さ方向分離可能畳み込み）

❌ **不適切な選択肢**：
- 「活性化関数にSigmoidを使用」→ReLUを使用（Sigmoidは関係ない）
- 「Pooling層を削除」→Pooling層は使用している
- 「全結合層を複数段重ねる」→逆に計算量増加
- 「バッチサイズを大きくする」→学習時の工夫（モデル構造ではない）

#### 詳細パターン：Depthwise Separable Convolutionの説明

> 「Depthwise Separable Convolutionに関する説明として、最も適切な選択肢を1つ選べ。」

✅ **正解の選択肢**：
- 「通常の畳み込みをDepthwise ConvolutionとPointwise Convolutionの2段階に分離」
- 「Depthwise Convolutionでは各チャネルに対して独立に空間方向の畳み込みを実行」
- 「Pointwise Convolutionは1×1畳み込みでチャネル間の情報を混合」
- 「計算量を通常の畳み込みの約1/8～1/9に削減」
- 「MobileNetの中核技術として採用」

❌ **不適切な選択肢（混同注意）**：
- 「パラメータ数が増加する代わりに精度が向上」→逆（パラメータ削減）
- 「Dilated Convolutionと同じ技術」→別の技術（Dilatedは受容野拡大）
- 「チャネル数を増やすことで計算量削減」→逆（チャネル数減少で削減）
- 「Pooling層の一種」→畳み込み層の改良手法

#### ひっかけポイント

| ひっかけ | 正しい理解 |
|----------|------------|
| ❌ 精度が大幅に向上 | ✅ 精度は若干低下（計算量削減とのトレードオフ） |
| ❌ パラメータ数増加 | ✅ パラメータ数削減（通常の約1/8） |
| ❌ Dilated Convolutionと同じ | ✅ 別の技術（Depthwise Separable=軽量化、Dilated=受容野拡大） |
| ❌ Pooling層の代替 | ✅ 畳み込み層の改良（Poolingとは無関係） |
| ❌ サーバー向けの技術 | ✅ モバイル・エッジデバイス向け |

### 実用例

**スマートフォンアプリ**：
- 顔認識（Face ID、顔検出）
- 物体検出（カメラアプリ）
- リアルタイム翻訳（OCR）
- AR（拡張現実）アプリ

**エッジデバイス**：
- 監視カメラ（リアルタイム解析）
- ドローン（自律飛行）
- IoTセンサー（異常検知）
- ロボット（物体認識）

**採用事例**：
- TensorFlow Lite（Google）
- PyTorch Mobile（Meta）
- Core ML（Apple）
- ONNX Runtime（Microsoft）

---

## 補足（更新）

- **実務的観点**：
  - 画像認識では転移学習が主流（ResNet、EfficientNet等の事前学習済みモデル）
  - ストライド2の畳み込みでプーリング層を代替する設計も増加
  - Data Augmentation（データ拡張）で過学習対策
  - Batch Normalizationで学習安定化・高速化
  - 1×1畳み込みでチャネル数削減（計算量削減）
  - Dilated ConvolutionはDeepLab（セグメンテーション）、WaveNet（音声）で実用
  - Global Average Poolingは解釈性重視の用途（医療診断、品質検査等）で有効
  - CAM/Grad-CAMで判断根拠の可視化が可能
  - **Depthwise Separable ConvolutionはMobileNet系モデルで標準採用、モバイル・エッジAIの基盤技術**
- **関連トピック**：
  - [ニューラルネットワーク基礎](neural_network_basics.md) - 活性化関数、誤差逆伝播
  - [画像認識](../07_ai_applications/image_recognition.md) - CNNの応用
  - [過学習対策](../05_machine_learning/overfitting_underfitting.md) - Dropout、正則化
  - [RNN](rnn.md) - 系列データ向けの構造
- **発展**：
  - Attention機構（Vision Transformer）
  - Dilated/Atrous Convolution（受容野拡大）← 本ページで説明
  - Depthwise Separable Convolution（軽量化）← 本ページで説明
  - Semantic Segmentation（U-Net、FCN、DeepLab）
