# 畳み込みニューラルネットワーク（CNN）

## 要点
- 画像認識に特化した深層学習モデル。畳み込み層とプーリング層で特徴抽出。
- **ストライド**はフィルタの移動幅、**パディング**は入力の余白追加で出力サイズを調整。
- パラメータ共有と局所受容野で、全結合層より少ないパラメータで高精度を実現。

## 定義
畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）は、画像データに対して**畳み込み層（Convolutional Layer）**と**プーリング層（Pooling Layer）**を組み合わせ、空間的な特徴を階層的に抽出するニューラルネットワーク。1998年のLeNet-5が起源。

## 重要キーワード
- **畳み込み層（Convolutional Layer）**: フィルタ（カーネル）で局所的特徴を抽出。
- **フィルタ（カーネル）**: 重み行列。画像上をスライドして特徴マップを生成。
- **ストライド（Stride）**: フィルタを移動させる幅（ピクセル数）。★重要
- **パディング（Padding）**: 入力画像の周囲に余白を追加（ゼロパディング等）。
- **特徴マップ（Feature Map）**: 畳み込み演算の出力。
- **プーリング層（Pooling Layer）**: 特徴マップのダウンサンプリング（Max/Average Pooling）。
- **受容野（Receptive Field）**: 各ニューロンが参照する入力領域。
- **パラメータ共有（Weight Sharing）**: 同じフィルタを全領域で使用。
- **局所結合（Local Connectivity）**: 全結合でなく局所的に結合。
- **チャネル（Channel）**: RGB画像なら3チャネル、中間層では複数の特徴マップ。
- **全結合層（Fully Connected Layer）**: CNN最終段で分類を行う。

## 詳細

### 背景と直観
CNNは1980年代の新古典派理論（Neocognitron, Fukushima）や、1998年のLeCunによるLeNet-5を起源とし、2012年のAlexNet以降、画像認識の主流となりました。

**基本的な考え方**：
- 画像の**空間構造**を保持しながら特徴抽出
- **局所的なパターン**（エッジ、テクスチャ等）を階層的に学習
- 全結合層より**パラメータ数を削減**し過学習を抑制

### CNNの基本構造

```
入力画像
  ↓
[畳み込み層 → 活性化(ReLU) → プーリング層] × 複数回
  ↓
[全結合層] × 複数回
  ↓
出力層（Softmax）
```

**典型例（AlexNet風）**：
```
入力(224×224×3)
 → Conv(96 filters) → ReLU → MaxPool
 → Conv(256 filters) → ReLU → MaxPool
 → Conv(384 filters) → ReLU
 → Conv(384 filters) → ReLU
 → Conv(256 filters) → ReLU → MaxPool
 → FC(4096) → ReLU → Dropout
 → FC(4096) → ReLU → Dropout
 → FC(1000) → Softmax
```

### 畳み込み層の詳細

#### 畳み込み演算
フィルタ（例：3×3の重み行列）を入力画像上でスライドさせ、要素ごとの積和を計算：

$$S(i,j) = \sum_{m}\sum_{n} I(i+m, j+n) \cdot K(m,n)$$

- $I$: 入力画像
- $K$: フィルタ（カーネル）
- $S$: 特徴マップ（出力）

#### 図解：畳み込み演算（3×3フィルタ）
```
入力画像（5×5）    フィルタ（3×3）
┌─────────┐    ┌─────┐
│1 2 3 4 5│    │1 0 1│
│2 3 4 5 6│ ⊗  │0 1 0│
│3 4 5 6 7│    │1 0 1│
│4 5 6 7 8│    └─────┘
│5 6 7 8 9│
└─────────┘
       ↓
出力（3×3）※ストライド1、パディング0
┌───────┐
│28 34 40│
│38 44 50│
│48 54 60│
└───────┘
```

### ストライド（Stride）★重要

#### 定義
**ストライド**は、フィルタを入力画像上で移動させる際の**移動幅（ピクセル数）**。

#### 影響
- **ストライド1**: 1ピクセルずつ移動（細かく特徴抽出）
- **ストライド2**: 2ピクセルずつ移動（出力サイズが約半分）
- ストライド大 → **出力サイズ小**、**計算量減**

#### 図解：ストライドの違い
```
ストライド1（1ピクセル移動）
┌─┬─┬─┬─┐
│■│■│ │ │  →  ┌─┬─┬─┐
├─┼─┼─┼─┤     │1│2│3│  
│ │■│■│ │  →  └─┴─┴─┘
├─┼─┼─┼─┤     出力: 3×3
│ │ │■│■│
└─┴─┴─┴─┘

ストライド2（2ピクセル移動）
┌─┬─┬─┬─┐
│■│■│ │ │  →  ┌─┬─┐
├─┼─┼─┼─┤     │1│2│  
│ │ │■│■│  →  └─┴─┘
└─┴─┴─┴─┘     出力: 2×2
```

#### 出力サイズの計算式
$$\text{出力サイズ} = \left\lfloor \frac{W - F + 2P}{S} \right\rfloor + 1$$

- $W$: 入力サイズ
- $F$: フィルタサイズ
- $P$: パディング
- $S$: ストライド

**計算例1**：
- 入力: 5×5
- フィルタ: 3×3
- パディング: 0
- ストライド: 1
- 出力: $(5 - 3 + 0) / 1 + 1 = 3$×3

**計算例2**（試験頻出パターン）：
- 入力: **11×11**
- フィルタ: **3×3**
- パディング: **2**
- ストライド: **2**
- 計算: $(11 + 2 \times 2 - 3) / 2 + 1 = (11 + 4 - 3) / 2 + 1 = 12 / 2 + 1 = 6 + 1 = 7$
- 出力: **7×7**

### パディング（Padding）

#### 定義
入力画像の周囲に余白（通常は0）を追加すること。

#### 目的
- **出力サイズの維持**（入力と同サイズに保つ）
- **端の情報の保持**（パディングなしでは端が失われる）

#### タイプ
- **Valid Padding**: パディングなし（出力サイズ減）
- **Same Padding**: 出力サイズ = 入力サイズになるよう調整
- **ゼロパディング**: 0で埋める（最も一般的）

#### 図解：パディング
```
入力（3×3）  →  パディング1  →  5×5
┌───┐       ┌─────────┐
│1 2│       │0 0 0 0 0│
│3 4│       │0 1 2 3 0│
└───┘       │0 4 5 6 0│
            │0 7 8 9 0│
            │0 0 0 0 0│
            └─────────┘
```

### プーリング層（Pooling Layer）

#### 目的
- **ダウンサンプリング**（特徴マップの縮小）
- **位置不変性**の獲得（微小な位置ずれに頑健）
- 計算量削減

#### 種類
**Max Pooling**（最も一般的）：
- 領域内の最大値を取得
```
入力（4×4）    Max Pooling(2×2, stride=2)
┌───────┐    ┌───┐
│1 3 2 4│    │3 4│
│5 6 1 2│ →  │8 7│
│7 8 3 5│    └───┘
│4 2 6 7│
└───────┘
```

**Average Pooling**：
- 領域内の平均値を取得

#### Max/Average Pooling vs Global Average Pooling（★重要な違い）

通常のプーリング（Max/Average Pooling）とGlobal Average Pooling（GAP）は**目的と適用範囲が全く異なる**手法です：

| 項目 | Max/Average Pooling | Global Average Pooling |
|------|-------------------|----------------------|
| **適用範囲** | 局所領域（2×2、3×3等） | **特徴マップ全体**（H×W全体） |
| **目的** | ダウンサンプリング | 全結合層の代替・解釈性向上 |
| **出力サイズ** | 入力より小さい特徴マップ | **チャネルごとに1値**（ベクトル） |
| **ネットワーク内の位置** | 中間層（畳み込み層の後） | **出力層の直前**（最終層） |
| **パラメータ数** | ゼロ | ゼロ |
| **空間情報** | 保持される（縮小） | **完全に失われる**（平均化） |
| **主な効果** | 位置不変性・計算量削減 | 解釈性向上・過学習抑制 |
| **可視化** | 不可 | **CAMで可視化可能** |

**具体例で見る違い**：

```
入力特徴マップ（4×4）
┌───────┐
│1 3 2 4│
│5 6 1 2│
│7 8 3 5│
│4 2 6 7│
└───────┘

↓ Max Pooling(2×2, stride=2) ← 局所領域の最大値
┌───┐
│6 4│  出力: 2×2の特徴マップ（空間情報は保持）
│8 7│
└───┘

↓ Average Pooling(2×2, stride=2) ← 局所領域の平均値
┌──────┐
│3.75 2.25│  出力: 2×2の特徴マップ（空間情報は保持）
│5.25 5.25│
└──────┘

↓ Global Average Pooling ← 全体の平均値
[4.125]  出力: 1つの値（空間情報は失われる）
```

**使い分けのポイント**：
- **Max/Average Pooling**: ネットワーク中間層で特徴抽出を続ける場合
- **Global Average Pooling**: 最終層で分類する際、解釈性を重視する場合

**試験での引っ掛け**：
- ❌ 「GAPは局所領域のプーリング」→ 誤り（全体を平均化）
- ❌ 「Max Poolingで解釈性向上」→ 誤り（解釈性向上はGAPの特徴）
- ❌ 「GAPは中間層で使用」→ 誤り（出力層直前で使用）
- ✅ 「GAPは全結合層の代替」→ 正しい
- ✅ 「Max Poolingはダウンサンプリング」→ 正しい

### パラメータ共有と局所結合

#### パラメータ共有
- 同じフィルタを画像全体で使用
- 例：3×3フィルタ → パラメータ数は9個（位置によらず）
- 全結合層なら: 100×100画像で10,000個のパラメータ

#### 利点
- **パラメータ数の大幅削減**
- **過学習の抑制**
- **平行移動不変性**（物体の位置が変わっても認識可能）

### 受容野（Receptive Field）

各層のニューロンが参照する入力領域：
```
畳み込み1層目: 3×3の局所領域
畳み込み2層目: より広い領域（例：5×5、7×7）
深い層ほど広い受容野 → 大域的特徴の抽出
```

### Dilated Convolution（拡張畳み込み/空間的畳み込み）

#### 定義
**Dilated Convolution（Atrous Convolution）**は、フィルタの要素間に「穴（空白）」を開けることで、**パラメータ数を増やさずに受容野を拡大**する畳み込み手法。Dilation Rate（拡張率）$r$ で穴の間隔を制御します。

#### 通常の畳み込みとの違い

**通常の畳み込み（Dilation Rate = 1）**：
```
3×3フィルタ（受容野: 3×3）
┌─┬─┬─┐
│●│●│●│
├─┼─┼─┤
│●│●│●│
├─┼─┼─┤
│●│●│●│
└─┴─┴─┘
パラメータ数: 9個
```

**Dilated Convolution（Dilation Rate = 2）**：
```
3×3フィルタが実質5×5の受容野をカバー
┌─┬─┬─┬─┬─┐
│●│ │●│ │●│
├─┼─┼─┼─┼─┤
│ │ │ │ │ │
├─┼─┼─┼─┼─┤
│●│ │●│ │●│
├─┼─┼─┼─┼─┤
│ │ │ │ │ │
├─┼─┼─┼─┼─┤
│●│ │●│ │●│
└─┴─┴─┴─┴─┘
パラメータ数: 9個（変わらず）
受容野: 5×5（拡大！）
```

#### Dilated Convolutionの計算式

受容野のサイズ：
$$R = (K - 1) \times r + 1$$

- $K$: フィルタサイズ（例：3×3なら $K=3$）
- $r$: Dilation Rate（拡張率）
- $R$: 実効受容野サイズ

**計算例**：
| フィルタサイズ | Dilation Rate | 受容野サイズ |
|------------|--------------|----------|
| 3×3 | r=1（通常） | 3×3 |
| 3×3 | r=2 | 5×5 |
| 3×3 | r=3 | 7×7 |
| 3×3 | r=4 | 9×9 |

#### Dilated Convolution特有のメリット（★試験重要）

通常の畳み込みと比較した際の主なメリット：

✅ **1. パラメータ数を増やさずに受容野を拡大**
- 最大の特徴：3×3フィルタのパラメータ数（9個）のまま、受容野を5×5、7×7に拡大可能
- 通常の5×5畳み込み: 25パラメータ、Dilated 3×3（r=2）: 9パラメータで同等の受容野

✅ **2. 計算量を増やさずに広域的な文脈情報を獲得**
- プーリング層なしで受容野拡大が可能
- セグメンテーションタスクで解像度を維持しながら広域情報を利用

✅ **3. 解像度の低下を防ぐ**
- プーリング層を使わないため、空間解像度が保持される
- セマンティックセグメンテーション（DeepLab等）で重要

❌ **メリットではないもの（試験の引っ掛け）**：
- 学習速度の高速化 → メリットではない（計算コストはほぼ同じ）
- パラメータ数の削減による過学習抑制 → パラメータ数は変わらない
- 小さい物体の検出精度向上 → 広域情報向き、小物体には不向き

#### 代表的な応用例

**DeepLab（セマンティックセグメンテーション）**：
- Atrous Spatial Pyramid Pooling (ASPP)でマルチスケール特徴抽出
- Dilation Rate = {6, 12, 18}の並列畳み込み

**WaveNet（音声生成）**：
- 時系列データで長距離依存関係を効率的に学習
- 指数的に増加するDilation Rate: 1, 2, 4, 8, 16, ...

#### 図解：複数層でのDilated Convolution

```
層1（r=1）: ●─●─●  受容野3
           
層2（r=2）: ●──●──●  受容野7（累積）

層3（r=4）: ●────●────●  受容野15（累積）

→ 3層で受容野15倍に拡大（パラメータは3×9=27個のみ）
```

#### 通常の畳み込みとの比較表

| 項目 | 通常の畳み込み | Dilated Convolution |
|------|-------------|-------------------|
| **パラメータ数** | フィルタサイズに比例 | フィルタサイズに比例（同じ） |
| **受容野拡大** | 層を深くするorフィルタサイズ増 | Dilation Rateで調整 |
| **解像度** | プーリング併用で低下 | 保持可能 |
| **計算効率** | 標準 | 同等 |
| **主な用途** | 一般的画像認識 | セグメンテーション、音声 |

#### 注意点

**Gridding Artifact（格子状のアーティファクト）**：
- Dilation Rateが大きすぎると、サンプリング点が離れすぎて情報が欠落
- 対策: Hybrid Dilated Convolution（異なるrateを組み合わせ）

### Global Average Pooling（GAP）と解釈性の向上

#### 定義
**Global Average Pooling（GAP、大域平均プーリング）**は、各特徴マップの空間次元全体を平均化して1つの値にする手法。**全結合層の代替**として出力層の直前に使用され、**解釈性を大幅に向上**させます。

#### 従来のCNN構造 vs GAP使用構造

**従来の構造（全結合層あり）**：
```
畳み込み層（複数）
    ↓ 出力: (H×W×C)の特徴マップ
全結合層（Flatten → Dense）
    ↓ パラメータ数: H×W×C × クラス数
出力層（Softmax）
    ↓
予測結果

問題点:
- パラメータ数が膨大（過学習のリスク）
- 特徴マップと出力クラスの対応関係が不明瞭
```

**GAP使用構造（解釈性向上）**：
```
畳み込み層（複数）
    ↓ 出力: (H×W×C)の特徴マップ
Global Average Pooling
    ↓ 各チャネルを1値に平均化: (1×1×C)
出力層（重み付き和 → Softmax）
    ↓
予測結果

利点:
- パラメータ数が大幅削減
- 各特徴マップとクラスの対応が明確
- 解釈性が向上（CAMで可視化可能）
```

#### GAPの計算方法

各特徴マップの空間次元全体で平均を取る：

$$\text{GAP}_k = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} f_k(i, j)$$

- $f_k$: 第$k$チャネルの特徴マップ
- $H, W$: 特徴マップの高さ・幅
- $\text{GAP}_k$: 第$k$チャネルの平均値（スカラー）

**具体例**：
```
特徴マップ（4×4）    GAP適用    出力（1値）
┌────────┐          
│2 3 1 4│          平均 = (2+3+1+4+
│1 2 5 3│                  1+2+5+3+
│4 1 2 1│                  4+1+2+1+
│3 2 3 2│                  3+2+3+2)/16
└────────┘                = 2.5
```

#### GAP使用のメリット（★試験重要）

✅ **1. 解釈性の向上（最大の特徴）**
- 各特徴マップ（チャネル）が特定クラスに対応
- Class Activation Mapping（CAM）で「どの領域が判断に寄与したか」を可視化可能
- 出力層の重みから各特徴マップの重要度が直接分かる

✅ **2. パラメータ数の大幅削減**
- 全結合層: 数百万～数千万パラメータ
- GAP: **パラメータゼロ**（平均演算のみ）
- 過学習のリスク低減

✅ **3. 入力サイズの柔軟性**
- 全結合層: 固定サイズの入力が必要
- GAP: 任意サイズの入力に対応可能

✅ **4. 空間的なロバスト性**
- 位置ずれに頑健（全体の平均を取るため）

❌ **GAPのデメリット（試験の引っ掛け）**：
- 精度が若干低下する場合がある（全結合層より表現力が限定的）
- 学習速度の高速化 → メリットではない（計算量はほぼ同じ）

#### Class Activation Mapping（CAM）

GAPを使用することで、**どの画像領域が判断に寄与したか**を可視化できます：

**CAMの計算手順**：
1. 最後の畳み込み層の特徴マップ: $f_k(i, j)$（$k$チャネル目）
2. GAP適用: $\text{GAP}_k = \frac{1}{HW}\sum_{i,j} f_k(i, j)$
3. 出力層の重み: $w_k^c$（$k$チャネルから$c$クラスへの重み）
4. クラス$c$のアクティベーションマップ: $$\text{CAM}^c(i, j) = \sum_k w_k^c \cdot f_k(i, j)$$

**可視化例**：
```
入力画像    →    畳み込み    →    CAM可視化
  犬の画像        特徴抽出       「犬」クラスに
                              寄与する領域が
                              ヒートマップで表示
                              （顔・体が強調）
```

#### 全結合層との比較表

| 項目 | 全結合層 | Global Average Pooling |
|------|---------|----------------------|
| **パラメータ数** | 非常に多い | ゼロ |
| **過学習リスク** | 高い | 低い |
| **解釈性** | 低い（ブラックボックス） | **高い（CAMで可視化可能）** |
| **入力サイズ** | 固定 | 可変 |
| **計算コスト** | 高い | 低い |
| **精度** | 高い（表現力が高い） | やや低い場合あり |
| **主な用途** | 一般的分類 | 解釈性重視の分類・物体位置特定 |

#### 代表的な応用例

**Network in Network（NIN, 2013）**：
- GAPを最初に提案した論文
- 全結合層を完全に排除

**GoogLeNet/Inception（2014）**：
- GAPで全結合層を削減
- パラメータ数を大幅削減（AlexNetの1/12）

**ResNet（2015）**：
- 最終層にGAPを使用
- 深い層でも学習安定

**CAM/Grad-CAM**：
- 医療画像診断での判断根拠可視化
- 品質検査での欠陥箇所特定

#### 注意点

**GAPが不向きなケース**：
- 細かい位置情報が必要なタスク（物体検出、セグメンテーション）
- 高精度が最優先のタスク（全結合層の方が精度高い場合あり）

**GAP使用のベストプラクティス**：
- 最後の畳み込み層のチャネル数 = クラス数にする設計が一般的
- Dropout等の正則化と併用で更に効果的

### 代表的なCNNアーキテクチャ

**LeNet-5 (1998)**：
- 手書き数字認識（MNIST）
- 畳み込み → プーリング → 全結合

**AlexNet (2012)**：
- ImageNet優勝（Top-5エラー率15.3%）
- ReLU、Dropout、GPU活用

**VGGNet (2014)**：
- 3×3フィルタの繰り返し
- 深さの重要性を実証（16-19層）

**ResNet (2015)**：
- 残差接続（Skip Connection）で152層を実現
- 勾配消失問題の解決

**Inception/GoogLeNet (2014)**：
- 複数サイズのフィルタを並列実行
- 1×1畳み込みで次元削減

### 実装例（擬似コード）

```python
# Kerasでの簡単なCNN
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])
```

## 試験での問われ方
- **典型設問**：
  - 「フィルタを移動させる幅を何と呼ぶか？」→ **ストライド（Stride）**
  - 「出力サイズを維持するための処理は？」→ **パディング（Padding）**
  - 「領域内の最大値を取る処理は？」→ **Max Pooling**
  - 「CNNが全結合層より優れる理由は？」→ パラメータ共有、局所受容野
  - 「Dilated Convolutionの主なメリットは？」→ **パラメータ数を増やさずに受容野を拡大**
  - 「全結合層に代わって解釈性を高める手法は？」→ **Global Average Pooling（GAP）**
  - 「MobileNetが計算負荷を削減した仕組みは？」→ **Depthwise Separable Convolution**
- **出力サイズ計算問題（頻出）**：
  > 「畳み込み層において、入力サイズ11×11、パディング幅2、カーネル幅3×3、ストライド2の場合の出力サイズは？」
  
  **解答手順**：
  1. 公式を適用: $(W + 2P - F) / S + 1$
  2. 代入: $(11 + 2×2 - 3) / 2 + 1$
  3. 計算: $(11 + 4 - 3) / 2 + 1 = 12 / 2 + 1 = 6 + 1$
  4. 答え: **7×7**
  
  **計算のコツ**：
  - パディング幅は「2倍」する（上下または左右に追加されるため）
  - ストライドが大きいほど出力は小さくなる
  - 小数点以下は切り捨て（床関数）
  
  **よくある誤答**：
  - ❌ 6×6 → ストライド除算後に「+1」を忘れた
  - ❌ 13×13 → パディングを2倍せず「2」のまま計算した
  - ❌ 5×5 → パディングを引き算した（正しくは足し算）

- **比較されやすい概念**：
  - **ストライド** vs **パディング**: 移動幅 vs 余白追加
  - **ストライド** vs **フィルタサイズ**: 移動幅 vs フィルタの大きさ
  - **Max Pooling** vs **Average Pooling**: 最大値 vs 平均値
  - **Max Pooling** vs **Global Average Pooling**: 局所的ダウンサンプリング vs 空間次元全体を1値に平均化
  - **CNN** vs **全結合NN**: パラメータ共有 vs 全結合
  - **畳み込み層** vs **プーリング層**: 特徴抽出 vs ダウンサンプリング
  - **全結合層** vs **Global Average Pooling**: パラメータ多数・解釈性低 vs パラメータゼロ・解釈性高
  - **通常の畳み込み** vs **Dilated Convolution**: 密な畳み込み vs 空間的に分散した畳み込み（パラメータ数同じ、受容野拡大）
  - **通常の畳み込み** vs **Depthwise Separable Convolution**: 一度に全処理 vs 2段階分離（計算量1/8～1/9）
- **引っ掛けポイント**：
  - 「フィルタの移動幅」→ **ストライド**（カーネルサイズではない）
  - 「入力の周囲に余白」→ **パディング**（ストライドではない）
  - ストライド大 → 出力サイズ**小**（大ではない）
  - パディング大 → 出力サイズ**大**（小ではない）
  - プーリングには**学習パラメータなし**（畳み込み層にはあり）
  - **Dilated Convolutionの引っ掛け**：
    - ✅ パラメータ数を増やさず受容野拡大 = **正しいメリット**
    - ✅ 解像度を保ちながら広域情報獲得 = **正しいメリット**
    - ❌ 学習速度の高速化 = メリットではない（計算コストはほぼ同じ）
    - ❌ パラメータ数削減 = 削減しない（フィルタサイズ同じなら同数）
    - ❌ 小物体検出の向上 = 広域情報向き、小物体には不向き
  - **Global Average Poolingの引っ掛け**：
    - ✅ 解釈性の向上（特徴マップと出力クラスの対応が明確） = **最大のメリット**
    - ✅ パラメータ数削減 = **正しいメリット**（パラメータゼロ）
    - ✅ 過学習抑制 = **正しいメリット**
    - ❌ 精度向上 = メリットではない（全結合層より精度は低い場合あり）
    - ❌ 学習速度の高速化 = メリットではない
- **頻出パターン**：
  - 出力サイズの計算（ストライド・パディングの影響）
  - CNNの構造順序（畳み込み→活性化→プーリング）
  - パラメータ数の比較（CNN vs 全結合、通常 vs Dilated）
  - 各層の役割（特徴抽出 vs ダウンサンプリング vs 分類）
  - Dilated Convolutionの受容野計算：$R = (K-1) \times r + 1$

## 補足
- **実務的観点**：
  - 画像認識では転移学習が主流（ResNet、EfficientNet等の事前学習済みモデル）
  - ストライド2の畳み込みでプーリング層を代替する設計も増加
  - Data Augmentation（データ拡張）で過学習対策
  - Batch Normalizationで学習安定化・高速化
  - 1×1畳み込みでチャネル数削減（計算量削減）
  - Dilated ConvolutionはDeepLab（セグメンテーション）、WaveNet（音声）で実用
  - Global Average Poolingは解釈性重視の用途（医療診断、品質検査等）で有効
  - CAM/Grad-CAMで判断根拠の可視化が可能
- **関連トピック**：
  - [ニューラルネットワーク基礎](neural_network_basics.md) - 活性化関数、誤差逆伝播
  - [画像認識](../07_ai_applications/image_recognition.md) - CNNの応用
  - [過学習対策](../05_machine_learning/overfitting_underfitting.md) - Dropout、正則化
  - [RNN](rnn.md) - 系列データ向けの構造
- **発展**：
  - Attention機構（Vision Transformer）
  - Dilated/Atrous Convolution（受容野拡大）← 本ページで説明
  - Depthwise Separable Convolution（軽量化）← 本ページで説明
  - Semantic Segmentation（U-Net、FCN、DeepLab）

---

## 軽量化CNN：Depthwise Separable Convolution

### 背景と必要性

**モバイル端末での課題**：
- 計算リソース（CPU/GPU）の制約
- メモリ容量の制限
- バッテリー消費の問題
- リアルタイム処理の要求

**軽量化CNNの登場**：
- **MobileNet（Google, 2017）**：モバイル端末向けの軽量化モデル
- **ShuffleNet（2018）**：チャネルシャッフルによる軽量化
- **EfficientNet（Google, 2019）**：Compound Scalingで精度と効率のバランス最適化

---

## EfficientNet（効率的なネットワーク）

### 要点
EfficientNetは2019年にGoogleが提案した、**ネットワークの深さ（depth）・幅（width）・解像度（resolution）の3つの次元を複合的にスケーリングする手法（Compound Scaling）**を導入したCNNアーキテクチャ。従来は1つの次元のみをスケールアップしていたが、EfficientNetは3次元を同時にバランス良くスケールすることで、少ないパラメータで高精度を実現。

### 定義
**EfficientNet**は、Compound Coefficient（複合係数）$\phi$ を用いて、深さ・幅・解像度を統一的にスケーリングするニューラルネットワーク設計手法。以下の式でスケーリング：

- **深さ（層数）**: $d = \alpha^\phi$
- **幅（チャネル数）**: $w = \beta^\phi$
- **解像度（画像サイズ）**: $r = \gamma^\phi$

制約条件：$\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2$（計算量が約2倍になるように調整）

### 重要キーワード
- **Compound Scaling（複合スケーリング）**: 深さ・幅・解像度を同時にスケーリングする手法
- **Compound Coefficient（複合係数）**: $\phi$、スケーリングの度合いを制御するパラメータ
- **深さ（Depth）**: ネットワークの層数
- **幅（Width）**: 各層のチャネル数（フィルタ数）
- **解像度（Resolution）**: 入力画像のサイズ（例：224×224、380×380）
- **NAS（Neural Architecture Search）**: ベースとなるEfficientNet-B0を自動設計
- **MBConv（Mobile Inverted Bottleneck Convolution）**: MobileNetV2のInverted Residualブロック

### 詳細

#### 従来のスケーリング手法の問題点

**1つの次元のみのスケーリング**：
- **深さのみ増加**（ResNet18→ResNet152）: 計算量増大、勾配消失リスク
- **幅のみ増加**（チャネル数倍増）: 細かい特徴は捉えにくい
- **解像度のみ増加**（224→384）: 計算量が大幅増加

**問題**：
- バランスが悪く、精度向上が頭打ちになる
- 計算量に対する精度の伸びが悪い（効率が低い）

#### Compound Scalingの原理

**3つの次元を同時にバランス良くスケーリング**：

```
ベースネットワーク（EfficientNet-B0）
  深さ=d₀, 幅=w₀, 解像度=r₀
  ↓
複合係数 φ を設定（φ=1, 2, 3, ...）
  ↓
深さ: d = α^φ · d₀
幅:   w = β^φ · w₀
解像度: r = γ^φ · r₀
  ↓
EfficientNet-B1, B2, ..., B7
（φが大きいほど大規模・高精度）
```

**制約条件の意味**：
$$\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2$$

- **理由**: 深さは線形に、幅と解像度は2乗で計算量に影響
- **$\phi$ が1増えると計算量が約2倍**になるように調整
- **$\alpha, \beta, \gamma$ は事前にグリッドサーチで最適化**（EfficientNet-B0で$\alpha=1.2, \beta=1.1, \gamma=1.15$）

#### 具体例：EfficientNet-B0からB7へのスケーリング

| モデル | $\phi$ | 深さ | 幅 | 解像度 | パラメータ数 | Top-1精度 |
|--------|--------|------|-----|--------|------------|-----------|
| **B0** | 0 | 基準 | 基準 | 224×224 | 5.3M | 77.1% |
| **B1** | 1 | 1.2倍 | 1.1倍 | 240×240 | 7.8M | 79.1% |
| **B2** | 2 | 1.4倍 | 1.2倍 | 260×260 | 9.2M | 80.1% |
| **B3** | 3 | 1.7倍 | 1.3倍 | 300×300 | 12M | 81.6% |
| **B4** | 4 | 2.1倍 | 1.4倍 | 380×380 | 19M | 82.9% |
| **B5** | 5 | 2.5倍 | 1.6倍 | 456×456 | 30M | 83.6% |
| **B6** | 6 | 3.0倍 | 1.8倍 | 528×528 | 43M | 84.0% |
| **B7** | 7 | 3.6倍 | 2.0倍 | 600×600 | 66M | 84.3% |

**特徴**：
- B0: 軽量（5.3M）だが高精度（77.1%）
- B7: 最高精度（84.3%）だが大規模（66M）
- **用途に応じてB0～B7を選択**（モバイルならB0、サーバーならB7）

#### EfficientNet-B0のベースアーキテクチャ

**設計手法**：
- **NAS（Neural Architecture Search）**で自動設計
- **MBConv（Mobile Inverted Bottleneck Convolution）**ブロックを使用
- Squeeze-and-Excitation（SE）ブロックでチャネル重み付け

**基本構造**：
```
入力（224×224×3）
  ↓
Conv 3×3
  ↓
MBConvブロック × 16（複数段）
  ↓
Conv 1×1
  ↓
Global Average Pooling
  ↓
全結合層（分類）
```

**MBConvブロック**：
1. 1×1畳み込み（チャネル拡張）
2. Depthwise Convolution 3×3または5×5
3. Squeeze-and-Excitation
4. 1×1畳み込み（チャネル削減）
5. Residual接続

### 他のモデルとの比較

#### ResNet vs EfficientNet

| 項目 | ResNet-50 | EfficientNet-B4 |
|------|-----------|-----------------|
| **パラメータ数** | 25.6M | **19M**（少ない） |
| **ImageNet精度** | 76.0% | **82.9%**（高い） |
| **計算量（GFLOPS）** | 4.1 | 4.2（ほぼ同じ） |
| **スケーリング** | 深さのみ | **3次元複合** |

**結論**：EfficientNetは**同じ計算量で約7%高精度**

#### MobileNet vs EfficientNet

| 項目 | MobileNetV2 | EfficientNet-B0 |
|------|-------------|-----------------|
| **パラメータ数** | 3.5M | **5.3M** |
| **ImageNet精度** | 72.0% | **77.1%**（高い） |
| **設計** | 手動設計 | **NAS**（自動） |
| **スケーリング** | 幅係数のみ | **3次元複合** |

**結論**：EfficientNet-B0は**少ないパラメータ増加で5%高精度**

### 試験での問われ方

#### 典型問題：複合係数によるスケーリング

> 「3つのハイパーパラメータ（深さ・広さ・解像度）を調整するCompound Coefficient（複合係数）を導入することで精度を高めている手法について、最も適切な選択肢を1つ選べ。」

✅ **正解**：**EfficientNet**

❌ **不適切な選択肢**：
- ResNet → 深さのみスケーリング
- VGGNet → 深さと幅を手動調整
- MobileNet → 幅係数のみスケーリング
- Inception → 複数サイズのフィルタを並列使用（スケーリングではない）

#### 詳細パターン：EfficientNetの特徴

> 「EfficientNetに関する説明として、最も適切な選択肢を1つ選べ。」

✅ **正解の選択肢**：
- 「深さ・幅・解像度の3次元を複合的にスケーリングする」
- 「Compound Coefficient φ を用いて統一的にスケーリング」
- 「ベースネットワーク（B0）はNAS（Neural Architecture Search）で設計」
- 「少ないパラメータで従来モデルより高精度を実現」
- 「MBConv（Mobile Inverted Bottleneck）ブロックを使用」

❌ **不適切な選択肢（混同注意）**：
- 「深さのみをスケーリングする」→ ResNetの特徴
- 「Transformer構造を使用」→ Vision Transformerの特徴
- 「全結合層を複数段使用」→ VGGNetの古い設計
- 「Residual接続がない」→ MBConvブロック内にResidual接続あり
- 「計算量が非常に大きい」→ 逆に効率的（少ない計算量で高精度）

#### ひっかけポイント

| ひっかけ | 正しい理解 |
|----------|------------|
| ❌ 深さのみスケーリング | ✅ 深さ・幅・解像度の3次元同時スケーリング |
| ❌ 手動設計 | ✅ NASで自動設計（B0）+複合スケーリング（B1～B7） |
| ❌ パラメータ数が多い | ✅ 効率的（ResNetより少ないパラメータで高精度） |
| ❌ モバイル専用 | ✅ B0はモバイル向け、B7はサーバー向けと幅広い |
| ❌ Transformerベース | ✅ CNNベース（Convolutionベース） |

#### 穴埋め問題例

> 「EfficientNetでは、ネットワークの（①深さ）・（②幅）・（③解像度）の3つを、（④Compound Coefficient/複合係数）によって統一的にスケーリングする手法を採用している。」

**正解**：
- ① 深さ（Depth、層数）
- ② 幅（Width、チャネル数）
- ③ 解像度（Resolution、画像サイズ）
- ④ Compound Coefficient（複合係数）/ $\phi$

### 補足

#### 実務での利用

**転移学習**：
- ImageNetで事前学習済みのEfficientNetを利用
- 独自データセットでファインチューニング
- PyTorch、TensorFlow、Kerasで実装済みモデルが利用可能

**用途別のモデル選択**：
- **モバイル・エッジ**：EfficientNet-B0, B1（軽量）
- **サーバー・クラウド**：EfficientNet-B4～B7（高精度）
- **リアルタイム処理**：B0, B1（推論速度重視）
- **精度重視**：B6, B7（計算資源豊富な場合）

**実装例**（PyTorch）：
```python
import torchvision.models as models

# EfficientNet-B0をロード
model = models.efficientnet_b0(pretrained=True)

# 独自データセット用にファインチューニング
model.classifier[1] = nn.Linear(1280, num_classes)
```

#### EfficientNetの後継・発展

**EfficientNetV2（2021）**：
- 学習速度を大幅改善（V1の5～11倍高速）
- Progressive Learning（段階的に画像サイズを増やして学習）
- Fused-MBConvブロック導入

**EfficientDet（2020）**：
- EfficientNetをベースにした物体検出モデル
- BiFPN（Bidirectional Feature Pyramid Network）

#### 関連技術

**NAS（Neural Architecture Search）**：
- 強化学習や進化的アルゴリズムでネットワーク構造を自動設計
- EfficientNet-B0の設計に使用
- 計算コストが高いが、高性能な構造を発見可能

**AutoML**：
- ハイパーパラメータ、アーキテクチャ、データ拡張を自動最適化
- EfficientNetはAutoMLの成功例

---

### NAS（Neural Architecture Search）★試験頻出

#### 定義
**NAS（Neural Architecture Search）**は、ニューラルネットワークの構造（層の数、フィルタサイズ、接続方法等）を**自動的に探索・設計**する技術。大量の候補構造を並列に評価し、最適なアーキテクチャを発見する。

#### 要点
- **構造の自動設計**：人手で設計する代わりに機械が最適構造を探索
- **大量のGPU並列計算**：数千～数万の候補を並列評価、計算コスト極大
- **探索空間の定義**：層の種類・数・接続方法等の候補を事前設定
- EfficientNet-B0、MobileNet v3等の高性能モデル設計に使用

#### NASの基本プロセス

```
1. 探索空間の定義
   ↓
2. 候補構造の生成（探索戦略）
   ↓
3. 各構造の学習・評価（大量GPU並列）
   ↓
4. 評価結果を探索戦略にフィードバック
   ↓
5. 最適構造の発見まで反復
```

#### 探索空間（Search Space）

**探索対象の要素**：
- **層の種類**：畳み込み、プーリング、Depthwise Separable等
- **層の数**：ネットワークの深さ
- **フィルタサイズ**：3×3、5×5、7×7等
- **チャネル数**：各層の幅
- **接続方法**：スキップ結合、分岐・合流等
- **活性化関数**：ReLU、Swish等

**例（セル構造の探索）**：
```
入力 → [操作1] → [操作2] → 出力
        ↓
    操作候補：
    - 3×3畳み込み
    - 5×5畳み込み
    - Depthwise Separable
    - Max Pooling
    - スキップ結合（何もしない）
```

#### 探索戦略（Search Strategy）

**主な手法**：

1. **強化学習ベース**
   - RNNコントローラが構造を生成
   - 評価結果（精度）を報酬として学習
   - Google（2017）が提案、AutoMLの基盤

2. **進化的アルゴリズム（Evolutionary Algorithm）**
   - 構造を個体として進化
   - 選択・交叉・突然変異で最適化
   - 並列探索に適する

3. **勾配ベース（Differentiable NAS）**
   - 構造探索を微分可能に定式化
   - DARTS（2018）が代表例
   - 探索時間を大幅短縮（数日→数時間）

4. **ベイズ最適化**
   - 過去の評価から次の候補を効率的に選択
   - 探索回数を削減

#### 評価方法（Performance Estimation）

**フル学習**：
- 各候補を収束まで学習して精度評価
- 最も正確だが計算コスト極大（数千GPU日）

**早期停止（Early Stopping）**：
- 数エポックで評価、低性能なら打ち切り
- 計算コスト削減

**重み共有（Weight Sharing）**：
- 候補間で重みを共有
- ENAS（Efficient NAS）で提案
- 大幅な高速化（1000倍）

**代理モデル（Surrogate Model）**：
- 軽量モデルで性能を予測
- 実際の学習回数を削減

#### 並列化の重要性

**大量GPU並列計算の必要性**：
- 探索空間は膨大（$10^{20}$以上の候補構造）
- 各構造の評価に数時間～数日かかる
- 逐次探索では現実的な時間で完了しない

**並列化の方法**：
```
【並列評価】
GPU1: 構造A → 精度85%
GPU2: 構造B → 精度87%
GPU3: 構造C → 精度83%
...
GPU1000: 構造Z → 精度90%

→ 1000構造を同時評価、探索時間を1/1000に短縮
```

**計算コストの例**：
- **Google AutoML**（2017）：800 GPU × 4日 = 3200 GPU日
- **AmoebaNet**（進化的NAS）：450 GPU × 7日 = 3150 GPU日
- **DARTS**（勾配ベース）：1 GPU × 4日 = 4 GPU日

#### NASの成果

**発見された高性能モデル**：
- **EfficientNet-B0**：NASで設計、SOTA精度達成
- **MobileNet v3**：NASで軽量化とパフォーマンスを最適化
- **NASNet**：ImageNetで当時のSOTA（2017）
- **AmoebaNet**：進化的アルゴリズムで発見

**人手設計との比較**：
| 項目 | 人手設計 | NAS |
|------|----------|-----|
| **設計期間** | 数ヶ月～数年 | 数日～数週間（GPU大量） |
| **精度** | 専門家の経験に依存 | 人手設計を超える場合あり |
| **計算コスト** | 低い | 極めて高い（数千GPU日） |
| **再現性** | 設計者のスキルに依存 | 客観的・自動的 |
| **汎用性** | タスクごとに再設計 | 探索空間変更で対応 |

#### 試験での問われ方

**典型問題**：「大量のGPUを用いて並列でニューラルネットワークの構造を探索する方法として、最も適切な選択肢を1つ選べ。」

**選択肢例**：
- A. **NAS（Neural Architecture Search）** → ✅ **正解**（構造の自動探索）
- B. バッチ正規化（Batch Normalization） → ❌ 不適切（学習安定化手法、構造探索ではない）
- C. Dropout → ❌ 不適切（過学習対策、構造探索ではない）
- D. データ拡張（Data Augmentation） → ❌ 不適切（過学習対策、構造探索ではない）
- E. 転移学習（Transfer Learning） → ❌ 不適切（学習済みモデル活用、構造探索ではない）
- F. 勾配降下法 → ❌ 不適切（パラメータ最適化、構造探索ではない）

**キーワード認識**：
- 「**並列で構造を探索**」→ NAS
- 「**大量のGPU**」→ NAS（計算コスト大）
- 「**自動設計**」→ NAS / AutoML
- 「**アーキテクチャ探索**」→ NAS

#### 引っ掛けポイント

| ひっかけ選択肢 | 正しい理解 | 実際の用途 |
|----------------|------------|------------|
| ❌ ハイパーパラメータ探索 | △ 関連あるが構造探索ではない | 学習率・バッチサイズ等の最適化 |
| ❌ AutoML | △ NASを含む広い概念 | ハイパーパラメータ+構造+データ拡張 |
| ❌ グリッドサーチ | ❌ パラメータの網羅的探索 | ハイパーパラメータ調整 |
| ❌ ランダムサーチ | ❌ パラメータのランダム探索 | ハイパーパラメータ調整 |
| ❌ 交差検証 | ❌ モデル評価手法 | 汎化性能の推定 |
| ✅ **NAS** | ✅ **構造の自動探索** | **ネットワークアーキテクチャの設計** |

**重要な対比**：
- **NAS**：ネットワーク**構造**の探索（層の種類・数・接続方法）
- **ハイパーパラメータ探索**：学習率・バッチサイズ等の**パラメータ**調整
- **AutoML**：NAS + ハイパーパラメータ探索 + データ拡張の統合
- **転移学習**：既存モデルの**再利用**（探索ではない）

#### 実例

**例1：EfficientNet-B0の設計**
```
【NASプロセス】
1. 探索空間：MBConvブロックの組み合わせ
2. 探索手法：強化学習ベース
3. 評価：ImageNetで精度測定
4. 計算コスト：大量GPU × 数日
5. 結果：B0モデル発見 → 複合スケーリングでB1～B7作成
```

**例2：MobileNet v3**
```
【NAS + NetAdapt】
1. NASでベース構造を探索
2. NetAdaptで計算量制約下で微調整
3. 結果：MobileNet v2より20%高速・精度向上
```

**例3：進化的NAS（AmoebaNet）**
```
【進化プロセス】
世代1: 100個の構造をランダム生成
      ↓ 評価
世代2: 上位20個を選択・交叉・変異
      ↓ 100個の新構造生成
世代3: さらに評価・進化
...
最終: 最高性能の構造を発見
```

#### 補足

**実務での利用**：
- **クラウドサービス**：Google Cloud AutoML、Azure AutoML
- **オープンソース**：NASNetモデル、DARTS実装
- **カスタムNAS**：特定タスク向けに探索空間をカスタマイズ

**課題**：
- **計算コスト極大**：数千GPU日、環境負荷も大きい
- **探索空間設計**：適切な候補を事前定義する必要
- **汎化性**：あるデータセットで最適でも他で最適とは限らない
- **解釈困難**：発見された構造がなぜ良いかを理解しにくい

**発展技術**：
- **Once-for-All Network**：1回の学習で複数サイズのモデルを同時生成
- **Hardware-aware NAS**：特定デバイス（スマホ、FPGA等）向けに最適化
- **Neural Architecture Transfer**：タスク間で構造を転移

#### 関連トピック
- [EfficientNet](#efficientnet複合スケーリング試験頻出)：NASで設計されたモデル
- [最適化手法](../10_math_statistics/optimization.md)：パラメータ最適化との違い
- [過学習対策](../05_machine_learning/overfitting_underfitting.md)：構造以外の性能改善手法

---

### Depthwise Separable Convolution（深さ方向分離可能畳み込み）

**定義**：
通常の畳み込みを**2つのステップに分離**することで計算量を大幅に削減する手法。

#### ステップ1：Depthwise Convolution（深さ方向畳み込み）

**仕組み**：
- 各チャネルに対して**独立に**空間方向（横×縦）の畳み込みを実行
- チャネル間の情報は混合しない

**処理イメージ**：
```
入力：H×W×C（高さ×幅×チャネル数）
     ↓
各チャネルごとに3×3フィルタで畳み込み
（Cチャネル → Cチャネル、チャネル数不変）
     ↓
出力：H'×W'×C
```

**特徴**：
- フィルタサイズ：K×K×1（チャネル方向の深さは1）
- フィルタ数：C個（入力チャネル数と同じ）
- 計算量：$H' \times W' \times K^2 \times C$

#### ステップ2：Pointwise Convolution（点ごと畳み込み）

**仕組み**：
- 1×1畳み込みでチャネル間の情報を混合
- 空間方向の処理はせず、各位置でチャネル次元の線形結合

**処理イメージ**：
```
入力：H'×W'×C
     ↓
1×1×C×Mフィルタで畳み込み
（Cチャネル → Mチャネル、チャネル数変換）
     ↓
出力：H'×W'×M
```

**特徴**：
- フィルタサイズ：1×1×C×M
- フィルタ数：M個（出力チャネル数）
- 計算量：$H' \times W' \times C \times M$

### 計算量の比較

#### 通常の畳み込み

```
入力：H×W×C
フィルタ：K×K×C×M
出力：H'×W'×M
```

**計算量**：
$$\text{通常} = H' \times W' \times K^2 \times C \times M$$

#### Depthwise Separable Convolution

**計算量**：
$$\text{Depthwise Separable} = H' \times W' \times (K^2 \times C + C \times M)$$

**削減率**：
$$\frac{\text{Depthwise Separable}}{\text{通常}} = \frac{K^2 \times C + C \times M}{K^2 \times C \times M} = \frac{1}{M} + \frac{1}{K^2}$$

**具体例**（K=3, M=128の場合）：
$$\frac{1}{128} + \frac{1}{9} \approx 0.119 \approx \frac{1}{8.4}$$

**結果**：通常の畳み込みの**約1/8～1/9の計算量**

### MobileNetの構造

**基本ブロック**：
```
Depthwise Convolution (3×3)
  ↓
Batch Normalization
  ↓
ReLU
  ↓
Pointwise Convolution (1×1)
  ↓
Batch Normalization
  ↓
ReLU
```

**全体構造**：
1. 通常の畳み込み層（最初の1層のみ）
2. Depthwise Separable Convolutionブロック × 13層
3. Average Pooling
4. 全結合層（分類）

**特徴**：
- パラメータ数：約420万（AlexNetの約1/15）
- 計算量：約0.57 GFLOPS（AlexNetの約1/20）
- ImageNet精度：Top-1約70%（通常CNNの90%程度の精度）

### MobileNetのバリエーション

| モデル | 年 | 主な改良点 |
|--------|-----|------------|
| **MobileNet v1** | 2017 | Depthwise Separable Convolutionの導入 |
| **MobileNet v2** | 2018 | Inverted Residual、Linear Bottleneck |
| **MobileNet v3** | 2019 | NAS（Neural Architecture Search）で構造最適化 |

**MobileNet v2の改良**：
- **Inverted Residual**：狭→広→狭（通常のResidualは逆）
- **Linear Bottleneck**：最後の層は活性化関数なし（情報保持）

### 計算量削減の具体例

**設定**：
- 入力：56×56×64
- フィルタ：3×3
- 出力：56×56×128

#### 通常の畳み込み

計算量：$56 \times 56 \times 3^2 \times 64 \times 128 = 231,211,008$ 回

#### Depthwise Separable Convolution

**Depthwise Convolution**：
$56 \times 56 \times 3^2 \times 64 = 1,806,336$ 回

**Pointwise Convolution**：
$56 \times 56 \times 64 \times 128 = 25,690,112$ 回

**合計**：$1,806,336 + 25,690,112 = 27,496,448$ 回

**削減率**：$\frac{27,496,448}{231,211,008} \approx 0.119 \approx \frac{1}{8.4}$

### 他の軽量化手法との比較

| 手法 | 原理 | 計算量削減 | 精度 |
|------|------|------------|------|
| **Depthwise Separable** | 畳み込みを2段階に分離 | 1/8～1/9 | 高（90%程度維持） |
| **1×1畳み込み** | チャネル数削減 | 中程度 | 高 |
| **Group Convolution** | チャネルをグループ分割 | 1/g（g=グループ数） | 中～高 |
| **Pruning** | 不要な重みを削除 | 可変 | 再学習で回復 |
| **Quantization** | パラメータの精度削減 | メモリ1/4 | わずかに低下 |

**Depthwise Separableの利点**：
- ✅ 精度低下が小さい（通常CNNの90%程度）
- ✅ 学習が安定（構造が単純）
- ✅ 実装が容易（標準的なフレームワークでサポート）

**欠点**：
- ❌ 小さいモデルでは効果が限定的（チャネル数が少ない場合）
- ❌ ハードウェア最適化が必要（GPUよりCPU/モバイルで真価）

### 試験での問われ方

#### 典型問題：MobileNetの計算量削減手法

> 「MobileNetは2017年にGoogleから発表されたモデルであり、モバイル端末でも学習できるほどに計算負荷が低いことが特徴です。この計算負荷を削減した仕組みとして、最も適切な選択肢を1つ選べ。」

✅ **正解**：Depthwise Separable Convolution（深さ方向分離可能畳み込み）

❌ **不適切な選択肢**：
- 「活性化関数にSigmoidを使用」→ReLUを使用（Sigmoidは関係ない）
- 「Pooling層を削除」→Pooling層は使用している
- 「全結合層を複数段重ねる」→逆に計算量増加
- 「バッチサイズを大きくする」→学習時の工夫（モデル構造ではない）

#### 詳細パターン：Depthwise Separable Convolutionの説明

> 「Depthwise Separable Convolutionに関する説明として、最も適切な選択肢を1つ選べ。」

✅ **正解の選択肢**：
- 「通常の畳み込みをDepthwise ConvolutionとPointwise Convolutionの2段階に分離」
- 「Depthwise Convolutionでは各チャネルに対して独立に空間方向の畳み込みを実行」
- 「Pointwise Convolutionは1×1畳み込みでチャネル間の情報を混合」
- 「計算量を通常の畳み込みの約1/8～1/9に削減」
- 「MobileNetの中核技術として採用」

❌ **不適切な選択肢（混同注意）**：
- 「パラメータ数が増加する代わりに精度が向上」→逆（パラメータ削減）
- 「Dilated Convolutionと同じ技術」→別の技術（Dilatedは受容野拡大）
- 「チャネル数を増やすことで計算量削減」→逆（チャネル数減少で削減）
- 「Pooling層の一種」→畳み込み層の改良手法

#### ひっかけポイント

| ひっかけ | 正しい理解 |
|----------|------------|
| ❌ 精度が大幅に向上 | ✅ 精度は若干低下（計算量削減とのトレードオフ） |
| ❌ パラメータ数増加 | ✅ パラメータ数削減（通常の約1/8） |
| ❌ Dilated Convolutionと同じ | ✅ 別の技術（Depthwise Separable=軽量化、Dilated=受容野拡大） |
| ❌ Pooling層の代替 | ✅ 畳み込み層の改良（Poolingとは無関係） |
| ❌ サーバー向けの技術 | ✅ モバイル・エッジデバイス向け |

### 実用例

**スマートフォンアプリ**：
- 顔認識（Face ID、顔検出）
- 物体検出（カメラアプリ）
- リアルタイム翻訳（OCR）
- AR（拡張現実）アプリ

**エッジデバイス**：
- 監視カメラ（リアルタイム解析）
- ドローン（自律飛行）
- IoTセンサー（異常検知）
- ロボット（物体認識）

**採用事例**：
- TensorFlow Lite（Google）
- PyTorch Mobile（Meta）
- Core ML（Apple）
- ONNX Runtime（Microsoft）

---

## バッチ正規化（Batch Normalization）★試験超重要

### 要点
- **CNNの隠れ層で、ミニバッチごとに各チャンネルを正規化**する手法（2015年、Ioffe & Szegedy提案）
- 学習の**安定化と高速化**を実現。大きな学習率の使用を可能にする
- 内部共変量シフト（Internal Covariate Shift）を抑制し、深いネットワークの学習を容易化

### 定義
**Batch Normalization（バッチ正規化、BN）**とは、ニューラルネットワークの各層で、ミニバッチ内のデータの平均と分散を用いて活性化を正規化する手法。CNNでは各チャンネル（特徴マップ）ごとに正規化を行う。学習時と推論時で計算方法が異なる。

### 重要キーワード
- **ミニバッチ正規化**: ミニバッチ単位で平均・分散を計算
- **チャンネルごとの正規化**: CNNでは各特徴マップチャンネルを独立に正規化
- **内部共変量シフト（Internal Covariate Shift）**: 学習中に各層の入力分布が変化する現象
- **スケール・シフトパラメータ（γ, β）**: 正規化後に学習可能なアフィン変換を適用
- **移動平均（Moving Average）**: 推論時に使用する統計量（学習時に蓄積）
- **学習安定化**: 勾配の爆発・消失を抑制
- **高速化**: 大きな学習率の使用が可能

---

### 詳細

#### 背景と問題意識

**深層学習の課題**：
- **学習の不安定性**: 深いネットワークでは勾配が爆発・消失しやすい
- **学習速度の遅さ**: 小さな学習率を使わざるを得ない
- **内部共変量シフト**: 各層の入力分布が学習中に変化し、層ごとの適応が困難

**内部共変量シフトとは**：
```
入力層 → 隠れ層1（分布A） → 隠れ層2
                ↓
         重み更新により分布変化
                ↓
入力層 → 隠れ層1（分布A'） → 隠れ層2
                              ↑
                        入力分布が変わり再適応が必要
```

**Batch Normalizationの解決策**：
- 各層の入力を常に同じ分布（平均0、分散1）に正規化
- 層間の依存関係を緩和し、各層が独立に学習可能

#### アルゴリズム（学習時）

**入力**: ミニバッチ $\mathcal{B} = \{x_1, x_2, ..., x_m\}$（m個のサンプル）

**手順**:

1. **ミニバッチの平均を計算**:
$$\mu_\mathcal{B} = \frac{1}{m} \sum_{i=1}^{m} x_i$$

2. **ミニバッチの分散を計算**:
$$\sigma^2_\mathcal{B} = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_\mathcal{B})^2$$

3. **正規化**:
$$\hat{x}_i = \frac{x_i - \mu_\mathcal{B}}{\sqrt{\sigma^2_\mathcal{B} + \epsilon}}$$
- $\epsilon$: 数値安定化のための微小値（通常 $10^{-5}$）

4. **スケール・シフト（学習可能パラメータ）**:
$$y_i = \gamma \hat{x}_i + \beta$$
- $\gamma$: スケールパラメータ（初期値1）
- $\beta$: シフトパラメータ（初期値0）
- これにより正規化の効果を調整可能（恒等変換も学習可能）

#### CNNにおけるBatch Normalization

**特徴マップの正規化**:

CNNの畳み込み層では、**各チャンネルごと**に正規化：

- **入力**: 特徴マップ $(N, C, H, W)$
  - $N$: バッチサイズ
  - $C$: チャンネル数
  - $H, W$: 高さ、幅

- **正規化単位**: 各チャンネル $c$ について、$(N \times H \times W)$ 個の値を用いて平均・分散を計算

**計算例**:
```
入力: (32, 64, 56, 56)  # バッチ32、チャンネル64、56×56画像
      ↓
チャンネル1: 32×56×56 = 100,352 個の値で平均・分散を計算
チャンネル2: 32×56×56 = 100,352 個の値で平均・分散を計算
...
チャンネル64: 32×56×56 = 100,352 個の値で平均・分散を計算
      ↓
学習パラメータ: γ（64個）、β（64個）
```

#### 配置位置

**典型的な配置**:
```
畳み込み層
  ↓
Batch Normalization  ← ここに挿入
  ↓
活性化関数（ReLU）
```

**論文の推奨**: Conv → BN → Activation
**実務では両方**: Conv → BN → Activation または Conv → Activation → BN

#### 推論時の動作

**学習時と推論時の違い**:

| 項目 | 学習時 | 推論時 |
|------|--------|--------|
| **平均** | ミニバッチの平均 $\mu_\mathcal{B}$ | **移動平均** $\mu_{\text{moving}}$ |
| **分散** | ミニバッチの分散 $\sigma^2_\mathcal{B}$ | **移動分散** $\sigma^2_{\text{moving}}$ |
| **更新** | 毎イテレーション計算 | 固定値を使用 |

**移動平均の計算**（学習中に蓄積）:
$$\mu_{\text{moving}} \leftarrow \alpha \mu_{\text{moving}} + (1-\alpha) \mu_\mathcal{B}$$

- $\alpha$: モメンタム係数（通常0.9～0.99）

**推論時の正規化**:
$$\hat{x} = \frac{x - \mu_{\text{moving}}}{\sqrt{\sigma^2_{\text{moving}} + \epsilon}}$$
$$y = \gamma \hat{x} + \beta$$

---

### 試験での問われ方（★超重要）

#### 典型的な選択肢問題

**問**: 学習の安定化や速度アップを目的に、畳み込みニューラルネットワーク（CNN）の隠れ層において、学習時のミニバッチ毎に各チャンネルを正規化する手法について、最も適切な選択肢を1つ選べ。

**A. Dropout**
- ❌ 不適切。過学習抑制の手法、正規化ではない

**B. Batch Normalization（バッチ正規化）**
- ⭕ **正解**。ミニバッチごとに各チャンネルを正規化

**C. Weight Decay（重み減衰）**
- ❌ 不適切。L2正則化、正規化手法ではない

**D. Data Augmentation（データ拡張）**
- ❌ 不適切。訓練データを増やす手法、正規化ではない

**正解**: **B（Batch Normalization）**

---

#### 判別ポイント（キーワードマッチング）

| キーワード | 該当手法 |
|-----------|---------|
| **ミニバッチごとに正規化** | ⭕ Batch Normalization |
| **各チャンネルを正規化** | ⭕ Batch Normalization |
| **学習の安定化・高速化** | ⭕ Batch Normalization |
| **内部共変量シフト抑制** | ⭕ Batch Normalization |
| ランダムにニューロン無効化 | ❌ Dropout |
| パラメータに制約を追加 | ❌ Weight Decay（L2正則化） |
| データを人工的に増やす | ❌ Data Augmentation |

---

#### 混同しやすい正規化手法

**Batch Normalization以外の正規化手法**:

| 手法 | 正規化単位 | 主な用途 | 特徴 |
|------|-----------|---------|------|
| **Batch Normalization** | ミニバッチ×空間×**チャンネル** | **CNN（一般）** | 最も広く使われる |
| **Layer Normalization** | サンプル×全特徴 | **RNN、Transformer** | バッチサイズ非依存 |
| **Instance Normalization** | サンプル×空間（チャンネル独立） | **スタイル変換** | 画像ごとに正規化 |
| **Group Normalization** | サンプル×空間×**グループ** | **小バッチ** | BNの小バッチ対応版 |

**試験での誤答パターン**:
- ❌「Layer Normalization」を選択 → RNN/Transformer向け、CNNではBNが主流
- ❌「Instance Normalization」を選択 → スタイル変換向け、一般的なCNN学習では不使用
- ❌「Dropout」を選択 → 正規化ではなく過学習抑制手法

**正解パターン**:
- ⭕「Batch Normalization」
- ⭕「バッチ正規化」
- ⭕「BN」

---

### Batch Normalizationの効果

#### 1. 学習の高速化

**大きな学習率の使用が可能**:
- 正規化により勾配のスケールが安定
- 学習率を10～100倍に増やせる
- 学習時間が大幅に短縮（例：ImageNetで従来の1/14）

**実験結果（ImageNet、2015年論文）**:
- 従来手法: 450万ステップで75%精度
- BN使用: 30万ステップで同等精度（**15倍高速**）

#### 2. 学習の安定化

**勾配の爆発・消失を抑制**:
- 各層の入力分布が安定
- 深いネットワークでも学習可能（ResNet等）

**Weight Initializationへの依存低減**:
- 適切な初期化（Xavier、He初期化）が必須だったが、BNで緩和

#### 3. 正則化効果

**過学習の抑制**:
- ミニバッチごとにノイズが加わる（確率的な正規化）
- Dropoutの併用が不要になる場合も

**Dropout削減**:
- BN導入前: Dropout 0.5（50%無効化）が標準
- BN導入後: Dropout 0.1～0.2で十分、またはなしでも可

#### 4. 深いネットワークの実現

**残差接続（ResNet）との相乗効果**:
- BN + ResNet → 1000層以上の超深層ネットワークが学習可能
- ImageNetで従来手法を大幅に上回る精度

---

### 実例

**例1: Inception v2（2015年）**
- **課題**: Inception v1（GoogLeNet）の学習が不安定
- **手法**: 全層にBatch Normalizationを導入
- **結果**: Top-5エラー率 4.82%（v1の6.67%から改善）

**例2: ResNet（2015年）**
- **構成**: Conv → BN → ReLU → Conv → BN → 加算 → ReLU
- **効果**: 152層の深いネットワークが学習可能
- **結果**: ImageNet優勝（Top-5エラー率 3.57%）

**例3: MobileNet系（2017年～）**
- **構成**: Depthwise Conv → BN → ReLU → Pointwise Conv → BN → ReLU
- **効果**: 軽量モデルでも高精度を維持
- **実用**: スマートフォンのリアルタイム認識

---

### 補足

#### Batch Normalizationの課題

**1. 小バッチサイズ問題**:
- バッチサイズが小さい（< 8）と統計量が不安定
- 対策: **Group Normalization**の使用

**2. 推論時の依存性**:
- 推論時に移動平均を使用（学習時と計算が異なる）
- 量子化やモバイル展開で注意が必要

**3. RNNでの不適合**:
- 系列長が可変のRNNでは使いにくい
- 対策: **Layer Normalization**の使用

**4. 計算コスト**:
- わずかに計算量増加（平均・分散計算）
- ただし、学習高速化の効果が大きく上回る

#### 実務での注意点

**学習時の設定**:
- モメンタム係数: 0.9～0.99（デフォルト0.99）
- ε値: $10^{-5}$（数値安定化）
- 学習率: BNなしの10倍程度から試す

**転移学習での扱い**:
- 事前学習済みモデルのBN層は**通常凍結しない**
- 移動平均の更新を有効化（`training=True`）

**推論時の最適化**:
- BN層を畳み込み層に統合可能（Folding）
- パラメータ数削減と高速化

---

### 定義（再掲）

**Batch Normalization（バッチ正規化）**:
- CNNの隠れ層で、ミニバッチごとに各チャンネルを正規化する手法
- 平均0、分散1に正規化後、学習可能なスケール・シフトを適用
- 学習の安定化・高速化、大きな学習率の使用を可能にする
- 内部共変量シフトを抑制し、深いネットワークの学習を容易化

---

## 補足（更新）

- **実務的観点**：
  - 画像認識では転移学習が主流（ResNet、EfficientNet等の事前学習済みモデル）
  - ストライド2の畳み込みでプーリング層を代替する設計も増加
  - Data Augmentation（データ拡張）で過学習対策
  - **Batch Normalizationは現代CNNの標準技術、ほぼ全ての層に挿入される**
  - 1×1畳み込みでチャンネル数削減（計算量削減）
  - Dilated ConvolutionはDeepLab（セグメンテーション）、WaveNet（音声）で実用
  - Global Average Poolingは解釈性重視の用途（医療診断、品質検査等）で有効
  - CAM/Grad-CAMで判断根拠の可視化が可能
  - **Depthwise Separable ConvolutionはMobileNet系モデルで標準採用、モバイル・エッジAIの基盤技術**
- **関連トピック**：
  - [ニューラルネットワーク基礎](neural_network_basics.md) - 活性化関数、誤差逆伝播
  - [画像認識](../07_ai_applications/image_recognition.md) - CNNの応用
  - [過学習対策](../05_machine_learning/overfitting_underfitting.md) - Dropout、正則化
  - [RNN](rnn.md) - 系列データ向けの構造
- **発展**：
  - Attention機構（Vision Transformer）
  - Dilated/Atrous Convolution（受容野拡大）← 本ページで説明
  - Depthwise Separable Convolution（軽量化）← 本ページで説明
  - Semantic Segmentation（U-Net、FCN、DeepLab）
