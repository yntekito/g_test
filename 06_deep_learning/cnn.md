# 畳み込みニューラルネットワーク（CNN）

## 要点（試験用）
- 画像認識に特化した深層学習モデル。畳み込み層とプーリング層で特徴抽出。
- **ストライド**はフィルタの移動幅、**パディング**は入力の余白追加で出力サイズを調整。
- パラメータ共有と局所受容野で、全結合層より少ないパラメータで高精度を実現。

## 定義
畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）は、画像データに対して**畳み込み層（Convolutional Layer）**と**プーリング層（Pooling Layer）**を組み合わせ、空間的な特徴を階層的に抽出するニューラルネットワーク。1998年のLeNet-5が起源。

## 重要キーワード
- **畳み込み層（Convolutional Layer）**: フィルタ（カーネル）で局所的特徴を抽出。
- **フィルタ（カーネル）**: 重み行列。画像上をスライドして特徴マップを生成。
- **ストライド（Stride）**: フィルタを移動させる幅（ピクセル数）。★重要
- **パディング（Padding）**: 入力画像の周囲に余白を追加（ゼロパディング等）。
- **特徴マップ（Feature Map）**: 畳み込み演算の出力。
- **プーリング層（Pooling Layer）**: 特徴マップのダウンサンプリング（Max/Average Pooling）。
- **受容野（Receptive Field）**: 各ニューロンが参照する入力領域。
- **パラメータ共有（Weight Sharing）**: 同じフィルタを全領域で使用。
- **局所結合（Local Connectivity）**: 全結合でなく局所的に結合。
- **チャネル（Channel）**: RGB画像なら3チャネル、中間層では複数の特徴マップ。
- **全結合層（Fully Connected Layer）**: CNN最終段で分類を行う。

## 詳細（教科書風）

### 背景と直観
CNNは1980年代の新古典派理論（Neocognitron, Fukushima）や、1998年のLeCunによるLeNet-5を起源とし、2012年のAlexNet以降、画像認識の主流となりました。

**基本的な考え方**：
- 画像の**空間構造**を保持しながら特徴抽出
- **局所的なパターン**（エッジ、テクスチャ等）を階層的に学習
- 全結合層より**パラメータ数を削減**し過学習を抑制

### CNNの基本構造

```
入力画像
  ↓
[畳み込み層 → 活性化(ReLU) → プーリング層] × 複数回
  ↓
[全結合層] × 複数回
  ↓
出力層（Softmax）
```

**典型例（AlexNet風）**：
```
入力(224×224×3)
 → Conv(96 filters) → ReLU → MaxPool
 → Conv(256 filters) → ReLU → MaxPool
 → Conv(384 filters) → ReLU
 → Conv(384 filters) → ReLU
 → Conv(256 filters) → ReLU → MaxPool
 → FC(4096) → ReLU → Dropout
 → FC(4096) → ReLU → Dropout
 → FC(1000) → Softmax
```

### 畳み込み層の詳細

#### 畳み込み演算
フィルタ（例：3×3の重み行列）を入力画像上でスライドさせ、要素ごとの積和を計算：

$$S(i,j) = \sum_{m}\sum_{n} I(i+m, j+n) \cdot K(m,n)$$

- $I$: 入力画像
- $K$: フィルタ（カーネル）
- $S$: 特徴マップ（出力）

#### 図解：畳み込み演算（3×3フィルタ）
```
入力画像（5×5）    フィルタ（3×3）
┌─────────┐    ┌─────┐
│1 2 3 4 5│    │1 0 1│
│2 3 4 5 6│ ⊗  │0 1 0│
│3 4 5 6 7│    │1 0 1│
│4 5 6 7 8│    └─────┘
│5 6 7 8 9│
└─────────┘
       ↓
出力（3×3）※ストライド1、パディング0
┌───────┐
│28 34 40│
│38 44 50│
│48 54 60│
└───────┘
```

### ストライド（Stride）★重要

#### 定義
**ストライド**は、フィルタを入力画像上で移動させる際の**移動幅（ピクセル数）**。

#### 影響
- **ストライド1**: 1ピクセルずつ移動（細かく特徴抽出）
- **ストライド2**: 2ピクセルずつ移動（出力サイズが約半分）
- ストライド大 → **出力サイズ小**、**計算量減**

#### 図解：ストライドの違い
```
ストライド1（1ピクセル移動）
┌─┬─┬─┬─┐
│■│■│ │ │  →  ┌─┬─┬─┐
├─┼─┼─┼─┤     │1│2│3│  
│ │■│■│ │  →  └─┴─┴─┘
├─┼─┼─┼─┤     出力: 3×3
│ │ │■│■│
└─┴─┴─┴─┘

ストライド2（2ピクセル移動）
┌─┬─┬─┬─┐
│■│■│ │ │  →  ┌─┬─┐
├─┼─┼─┼─┤     │1│2│  
│ │ │■│■│  →  └─┴─┘
└─┴─┴─┴─┘     出力: 2×2
```

#### 出力サイズの計算式
$$\text{出力サイズ} = \left\lfloor \frac{W - F + 2P}{S} \right\rfloor + 1$$

- $W$: 入力サイズ
- $F$: フィルタサイズ
- $P$: パディング
- $S$: ストライド

**計算例**：
- 入力: 5×5
- フィルタ: 3×3
- パディング: 0
- ストライド: 1
- 出力: $(5 - 3 + 0) / 1 + 1 = 3$×3

### パディング（Padding）

#### 定義
入力画像の周囲に余白（通常は0）を追加すること。

#### 目的
- **出力サイズの維持**（入力と同サイズに保つ）
- **端の情報の保持**（パディングなしでは端が失われる）

#### タイプ
- **Valid Padding**: パディングなし（出力サイズ減）
- **Same Padding**: 出力サイズ = 入力サイズになるよう調整
- **ゼロパディング**: 0で埋める（最も一般的）

#### 図解：パディング
```
入力（3×3）  →  パディング1  →  5×5
┌───┐       ┌─────────┐
│1 2│       │0 0 0 0 0│
│3 4│       │0 1 2 3 0│
└───┘       │0 4 5 6 0│
            │0 7 8 9 0│
            │0 0 0 0 0│
            └─────────┘
```

### プーリング層（Pooling Layer）

#### 目的
- **ダウンサンプリング**（特徴マップの縮小）
- **位置不変性**の獲得（微小な位置ずれに頑健）
- 計算量削減

#### 種類
**Max Pooling**（最も一般的）：
- 領域内の最大値を取得
```
入力（4×4）    Max Pooling(2×2, stride=2)
┌───────┐    ┌───┐
│1 3 2 4│    │3 4│
│5 6 1 2│ →  │8 7│
│7 8 3 5│    └───┘
│4 2 6 7│
└───────┘
```

**Average Pooling**：
- 領域内の平均値を取得

### パラメータ共有と局所結合

#### パラメータ共有
- 同じフィルタを画像全体で使用
- 例：3×3フィルタ → パラメータ数は9個（位置によらず）
- 全結合層なら: 100×100画像で10,000個のパラメータ

#### 利点
- **パラメータ数の大幅削減**
- **過学習の抑制**
- **平行移動不変性**（物体の位置が変わっても認識可能）

### 受容野（Receptive Field）

各層のニューロンが参照する入力領域：
```
畳み込み1層目: 3×3の局所領域
畳み込み2層目: より広い領域（例：5×5、7×7）
深い層ほど広い受容野 → 大域的特徴の抽出
```

### 代表的なCNNアーキテクチャ

**LeNet-5 (1998)**：
- 手書き数字認識（MNIST）
- 畳み込み → プーリング → 全結合

**AlexNet (2012)**：
- ImageNet優勝（Top-5エラー率15.3%）
- ReLU、Dropout、GPU活用

**VGGNet (2014)**：
- 3×3フィルタの繰り返し
- 深さの重要性を実証（16-19層）

**ResNet (2015)**：
- 残差接続（Skip Connection）で152層を実現
- 勾配消失問題の解決

**Inception/GoogLeNet (2014)**：
- 複数サイズのフィルタを並列実行
- 1×1畳み込みで次元削減

### 実装例（擬似コード）

```python
# Kerasでの簡単なCNN
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])
```

## 試験での問われ方
- **典型設問**：
  - 「フィルタを移動させる幅を何と呼ぶか？」→ **ストライド（Stride）**
  - 「出力サイズを維持するための処理は？」→ **パディング（Padding）**
  - 「領域内の最大値を取る処理は？」→ **Max Pooling**
  - 「CNNが全結合層より優れる理由は？」→ パラメータ共有、局所受容野
- **比較されやすい概念**：
  - **ストライド** vs **パディング**: 移動幅 vs 余白追加
  - **ストライド** vs **フィルタサイズ**: 移動幅 vs フィルタの大きさ
  - **Max Pooling** vs **Average Pooling**: 最大値 vs 平均値
  - **CNN** vs **全結合NN**: パラメータ共有 vs 全結合
  - **畳み込み層** vs **プーリング層**: 特徴抽出 vs ダウンサンプリング
- **引っ掛けポイント**：
  - 「フィルタの移動幅」→ **ストライド**（カーネルサイズではない）
  - 「入力の周囲に余白」→ **パディング**（ストライドではない）
  - ストライド大 → 出力サイズ**小**（大ではない）
  - パディング大 → 出力サイズ**大**（小ではない）
  - プーリングには**学習パラメータなし**（畳み込み層にはあり）
- **頻出パターン**：
  - 出力サイズの計算（ストライド・パディングの影響）
  - CNNの構造順序（畳み込み→活性化→プーリング）
  - パラメータ数の比較（CNN vs 全結合）
  - 各層の役割（特徴抽出 vs ダウンサンプリング vs 分類）

## 補足
- **実務的観点**：
  - 画像認識では転移学習が主流（ResNet、EfficientNet等の事前学習済みモデル）
  - ストライド2の畳み込みでプーリング層を代替する設計も増加
  - Data Augmentation（データ拡張）で過学習対策
  - Batch Normalizationで学習安定化・高速化
  - 1×1畳み込みでチャネル数削減（計算量削減）
- **関連トピック**：
  - [ニューラルネットワーク基礎](neural_network_basics.md) - 活性化関数、誤差逆伝播
  - [画像認識](../07_ai_applications/image_recognition.md) - CNNの応用
  - [過学習対策](../05_machine_learning/overfitting_underfitting.md) - Dropout、正則化
  - [RNN](rnn.md) - 系列データ向けの構造
- **発展**：
  - Attention機構（Vision Transformer）
  - Dilated/Atrous Convolution（受容野拡大）
  - Depthwise Separable Convolution（軽量化）
  - Semantic Segmentation（U-Net、FCN）
