# 生成モデル（Generative Models）

## 要点
- 生成モデルはデータの確率分布を学習し、新しいデータを生成するモデル。代表例：オートエンコーダ（AE）、変分オートエンコーダ（VAE）、GAN。
- **オートエンコーダと変分オートエンコーダの共通点**：デコーダの出力はエンコーダに与えられた入力情報を**再構成する（復元する）**。
- VAEは潜在変数に確率分布を導入し、滑らかな潜在空間でデータ生成が可能。GANは識別器との敵対的学習で高品質な生成を実現。

## 定義
**生成モデル（Generative Model）**は、訓練データの確率分布 $p(x)$ を学習し、その分布に従う新しいサンプルを生成するモデル。識別モデルが $p(y|x)$（条件付き確率）を学習するのに対し、生成モデルは $p(x)$ や $p(x, y)$（同時確率）を学習する。

## 重要キーワード
- **オートエンコーダ（Autoencoder, AE）**: 入力を潜在表現に圧縮（エンコード）し、再構成（デコード）する教師なし学習モデル
- **変分オートエンコーダ（VAE）**: 潜在変数に確率分布を導入したオートエンコーダ
- **GAN（敵対的生成ネットワーク）**: 生成器と識別器の敵対的学習で高品質な生成を実現
- **再構成（Reconstruction）**: デコーダが元の入力を復元すること
- **潜在変数（Latent Variable）**: 低次元の圧縮された表現
- **エンコーダ（Encoder）**: 入力を潜在表現に変換
- **デコーダ（Decoder）**: 潜在表現から出力を生成

## 詳細

### オートエンコーダ（Autoencoder）

#### 基本構造
オートエンコーダは、入力データを低次元の**潜在表現**に圧縮し、その表現から元のデータを**再構成**する2つの部分から構成されます：

```
入力 x
  ↓
【エンコーダ（Encoder）】
  入力 → 潜在表現 z
  ↓
潜在空間（低次元）
  z = f(x)
  ↓
【デコーダ（Decoder）】
  潜在表現 → 再構成 x'
  ↓
出力 x'（入力の再構成）

目的: x' ≈ x （入力と出力を一致させる）
```

#### 学習目標
**再構成誤差（Reconstruction Error）**を最小化：

$$L = ||x - x'||^2 = ||x - \text{Decoder}(\text{Encoder}(x))||^2$$

#### オートエンコーダの種類

**1. 標準オートエンコーダ**：
- 潜在次元 < 入力次元で次元削減
- データ圧縮、特徴抽出に利用

**2. デノイジングオートエンコーダ（DAE）**：
- 入力にノイズを加え、元の入力を復元
- ロバストな特徴学習

**3. スパースオートエンコーダ**：
- 潜在表現に疎性（スパース性）を課す
- 重要な特徴のみを抽出

#### 応用例
- 異常検知（再構成誤差が大きい = 異常）
- 次元削減（PCAの非線形版）
- ノイズ除去
- 特徴抽出

### 変分オートエンコーダ（VAE: Variational Autoencoder）

#### 定義
VAEは、潜在変数 $z$ に**確率分布**を導入したオートエンコーダ。エンコーダは入力から潜在分布のパラメータ（平均 $\mu$、分散 $\sigma^2$）を推定し、デコーダはサンプリングされた $z$ から入力を再構成します。

#### 基本構造

```
入力 x
  ↓
【エンコーダ】
  入力 → μ, σ²（分布のパラメータ）
  ↓
潜在空間（確率分布）
  z ~ N(μ, σ²)（正規分布からサンプリング）
  ↓
【デコーダ】
  z → 再構成 x'
  ↓
出力 x'
```

#### 標準AEとVAEの違い

| 項目 | オートエンコーダ（AE） | 変分オートエンコーダ（VAE） |
|------|---------------------|------------------------|
| **潜在表現** | 決定的な値（1点） | **確率分布**（平均・分散） |
| **エンコーダ出力** | z（ベクトル） | μ, σ²（分布パラメータ） |
| **サンプリング** | なし | **あり**（再パラメータ化トリック） |
| **損失関数** | 再構成誤差のみ | 再構成誤差 + **KLダイバージェンス** |
| **生成能力** | 限定的（学習データ近傍のみ） | **高い**（滑らかな潜在空間） |
| **潜在空間** | 不連続・ばらつき | **連続的・滑らか** |
| **用途** | 次元削減、特徴抽出 | **データ生成**、異常検知 |

#### VAEの損失関数（ELBO）

VAEは2つの項を最小化：

$$L = \underbrace{||x - x'||^2}_{\text{再構成誤差}} + \underbrace{\text{KL}(q(z|x) || p(z))}_{\text{KLダイバージェンス}}$$

- **再構成誤差**: デコーダの出力と入力の差
- **KLダイバージェンス**: 潜在分布を標準正規分布 $N(0, 1)$ に近づける正則化項

#### 再パラメータ化トリック（Reparameterization Trick）

サンプリング $z \sim N(\mu, \sigma^2)$ を微分可能にする技法：

$$z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim N(0, 1)$$

これにより誤差逆伝播が可能になります。

#### VAEの利点
- **滑らかな潜在空間**: 補間が可能（顔画像で表情を連続的に変化等）
- **生成能力**: 学習データに無いパターンも生成可能
- **確率的解釈**: 理論的基盤が明確

### オートエンコーダとVAEの共通点（★試験重要）

両者に共通する最も重要な特徴：

✅ **デコーダの出力はエンコーダに与えられた入力情報を「再構成する（復元する）」**

```
共通の学習目標:
  入力 x → エンコーダ → 潜在表現 → デコーダ → 出力 x'
  
  目的: x' ≈ x （できるだけ元の入力に近づける）
```

**具体的な共通点**：
1. **Encoder-Decoder構造**: 両方とも2段階の変換
2. **再構成が目的**: 入力を復元することが学習目標
3. **次元圧縮**: 潜在表現は入力より低次元
4. **教師なし学習**: ラベル不要で学習可能
5. **再構成誤差を最小化**: 損失関数に再構成項を含む

**異なる点**：
- AE: 潜在表現は決定的な値
- VAE: 潜在表現は確率分布（生成能力が高い）

### GAN（敵対的生成ネットワーク）

#### 基本構造

GANは2つのネットワークの**敵対的学習**で生成を行います：

```
【生成器（Generator）】
  ランダムノイズ z → 偽データ x_fake
  目的: 識別器を騙す

     ↓ x_fake

【識別器（Discriminator）】
  入力（本物 or 偽物）→ 確率 [0, 1]
  目的: 本物と偽物を区別

本物データ x_real も入力
```

#### 学習プロセス

1. **識別器の学習**: 本物を「本物」、偽物を「偽物」と判定
2. **生成器の学習**: 識別器を騙せるような偽物を生成
3. この2つを交互に繰り返す（敵対的学習）

#### 損失関数

$$\min_G \max_D \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]$$

- $G$: 生成器（Generator）
- $D$: 識別器（Discriminator）
- $D(x)$: 本物である確率
- $G(z)$: 生成器の出力

#### GANの種類

**DCGAN（Deep Convolutional GAN）**：
- 畳み込み層を使用
- 画像生成で高品質

**CGAN（Conditional GAN）**：
- 条件（ラベル）を与えて生成
- 例：「猫」を指定して猫の画像を生成

**StyleGAN**：
- 高解像度・高品質な顔画像生成
- スタイル転送が可能

**Pix2Pix**：
- 画像から画像への変換
- 例：スケッチ→写真、昼→夜
- **ペア画像が必要**（入力と正解のセット）

**CycleGAN**：
- ペア画像不要の変換
- 例：馬↔シマウマ、写真↔絵画

#### CycleGAN（Cycle-Consistent Adversarial Network）の詳細

##### 定義（★試験重要）
**CycleGAN**は、**ペア画像（対応する入力-出力の組）なしで**異なるドメイン間の画像変換を学習するGAN。Cycle Consistency Loss（循環一貫性損失）により、変換後に元に戻せることを保証する。

##### 典型的な質問形式
> 「CycleGANの説明として、最も適切な選択肢を1つ選べ。」

✅ **正解の選択肢**：
- **ペア画像なしでドメイン間の画像変換を学習できる**
- **Cycle Consistency Lossで変換の一貫性を保証する**
- **2つの生成器と2つの識別器を使用する**
- 馬→シマウマ、シマウマ→馬のような双方向変換が可能

❌ **不適切な選択肢（混同注意）**：
- ペア画像が必要 → 誤り（**Pix2Pix**の特徴）
- 1つの生成器のみ使用 → 誤り（2つの生成器を使用）
- 条件付きラベルで生成 → 誤り（**CGAN**の特徴）
- 高解像度の顔画像生成 → 誤り（**StyleGAN**の特徴）

##### Pix2Pix vs CycleGANの比較（重要）

| 項目 | Pix2Pix | CycleGAN |
|------|---------|----------|
| **訓練データ** | **ペア画像が必要** | **ペア画像不要** |
| **生成器** | 1つ | **2つ（双方向）** |
| **識別器** | 1つ | **2つ** |
| **変換方向** | 一方向（A→B） | **双方向（A↔B）** |
| **損失関数** | 敵対的損失 + L1損失 | 敵対的損失 + **Cycle Consistency Loss** |
| **データ収集** | 困難（対応付け必要） | **容易**（対応不要） |
| **変換精度** | 高い | やや低い |
| **用途** | スケッチ→写真、地図→航空写真 | スタイル変換、馬↔シマウマ |

##### CycleGANの構造

```
ドメインA（例：馬）     ドメインB（例：シマウマ）

   実画像 x_A                実画像 x_B
      ↓                          ↓
【生成器 G: A→B】          【生成器 F: B→A】
      ↓                          ↓
   偽画像 y_B                 偽画像 y_A
      ↓                          ↓
【識別器 D_B】             【識別器 D_A】
  本物 or 偽物？              本物 or 偽物？

【Cycle Consistency（循環一貫性）】
  x_A → G(x_A)=y_B → F(y_B) ≈ x_A  (元に戻る)
  x_B → F(x_B)=y_A → G(y_A) ≈ x_B  (元に戻る)
```

**4つのネットワーク**：
1. **生成器G**: ドメインA → ドメインB（例：馬 → シマウマ）
2. **生成器F**: ドメインB → ドメインA（例：シマウマ → 馬）
3. **識別器D_B**: ドメインBの本物/偽物を判定
4. **識別器D_A**: ドメインAの本物/偽物を判定

##### Cycle Consistency Loss（循環一貫性損失）

CycleGANの核心的な工夫：

$$L_{cyc} = ||F(G(x_A)) - x_A|| + ||G(F(x_B)) - x_B||$$

**意味**：
- $x_A$（馬）→ $G(x_A)$（偽シマウマ）→ $F(G(x_A))$（復元馬）≈ $x_A$（元の馬）
- 変換して戻したら元に戻るべき = **循環一貫性**

この制約により、ペア画像なしでも意味のある変換を学習できる。

##### 全体の損失関数

$$L_{total} = \underbrace{L_{GAN}(G, D_B)}_{\text{敵対的損失}} + \underbrace{L_{GAN}(F, D_A)}_{\text{敵対的損失}} + \lambda \underbrace{L_{cyc}}_{\text{循環一貫性}}$$

- $\lambda$: 循環一貫性の重み（通常10）

##### CycleGANの利点

✅ **主な利点**：
1. **ペア画像不要**：対応するデータの収集が不要（最大の利点）
2. **双方向変換**：A→BとB→Aを同時に学習
3. **柔軟なドメイン変換**：スタイル変換、季節変換等に適用可能

❌ **制約・欠点**：
1. **形状の大きな変化は困難**：馬→犬のような構造変化は難しい
2. **細部の精度低下**：Pix2Pixよりやや精度が低い
3. **学習時間が長い**：4つのネットワークを同時学習

##### 代表的な応用例

**スタイル変換**：
- 写真 ↔ モネ/ゴッホ風絵画
- 昼 ↔ 夜
- 夏 ↔ 冬

**動物変換**：
- 馬 ↔ シマウマ
- 猫 ↔ 犬（顔のみ）

**その他**：
- リンゴ ↔ オレンジ
- 衛星画像 ↔ 地図（ペアなし）

##### 試験での引っ掛けポイント

**CycleGANに関する正誤**：
- ✅ 「ペア画像なしで学習できる」= **CycleGANの最大の特徴**
- ✅ 「双方向変換を同時に学習」= **正しい**
- ✅ 「Cycle Consistency Lossを使用」= **正しい**
- ❌ 「ペア画像が必要」→ 誤り（**Pix2Pixの特徴**）
- ❌ 「1つの生成器のみ」→ 誤り（2つの生成器）
- ❌ 「条件付き生成」→ 誤り（**CGANの特徴**）

**Pix2Pix vs CycleGAN**：
- Pix2Pix: ペア画像必要、一方向変換、高精度
- CycleGAN: ペア画像不要、双方向変換、やや低精度

#### GANの課題

**モード崩壊（Mode Collapse）**：
- 生成器が多様性を失い、同じようなデータしか生成しなくなる

**学習の不安定性**：
- 生成器と識別器のバランスが重要
- 片方が強すぎると学習が進まない

### 生成モデルの比較

| 項目 | オートエンコーダ | VAE | GAN |
|------|--------------|-----|-----|
| **学習方法** | 再構成誤差最小化 | 再構成誤差+KL | 敵対的学習 |
| **生成品質** | 低い | 中程度 | **高い** |
| **多様性** | 低い | 中程度 | 高い |
| **学習安定性** | **高い** | 高い | 低い |
| **潜在空間** | 不明瞭 | **滑らか** | 不明瞭 |
| **理論的基盤** | 明確 | **非常に明確** | やや不明瞭 |
| **計算コスト** | 低い | 低い | **やや高い** |
| **用途** | 次元削減、異常検知 | データ生成、補間 | 高品質画像生成 |

## 試験での問われ方
- **典型設問**：
  - 「オートエンコーダとVAEの共通点は？」→ **デコーダの出力が入力を再構成する**
  - 「VAEが標準AEより生成に優れる理由は？」→ 潜在空間が確率分布で滑らか
  - 「GANの学習方法は？」→ 生成器と識別器の敵対的学習
  - 「GANの課題は？」→ モード崩壊、学習の不安定性
  - 「CycleGANの特徴は？」→ **ペア画像なしで双方向のドメイン変換が可能**
  - 「Pix2PixとCycleGANの違いは？」→ ペア画像の必要性（必要 vs 不要）
- **比較されやすい概念**：
  - **オートエンコーダ** vs **VAE**: 決定的潜在表現 vs 確率的潜在表現
  - **VAE** vs **GAN**: 再構成ベース vs 敵対的学習、学習安定 vs 高品質生成
  - **Pix2Pix** vs **CycleGAN**: ペア画像必要 vs 不要、一方向 vs 双方向、高精度 vs やや低精度
  - **CGAN** vs **CycleGAN**: 条件付き生成 vs ドメイン変換
  - **StyleGAN** vs **CycleGAN**: 高解像度顔生成 vs スタイル変換
  - **再構成** vs **生成**: 入力の復元 vs 新規データの作成
  - **エンコーダ** vs **デコーダ**: 圧縮 vs 復元
- **引っ掛けポイント**：
  - ✅ 「AEとVAEは両方とも入力を再構成する」= **正しい**
  - ❌ 「AEは教師あり学習」→ 誤り（教師なし学習）
  - ❌ 「VAEはラベルが必要」→ 誤り（教師なし学習）
  - ❌ 「GANは再構成誤差を最小化」→ 誤り（敵対的学習）
  - ✅ 「VAEはKLダイバージェンスで正則化」= **正しい**
  - ❌ 「GANは常に安定して学習できる」→ 誤り（学習不安定が課題）
  - ✅ 「CycleGANはペア画像なしで学習できる」= **正しい**
  - ❌ 「CycleGANはペア画像が必要」→ 誤り（**Pix2Pixの特徴**）
  - ✅ 「CycleGANはCycle Consistency Lossを使用」= **正しい**
  - ❌ 「CycleGANは1つの生成器のみ」→ 誤り（2つの生成器）
- **頻出パターン**：
  - AE/VAEの共通点（再構成）と相違点（潜在表現の性質）
  - VAEの損失関数（再構成誤差 + KLダイバージェンス）
  - GANの構成要素（生成器・識別器）と学習方法
  - CycleGANの特徴（ペア画像不要、双方向変換、Cycle Consistency Loss）
  - Pix2Pix vs CycleGANの違い（データ要件、変換方向、精度）
  - 各モデルの用途（次元削減、データ生成、高品質画像生成、スタイル変換）

## 補足
- **実務的観点**：
  - オートエンコーダは異常検知で広く使用（製造業の欠陥検出等）
  - VAEは創薬（分子生成）、画像編集（顔属性変換）で活用
  - GANはDeepFake、高解像度化、データ拡張（data augmentation）で実用
  - Diffusion Models（拡散モデル）がGANを超える生成品質で注目（2022年～）
  - Stable Diffusion、DALL-E等がText-to-Image生成で実用化
- **関連トピック**：
  - [ニューラルネットワーク基礎](neural_network_basics.md) - Encoder-Decoder構造の基礎
  - [CNN](cnn.md) - DCGAN等で使用される畳み込み層
  - [RNN](rnn.md) - 系列データの生成モデル
  - [自然言語処理](../07_ai_applications/natural_language_processing.md) - テキスト生成への応用
  - [画像認識](../07_ai_applications/image_recognition.md) - 生成モデルの応用
- **発展**：
  - Diffusion Models（DDPM、DDIM）
  - Transformer-based生成モデル（GPT、DALL-E）
  - Flow-based Models（Normalizing Flow）
  - Energy-based Models（EBM）
